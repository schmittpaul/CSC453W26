---
title: CSC 453
subtitle: Winter 2026 Day 3
format: 
  clean-revealjs:
    self-contained: true
    incremental: true
    margin: 0.15 
    # height: 700   # Optional: Normal height (defaults to 700)
    # width: 1000   # Optional: Normal width (defaults to 900)
---

## Admin
:::{.nonincremental}
- Lab 1 due tonight
  - Windows users: there are some settings to make the VM work if you missed lab
- Programming assignment 1 due next Monday
:::

# Dual-mode / Syscalls {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- How do we ensure that a user process doesn't harm others?
- How do system calls work? How do they related to wrapper libraries like `glibc`?
:::


## Dual-mode operation

- Dual-mode operation allows OS to protect itself and components
  - [User mode]{.alert} and [kernel]{.alert} mode 
- Mode bit provided by hardware 
  - Provides ability to distinguish when system is running user code or kernel code.
  - When a user is running → mode bit is "user"
  - When kernel code is executing → mode bit is "kernel"
- [System call]{.alert} changes mode to kernel, return from call resets it to user
- Some instructions are only executable in kernel mode

## System calls

- The OS offers a number of services. How do we (applications) interface with them?
  - We don't want to deal with the details, just the abstraction
  - The OS has ultimate control over these operations
- System calls are the "language" of communication with the OS
- Standards
  - Win32 (MS)
  - POSIX (nearly all Unix-based systems)
  - Java API for the JVM

## System calls (cont'd)

- Like a function call, we push arguments onto the stack, then we call into the library that provides the system call
- Each system call has a special number, placed into a register
- Executes a TRAP instruction (switch to kernel mode)
- A logical separation of memory space
- Kernel's system call handler is invoked, once done (but may block) may be returned to the process

## System calls (cont'd)

- Table defined in the kernel: [https://github.com/torvalds/linux/blob/master/arch/x86/entry/
syscalls/syscall_32.tbl](https://github.com/torvalds/linux/blob/master/arch/x86/entry/syscalls/syscall_32.tbl)
  - Note that system call tables can differ between architectures
- You can run using the table values themselves using the `syscall()` wrapper
  - Q: why does `syscall()` exist?
  - If you're interested… There are debates [https://lwn.net/Articles/771441/](https://lwn.net/Articles/771441/)

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::

# Process basics {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- What do processes contain?
- How does the OS run multiple processes at the same time?
- How are processes laid out in memory?
- How does the OS store information about each process?
:::

## Processes 
- Most fundamental OS abstraction
  - Processes organize information about other abstractions and represent a single thing the computer is "doing"
- When you run an executable program (passive), the OS creates a [process]{.alert} == a running program (active)
- One program can be multiple processes

## Process organization

:::: {.columns}

::: {.column width="45%"}
- Unlike threads, address spaces and files, processes are not tied to a hardware component. Instead, they contain other abstractions
- Processes contain:
  - one or more [threads]{.alert},
  - an [address space]{.alert}, and
  - zero or more open [file handles]{.alert} representing files
:::

::: {.column width="5%"}
:::

::: {.column width="50%"}
![](images/process_organization.png){.fragment}
:::

::::

## Multiprogramming
- Processes are the core abstraction that allows for [multiprogramming]{.alert}: the illusion of concurrency
- OS timeshares CPU across multiple processes: virtualizes CPU
- OS has a CPU scheduler that picks one of the many active processes to execute on a CPU
- Policy: 
  - [which]{.alert} process to run
- Mechanism: 
  - how to [context switch]{.alert} between processes

## Process's view of the world
:::: {.columns}

::: {.column width="65%"}
- Own memory with consistent addressing (divorced from physical addressing)
- It has exclusivity over the CPU: It doesn't have to worry about scheduling
- Conversely, it doesn't know when it will be scheduled, so real time events require special handling
- Has some identity: pid, gid, uid
- Has a set of services available to it via the OS
  - Data (via file system)
  - Communication (sockets, IPC)
  - More resources (e.g., memory)
:::

::: {.column width="5%"}
:::

::: {.column width="30%"}
![](images/process_structure.png){.fragment}
:::

::::

## Process memory layout
:::: {.columns}

::: {.column width="48%"}
- [Text]{.alert} segment: machine instructions; shareable between identical processes; read-only
- [Data]{.alert} segment: for initialized data; e.g., 
```int count = 99;```
- [BSS]{.alert} (block started by symbol) segment: uninitialized data; e.g., `int sum[10];`
- [Heap]{.alert}: dynamic memory allocation
- [Stack]{.alert}: initial arguments and environment; stack frames

:::

::: {.column width="2%"}
:::

::: {.column width="50%"}
![](images/process_memory.png){.fragment}
:::

::::

## OS's view of the (process) world
:::: {.columns}

::: {.column width="38%"}
- Data for each process is held in a data structure known as a [Process Control Block]{.alert}
- Partitioned memory: 
  - dedicated & shared address space   
  - perhaps non-contiguous
- Process table holds PCBs

:::

::: {.column width="2%"}
:::

::: {.column width="60%"}
![](images/process_table.png){.fragment}
:::

::::

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::

# Process state and scheduling {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- What are the different process states and what causes transitions?
- What is a context switch?
- What are the two general categories of processes and how do they differ?
:::

## Process states
- As a process executes, it changes *state*
  - [New]{.alert}: The process is being created
  - [Running]{.alert}: Instructions are being executed
  - [Waiting]{.alert}: The process is waiting for some event (typically I/O or signal handling) to occur
  - [Ready]{.alert}: The process is waiting to be assigned to a processor
  - [Terminated]{.alert}: The process has finished execution

## Process state transitions

![](images/process_states.png)

## Process state transitions (cont'd)
:::: {.columns}

::: {.column width="45%"}
- Running process can move from running to terminated (exit or killed), moved to ready (time slice up), or blocked (signaled to wait, I/O)
- Which state transitions could happen with these expensive actions?
  - Compute a new RSA key?
  - Find the largest value in a 1TB of data?
:::

::: {.column width="2%"}
:::

::: {.column width="53%"}
![](images/process_states2.png)
:::

::::

::: {.notes}
- Running to Waiting: This transition occurs when a process cannot continue executing until a specific event occurs. Here are some examples:
  - I/O Operations: 
    - Example: A process needs to read data from a disk. It issues an I/O request and then moves to the Waiting state until the data is read and available.
    - Real-World Scenario: A web server process waiting for data to be read from a database.
  - Resource Availability:
    - Example: A process requires a resource (like a printer) that is currently in use by another process. It moves to the Waiting state until the resource becomes available.
    - Real-World Scenario: A document editing application waiting for access to a shared printer.
  - Inter-Process Communication (IPC):
    - Example: A process is waiting for a message from another process. It moves to the Waiting state until the message is received.
    - Real-World Scenario: A chat application waiting for a message from a server.
  - Synchronization Primitives:
    - Example: A process is waiting for a lock or semaphore to be released by another process. It moves to the Waiting state until the lock is available.
    - Real-World Scenario: A banking application waiting for a transaction lock to be released.
- Running to Ready: This transition occurs when a process is preempted by the scheduler, but it is still ready to run as soon as it gets CPU time again. Here are some examples:
  - Time Slice Expiration:
    - Example: A process has used up its allocated time slice. The scheduler preempts it and moves it to the Ready state, allowing another process to run.
    - Real-World Scenario: A video streaming application being preempted to allow a background update process to run.
  - Higher Priority Process:
    - Example: A higher priority process becomes ready to run. The scheduler preempts the current process and moves it to the Ready state.
    - Real-World Scenario: An emergency alert system preempting a running media player application.
  - Voluntary Yield:
    - Example: A process voluntarily yields the CPU, indicating it can be preempted. The scheduler moves it to the Ready state.
    - Real-World Scenario: A background data synchronization process yielding the CPU to allow a user-initiated task to run.

:::

## Process scheduling
- [OS process scheduler]{.alert} selects among available processes for next execution on CPU core
- Goal?
  - Maximize CPU use, quickly switch processes onto CPU core
- Maintains [scheduling queues]{.alert} of processes
  - [Ready queue]{.alert}: set of all processes residing in main memory, ready and waiting to execute
  - [Wait queues]{.alert}: set of processes waiting for an event (i.e., I/O)
- Processes migrate among the various queues over their lifetime

## Context switching
- When CPU switches to another process, the system must save the state of the old process and load the saved state for the new process via a [context switch]{.alert}
- Context of a process represented in the PCB
- Context-switch time is **pure overhead**; the system does no useful work while switching
  - The more complex the OS and the PCB → the longer the context switch
- Time dependent on hardware support
  - Some hardware provides multiple sets of registers per CPU → multiple contexts loaded at once


## Context switching overhead
- On the order of milliseconds
- If not done intelligently, you can spend more time context-switching than actual processing
- Question: Why shouldn't processes control context switching?

::: {.notes}
- They could refuse to give up CPU (processes are greedy)
- They're intentionally isolated, and don't have enough information about other processes
- It would cause too much complication (every process would have to implement its own context switch code)
:::

## Scheduling basics
- Scheduler usually makes the transition decisions; hides the details from the process/user
- Processes often characterized as one of two types by what state they spend most of their time in
  - [I/O bound]{.alert}: work is dependent on I/O; e.g., browser, db, media streaming
  - [CPU bound]{.alert}: work is dependent on CPU; e.g., scientific apps, cryptography
  - Why does this matter?
    - Understanding which your process is allows for optimization
      - CPU-bound? Faster CPU, parallelize. 
      - I/O? Faster I/O devices, use async
- Scheduler must balance CPU- & I/O-bound processes
  - Reminder: the goal is to maximize CPU utilization

## Aside: multiprocessing in mobile
- Some mobile systems (e.g., early versions of iOS)  allow only one process to run, others suspended
- Due to screen real estate, user interface limits iOS provides: 
  - Single [foreground]{.alert} process controlled via user interface
  - Multiple [background]{.alert} processes in memory, running, but not on the display, and with limits
    - Limits include single, short task, receiving notification of events, specific long-running tasks like audio playback
- Android runs foreground and background, with fewer limits
  - Background process uses a [service]{.alert} to perform tasks
  - Service can keep running even if background process is suspended
  - Service has no user interface, small memory use


## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::


# Process management {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- Which system calls are related to process management and lifecycles? 
- How does the process hierarchy work?
- What are zombies and orphans? Why do zombies exist?
:::

## UNIX process APIs
- `fork()` creates a new child process
  - All processes are created by forking from a parent
  - The `init` process is ancestor of all processes
    - Run `pstree` in a terminal to see
- `exec()` makes a process execute a given executable (effectively replaces the process)
- `exit()` terminates a process
- `wait()` causes a parent to block until child terminates
- Many variants exist of the above system calls with different arguments

## What happens during a `fork()`?
- A new process is created by making a copy of parent's memory image
- Both parent and child have unique address spaces (isolated from each other, allowing for independent processing)
- The new process is added to the OS process list and scheduled
- Parent and child start execution just after fork (with different return values)
- Parent and child execute and modify the memory data independently

## Process creation
- Different execution models
  - Parent & child may execute independently
  - Parent may wait for child
  - Child may create more children (Process hierarchies)
  - Parent may kill children
- Child often invokes `exec()` to change its memory image to a new program
- Why two steps (`fork()` then `exec()`)? 
  - Allows the child to change file descriptors and other settings before `exec()`

## Process destruction
- Some operating systems do not allow child to exist if its parent has terminated.  If a process terminates, then all its children must also be terminated
  - [Cascading termination]{.alert}: All children, grandchildren, etc., are terminated.
  - The termination is initiated by the operating system
- The parent process may wait for termination of a child process by using the `wait()` system call. The call returns status information and the pid of the terminated process
  ```{c}
  pid = wait(&status); 
  ```

## Zombies and orphans
:::: {.columns}

::: {.column width="58%"}
- If no parent waiting (did not invoke `wait()`), and process completes, process is a [zombie]{.alert}
  - Zombie = dead but not yet reaped (exit status hasn't been read)
  - Still has an entry in the process table
  - We need zombies: so the kernel can preserve a child's exit status until the parent calls `wait()`, even if the child exits first
- If parent terminated without invoking `wait()`, process is an [orphan]{.alert}
  - Orphan = alive but parent is gone
  - `init` benevolently adopts orphans 
:::

::: {.column width="2%"}
:::

::: {.column width="40%"}
![](images/zombies_orphans.png)

:::

::::

:::{.notes}
```
Child exits → zombie
Parent exits → zombie becomes orphan
init adopts it → init calls wait() → zombie disappears
```
:::

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::


