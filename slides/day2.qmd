---
title: CSC 453
subtitle: Winter 2026 Day 2
format: 
  clean-revealjs:
    self-contained: true
    incremental: true
    margin: 0.15 
    # height: 700   # Optional: Normal height (defaults to 700)
    # width: 1000   # Optional: Normal width (defaults to 900)
---
## Admin
:::{.nonincremental}
- Quiz 1 due Friday
  - NOTE: this first quiz allows unlimited attempts. The rest will not.
- Lab 1 due Monday
- Assignment 1 due Jan 19
  - I'll talk a bit about this during lab today
- I realize this seem like a lot, but time is short
:::

# OS abstractions {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- What are the main abstractions OSes provide?
- What are the abstraction challenges?
:::

## Abstractions

- Abstractions _simplify application design_ by:
  - hiding undesirable properties,
  - adding new capabilities, and
  - organizing information
- Abstractions provide an [interface]{.alert} to application programmers that separates [policy]{.alert}—what the interface commits to accomplishing—from [mechanism]{.alert}—how the interface is implemented.

## What are the abstractions?

- CPUs
  - Processes, threads
- Memory
  - Address space
- Disk
  - Files

## Example OS abstraction: file systems

- What [undesirable properties]{.alert} do file systems hide?
  - Disks are slow!
  - Chunks of storage are actually distributed all over the disk
  - Disk storage may fail!
- What [new capabilities]{.alert} do files add?
  - Growth and shrinking
  - Organization into directories, searchability
- What [information]{.alert} do files help organize?
  - Ownership and permissions
  - Access time, modification time, type, etc.

## Abstraction tradeoffs - discussion

::: {.nonincremental}
- Identify undesirable properties hidden by, new capabilities added, and info organization provided with these abstractions:
  - Process / threads
  - Address space
:::

::: {.notes}
Processes/Threads

- Hiding undesirable properties:
  - Example: The process abstraction hides the complexity of CPU scheduling and context switching. Applications don't need to manage the low-level details of how the CPU switches between different tasks. Similarly, the thread abstraction hides the intricacies of managing multiple execution paths within a single process, allowing developers to focus on the logic of concurrent tasks.
- Adding new capabilities:
  - Example: Processes provide isolation between different applications, ensuring that one misbehaving application doesn't affect others. Threads within a process allow for parallel execution of tasks, improving performance and responsiveness. Additionally, operating systems often provide inter-process communication (IPC) mechanisms, enabling processes to coordinate and share data.
- Organizing information:
  - Example: The process abstraction organizes the execution environment by encapsulating the code, data, and resources needed for a program to run. Threads further organize execution by dividing tasks within a process into smaller, manageable units. This organization helps in structuring complex applications and improving their maintainability.

Memory Address Space

- Hiding undesirable properties:
  - Example: The memory address space abstraction hides the physical memory layout from applications. Programs use virtual addresses, which the operating system maps to physical memory locations. This abstraction also hides the details of memory fragmentation and allocation, simplifying memory management for developers.
- Adding new capabilities:
  - Example: Virtual memory allows applications to use more memory than physically available by swapping data to and from disk. This capability enables larger and more complex applications to run on systems with limited physical memory. Additionally, memory protection mechanisms prevent one process from accessing the memory of another, enhancing system stability and security.
- Organizing information:
  - Example: The memory address space abstraction organizes memory into segments such as code, data, heap, and stack. This organization helps in managing different types of data efficiently and ensures that memory is used in a structured manner. For instance, the stack is used for function calls and local variables, while the heap is used for dynamic memory allocation.

:::

## Abstraction pros / cons

- [Advantages]{.alert} of OS providing abstractions?
  - Allow applications to reuse common facilities
  - Make different devices look the same
  - Provide higher-level or more useful functionality
- [Challenges]{.alert}?
  - What are the correct abstractions?
  - How much should be exposed?

## OS design requirements - what do we need?

- [Convenience]{.alert}, abstraction of hardware resources for user programs
- [Efficiency]{.alert} of usage of CPU, memory, etc.
- [Isolation]{.alert} between multiple processes
- [Reliability]{.alert}, the OS must not fail
- Other:
  - Security
  - Mobility

## {background-color="#6E404F"}

::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::


# Resource management {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- How does the OS manage access to resources?
:::

## OS as a resource manager 


- Another view: [resource manager]{.alert} - shares resources "well"
- [Advantages]{.alert} of the OS managing resources?
  - Protect applications from one another
  - Provide efficient access to resources (cost, time, energy)
  - Provide fair access to resources
- [Challenges]{.alert}?
  - What are the correct mechanisms?
  - What are the correct policies?

## Resources are managed via [services]{.alert}

- Program Execution (loading, running, monitoring, terminating)
- Performance (optimizing resources under constraints)
- Correctness (overseeing critical operations, preventing interference)
- Fairness (access to and allocation of resources)
- Error detection & recovery (network partition & media failure)

## Services (cont'd)

- Communication (inter-process, software-to-hardware, hardware-to-hardware, system-to-system, wide-area)
- I/O: reading & writing, support for various mediums, devices, performance, and protections
- Data Organization (naming), Services (search) & Protection (access control)
- Security (isolation, enforcement, services, authentication, accounting and logging, trust)
- User interfaces (command-line, GUIs, multiple users)

## Each service has [challenges]{.alert} and [tensions]{.alert}

Example 1: We have limited RAM, and we want to run more programs that can be stored. 
  
- How do we allocate space?
- Who stays?
- Who goes? 
- What if we're wrong? 
- What if the system is under extremely heavy load?
- Is there a way to predict the future?

## Each service has [challenges]{.alert} and [tensions]{.alert}

Example 2: We have two process (producer / consumer); how do they communicate? 

- Message passing? Shared memory? 
- How do they synchronize? 
  - How to we prevent over-production? Over-consumption?
  - Context-switching?

## {background-color="#6E404F"}

::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::

# Boot chain {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- What is the chain of events that takes place before you are able to run a process?
- Where do the different parts of the chain reside? How are they called?
:::

## Boot is like a relay race

- A sequence of programs
- Each stage:
  - Has slightly more power
  - Loads the next stage
  - Jumps to it

## Power-On 

- CPU resets
- Instruction pointer set to a fixed address
- Execution begins in firmware (ROM)
- [The CPU does not know what an OS is]{.alert}

## Firmware (BIOS / UEFI)

- Initializes RAM
- Initializes minimal hardware
- Finds one program to run (bootloader)
- Loads it into memory
- Jumps to it

## Bootloader's job (GRUB Example)

- Understand filesystems
- Load the kernel image
- Load the initramfs
- Pass arguments to the kernel
- Jump to the kernel entry point
- Provides kernel command line args
  ```{.code}
  root=/dev/sda1
  init=/sbin/init
  console=ttyS0
  ```

## What the bootloader does [not]{.alert} do

- Does not schedule processes
- Does not manage memory long-term
- Does not run the OS

## Kernel

Think of the kernel in phases

1. Self-setup
2. Hardware abstraction
3. Userspace handoff

## Kernel self-setup
-	Sets up page tables
- Enables virtual memory
- Initializes scheduler
- Sets up interrupts

:::{.fragment}
The kernel cannot rely on [anything]{.alert} yet: it is building the world.
:::

## Kernel hardware abstractions
### This is where hardware becomes an abstraction.
- Detects hardware
- Loads drivers
- Turns devices into files:
  - `/dev/sda`
  - `/dev/tty`
- Creates kernel threads

## Userspace handoff
- Mounts the root filesystem
- Chooses one program to run
- Executes it with `execve()`
  ```{.c}
  execve("/sbin/init", ...);
  ```

## Init (PID 1)
- First userspace process
- Always PID 1
- Parent of all other processes

:::{.fragment}
If PID 1 exits?

- The kernel panics or shuts down
:::

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::

# Kernel basics {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- What are the different kernel paradigms?
- Why would you choose one over the other?
:::

## Paradigms

- The OS offers a number of services. What should go in the kernel?
  - IPC
  - VFS
  - File system
  - Scheduler
  - Virtual Memory
  - Device drivers

## Monolithic kernels

- Oldest, very common design (Linux, Windows 9x, BSDs)
- Single piece of code in memory
- Limited [information hiding]{.alert}
  - One part of the kernel can directly access data and functions of other parts

## Monolithic kernels (cont'd)

- Q: What happens when you need something new supported (new hardware device, new system call, new filesystem)? 
- [Modules]{.alert} (loadable kernel modules - LKMs) allow for flexibility, customization, support 
  - Pros?
    - Memory savings
    - Flexibility
    - Minimal downtime
  - Cons? 
    - (minor) fragmentation: the base kernel can be loaded contiguously in memory
    - Security ([https://github.com/m0nad/Diamorphine](https://github.com/m0nad/Diamorphine) **DO NOT USE THIS, IT'S SIMPLY TO SHOW YOU**)

## Layered kernels

- Dijkstra created the THE OS in the 60s, introducing the concept
Each inner layer is more privileged; required a trap to move down layers
- Hardware-enforcement possible
- Intel [announced](https://www.intel.com/content/www/us/en/developer/articles/technical/envisioning-future-simplified-architecture.html) in May 2024 that the new architectures will only have rings 0 and 3

## Microkernels

:::: {.columns}

::: {.column width="55%"}

- Popular research area long ago, didn't win (although people remain interested in the principles)
- All non-essential components removed from the kernel, for modularization, extensibility, isolation, security, and ease of management
- A collection of OS services running in user space
- Downsides? 
  - Heavy communication costs through message passing (marshaled through the kernel)

:::

::: {.column width="5%"}
:::

::: {.column width="40%"}
![](images/microkernel.png){.fragment}
:::

::::

## Monolithic vs Microkernel
![](images/mono_vs_micro.png)

## {background-color="#6E404F"}

::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::

<!-- # Process basics {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- How do we ensure that a user process doesn't harm others?
- How do system calls work? How do they related to wrapper libraries like `glibc`?
:::


## Dual-mode operation

- Dual-mode operation allows OS to protect itself and components
  - [User mode]{.alert} and [kernel]{.alert} mode 
- Mode bit provided by hardware 
  - Provides ability to distinguish when system is running user code or kernel code.
  - When a user is running → mode bit is "user"
  - When kernel code is executing → mode bit is "kernel"
- [System call]{.alert} changes mode to kernel, return from call resets it to user
- Some instructions are only executable in kernel mode

## System calls

- The OS offers a number of services. How do we (applications) interface with them?
  - We don't want to deal with the details, just the abstraction
  - The OS has ultimate control over these operations
- System calls are the "language" of communication with the OS
- Standards
  - Win32 (MS)
  - POSIX (nearly all Unix-based systems)
  - Java API for the JVM

## System calls (cont'd)

- Like a function call, we push arguments onto the stack, then we call into the library that provides the system call
- Each system call has a special number, placed into a register
- Executes a TRAP instruction (switch to kernel mode)
- A logical separation of memory space
- Kernel's system call handler is invoked, once done (but may block) may be returned to the process

## System calls (cont'd)

- Table defined in the kernel: [https://github.com/torvalds/linux/blob/master/arch/x86/entry/syscalls/syscall_32.tbl](https://github.com/torvalds/linux/blob/master/arch/x86/entry/syscalls/syscall_32.tbl)
- You can run using the table values themselves using the `syscall()` wrapper
  - Q: why does `syscall()` exist?
  - If you're interested… There are debates [https://lwn.net/Articles/771441/](https://lwn.net/Articles/771441/)

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::


# Assignment 1: SLOsh {background-color="#40666e"}

## SLOsh

- This assignment should be a refresher of 357 topics
- skeleton code on Canvas
- Your minimal shell will support: 
  - basic command execution
  - built-in commands
  - signal handling
  - I/O redirection
  - piping

## Requirements

::: {.nonincremental}
- C99 POSIX
- Must compile / run on the unix* servers
- You must create a functional Makefile
- Submit a tar (.tgz) file in Canvas
:::

## Command execution

- Execute external commands 
  - Use `fork()`, `exec()`, and `waitpid()` to manage process execution
- Support command-line arguments
- Handle both relative and absolute paths to executables
- Report command execution errors appropriately

## Redirection / piping

- Use `open()`, `dup2()`, and `close()` for file redirection
- Use `pipe()` for creating pipes between processes

## Signal handling

- Signals are async. They can happen at any time
- Certain functions are async-safe, others are not
  - `printf()` contains internal buffers and state; an interruption can lead to corrupted buffers 

## Handling SIGINT

- `write()` a newline or whatever to signify the signal was caught.
- If there is not a child running, `write()` a new prompt

## Parent vs child

- The child should immediately reset signal handling to the default
- Look up `signal()`'s man
  ```{.bash code-line-numbers=false}
  man 2 signal
  ``` 

## Sigaction

- `sigaction()` is newer than `signal()`
- Offers more control and is more consistent across systems
- Allows specifying flags
  - SA_RESTART (`man 7 signal`)
    - Without it, syscalls return with EINTR error if they are interrupted by a signal
    - With it, most syscalls automatically restart
- Is the POSIX-compliant approach
- EINTR can still happen, it's wise to check for it and handle it
  - When reading input from user

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::
-->