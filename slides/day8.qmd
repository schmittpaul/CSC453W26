---
title: CSC 453
subtitle: Winter 2026 Day 8
format: 
  clean-revealjs:
    self-contained: true
    incremental: true
    margin: 0.15 
    # height: 700   # Optional: Normal height (defaults to 700)
    # width: 1000   # Optional: Normal width (defaults to 900)
---

## Admin
:::{.nonincremental}
- Quiz due Friday
- Lab (synchronization and deadlock) due Monday
:::


# Primitives {background-color="#40666e"}
## Questions to consider
:::{.nonincremental}
- How do synchronization solutions compare in implementation / function?
- Why can busy-waiting primitives cause problems like priority inversion, and how do blocking primitives help address this?
- When would you choose a counting semaphore versus a binary semaphore or mutex, and what distinguishes them?
:::



## Semaphores
:::: {.columns}
::: {.column width="68%" .nonincremental}
- Synchronization tool that provides more sophisticated ways (than mutex locks)  for processes to synchronize their activities
- Semaphore `S`: integer variable
- Can only be accessed via two atomic operations
  - `wait()` and `signal()`
    - Originally called `P()` and `V()` (because, Dutch - another Dijkstra invention)
- Do not have ownership, any thread can signal (increment) or wait (decrement)
:::

::: {.column width="2%"}
:::

::: {.column width="30%"}
```{.c}
wait(S) { 
    while (S <= 0)
       ; // busy
    S--;
}

signal(S) { 
    S++;
}
```
:::
::::

## Semaphores (cont'd)
:::: {.columns}
::: {.column width="68%" .nonincremental}
- [Binary semaphore]{.alert}: integer value can range only between 0 and 1
  - Functionally the same as a mutex (often when people call something a mutex it's actually a binary semaphore)


:::

::: {.column width="2%"}
:::

::: {.column width="30%"}
```{.c}
do{
  wait(mutex);
  //CS
  signal(mutex);
}while(TRUE);
```
:::
::::
- [Counting semaphore]{.alert}: integer value can range over an unrestricted domain
  - When would this make sense?
    - Protect a finite set of resources rather than a single one (e.g., you have a pool of db connections that can be shared by processes)
    - Initialize `S` to the number of resources
    - Decrement `S` each time someone grabs a resource, increment when they release

## Semaphores (cont'd)
:::: {.columns}
::: {.column width="68%" .nonincremental}
- Can also be used to force synchronization
- Consider $P_1$  and $P_2$ that with two statements $S_1$ and $S_2$ and the requirement that $S_1$ to happen before $S_2$

:::

::: {.column width="2%"}
:::

::: {.column width="30%"}
```{.c}
P1:
   S1;
   signal(sync);
P2:
   wait(sync);
   S2;
```
:::
::::

## Blocking semaphores
:::: {.columns}
::: {.column width="58%" .nonincremental}
- We add `sleep()` and `wakeup()` to the underlying implementation
- Call to wait, and semaphore not available, process is blocked with `sleep()` (wait state) and placed on a waiting queue
- Blocked processes are notified of an available semaphore by the `wakeup()` operation
  - goes from waiting to ready
  - Able to achieve bounded wait and progress with FIFO queue

:::

::: {.column width="2%"}
:::

::: {.column width="40%"}
```{.c}
wait(semaphore *S) { 
   S->value--; 
   if (S->value < 0) {      
      add process to S->list; 
      sleep(); 
   } 
}

signal(semaphore *S) { 
   S->value++; 
   if (S->value <= 0) {      
      remove P from S->list; 
      wakeup(P); 
   } 
} 

```
:::
::::

## Mutexes vs. semaphores
- Mutexes are generally lighter weight / faster
- Semaphores can support multiple instances
- Semaphores don't have the ownership limitations 

## Choose your primitive
- For each, choose between: atomic instructions; futexes; spin lock mutexes; semaphores
- Scenario 1: You need to protect a critical section where only one thread should execute at a time, and the critical section is expected to be held for a relatively long duration.
  - Futex
- Scenario 2: You have a pool of database connections, and you need to limit the number of threads that can access these connections simultaneously.
  - Counting semaphore

## Choose your primitive (cont'd)
- For each, choose between: atomic instructions; futexes; spin lock mutexes; semaphores
- Scenario 3: You need to increment a shared counter frequently, and the operation is very quick.
  - Atomic instruction
- Scenario 4: You need to protect a critical section where only one thread should execute at a time, but the critical section is expected to be held for a very short duration.
  - Spin lock mutex

## Beware: mistakes are easy to make
-  Incorrect use of semaphore operations
    - wrong order: `signal(mutex)` ...  `wait(mutex)`
    - repeating: `wait(mutex)`  ...  `wait(mutex)`
    - Omitting of `wait(mutex)` and/or `signal(mutex)`
- Be careful

## Monitors
- Subtle mistakes with semaphores can lead to deadlocks, leading to [monitors]{.alert}
- Can think of monitors as a library with an API (abstract data type)
  - Processes share the library, but not internal data (directly)
  - This requires language specific understanding of a monitor (C doesn't have them, natively)
  - More relevant in languages like Java and other high-level languages that provide built-in monitor support

## Monitors (cont'd)
:::: {.columns}
::: {.column width="58%" .nonincremental}
- Main idea: only one processes can be active within a monitor at any instant
  - Up to the compilers to ensure mutual exclusion on monitor procedures
    - It can use other sync primitives to achieve this: e.g. a semaphore or mutex
  - We're offloading synchronization correctness to the compiler, (hopefully) lessening the chance for error by the user
- Monitor variables are private
:::

::: {.column width="2%"}
:::

::: {.column width="40%"}
![](images/monitor.png)
:::
::::

## Condition variables
- Monitors often have condition variables
- Condition variables have `wait()` and `signal()` operations
  - `x.wait()`:  a process that invokes the operation is suspended until `x.signal()` 
  - `x.signal()`: resumes one of processes (if any) that invoked `x.wait()`
    - If no `x.wait()` on the variable, then it has no effect on the variable
- Big benefit of condition variables: `x.broadcast()`

## Mutexes, semaphores, Monitors, Condition variables
- Mutexes and Semaphores are good for:
  - Simple mutual exclusion
  - Simple counting resources
- Monitors are good for:
  - Complex synchronization between many threads
  - Thread-safe operations (only allow one thread into the monitor at a time)
- Condition variables are good for:
  - Producer-consumer problems (consumer threads waiting on some condition, signaled when ready)
  - We want to make one or more threads sleep until a resource is ready


## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::

# Deadlocks {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- What are the four necessary conditions for deadlock, and why must all four be present simultaneously?
- How can Resource Allocation Graphs help us visualize and understand when deadlock might occur?
- Why is a cycle necessary but not sufficient for deadlock when there are multiple instances of a resource?
:::

## Deadlocks
- If we're not careful about dependencies, we might create pathologies that lead to deadlock
  - Like race conditions, may only happen sometimes, making them hard to identify and debug
- Example: Three processes, three resources of the same type, each process requires two resources to make progress
  - This can happen across a network as well, which is particularly hard to diagnose
- Can we [detect and resolve]{.alert} these situations? Can we [prevent]{.alert} them?

## Deadlock example
- Classic example: Thread1 holds lock L1 and is waiting for lock L2. Thread2 holds L2 and is waiting for L1
  ```
    Thread 1: 			            Thread 2:
    pthread_mutex_lock(L1); 		pthread_mutex_lock(L2);
    pthread_mutex_lock(L2); 		pthread_mutex_lock(L1);
  ```

## Deadlock characteristics
- Definition: A set of processes are deadlocked if each process in the set is waiting for an event that only another process in the set can cause.
  - [Resource deadlock]{.alert} is the most common (and what we'll focus on generally)
  - [Communication deadlock]{.alert}: e.g., Process A sends a message to B, then sleeps until reply; Process B sleeps until it receives a message from A; message is lost

## Conditions for deadlock
- Four necessary conditions (simultaneous):
  - **Mutual exclusion**: At least one resource can only be held by one process at a time; this can result in other processes waiting for that resources
  - **Hold and wait**: A process must be holding at least one resource while waiting for other resources (held by other processes)
  - **No preemption**: Resources can only be released voluntarily by a process; Resources cannot be revoked
  - **Circular wait**: A set of $n$ waiting process ${P_0, ..., P_n}$ such that $P_i$ is waiting for resources held by $P_{i+1 \bmod{n}}$ 
- All must be met, and some imply others: e.g. Circular wait implies hold and wait.

## Deadlock conditions
- Each condition relates to a policy that may or may not be implemented
  - Q: Can a resource be assigned to more than one process?
  - Q: Can a process request multiple resources? Over what period of time?
  - Q: Can resources be preempted, and how?

## Deadlock modeling
:::: {.columns}
::: {.column width="63%" .nonincremental}
- Resource Allocation Graphs: A directed graph, where process and resources are nodes (sometimes circles and squares respectively), and edges are resource allocations & requests
- Graph for

  ```
  Thread 1: 		          Thread 2:
  pthread_mutex_lock(L1);     pthread_mutex_lock(L2);
  pthread_mutex_lock(L2);     pthread_mutex_lock(L1);
	```


:::

::: {.column width="2%"}
:::

::: {.column width="35%"}
![](images/RAG.png)
:::
::::
- Cycles in a graph indicate deadlock
  - When resources have only one instance: A cycle is both necessary and sufficient for deadlock
  - **If there are multiple instances: A cycle is necessary but not sufficient for a deadlock**

## Is this deadlocked?


- There is a cycle
- But no hold and wait

![](images/deadlock_rag.png)

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::

# Handling deadlocks {background-color="#40666e"}

## Questions to consider
:::{.nonincremental}
- What are the approaches to handling deadlock? How practical is each? How do they differ in approach?
- How does deadlock avoidance differ from deadlock prevention? What techniques do we implement for deadlock avoidance?
- What are the trade-offs between detecting/recovering from deadlock versus preventing or avoiding it, and when is detection practical?
:::

## How should the OS handle deadlocks?
- OS can [prevent]{.alert} deadlock: ensure deadlocks can never occur (by preventing one of the deadlock requirements from occurring)
- OS can [avoid]{.alert} deadlock: like prevention, but given more information about a processes resource needs
- OS can [detect]{.alert} deadlock: allow system to deadlock, detect and recover
- OS can [do nothing]{.alert}, and let applications handle it
  - [Ostrich Algorithm]{.alert}: head in sand; wait

## Deadlock prevention
:::{.nonincremental}
- Remember, we just have to break one of these to prevent deadlock
  - Mutual exclusion
  - Hold and wait
  - No preemption
  - Circular wait
:::

- Any ideas?

:::{.notes}
Example Strategies:
- Dynamic Resource Allocation: Implement algorithms that dynamically adjust resource allocation based on current system state and process priorities.
- Timeout Mechanism: Introduce timeouts for resource requests, forcing processes to release resources if they cannot acquire all necessary resources within a certain timeframe.
- Resource Hierarchies: Establish a hierarchy for resource allocation, ensuring that processes request resources in a predefined order to avoid circular wait conditions.
- Predictive Analysis: Use machine learning to predict potential deadlock scenarios based on historical data and proactively adjust resource allocation.

Follow-Up Questions:
- How does your strategy address mutual exclusion?
- Can your strategy be implemented in real-world systems? If so, how?
- What challenges might arise when implementing your strategy?
:::

## Attacking mutual exclusion
- No one resource can only be held by one process at a time; while some resources are preemptable (like memory, through swapping) preventing mutual exclusion is fundamentally difficult as so many resource are non-sharable: printers, files, disks, etc.
  - We can create a monitor for non-preemptable resources (e.g., print spooler, disk drive buffer)

## Attacking hold and wait
- When a process requests a resource, it cannot be holding any other resources
- A process must request **all** of its resources at one time
- Example, treat group of lock acquisitions like a critical section and surround with a mutex

  ```{.c}
  pthread_mutex_lock(global_lock);
  pthread_mutex_lock(L1);
  pthread_mutex_lock(L2);
  ...
  pthread_mutex_unlock(global_lock);
  ```
- See any downsides?
  - Must know all needed locks a priori
  - Will likely decrease concurrency

## Attacking no preemption
- If a process is holding some resources and requests another that cannot be immediately allocated, then all resources held are released
- Process is restarted only when it can regain its old resources plus the new
- Or, if a process requests a resource that cannot be immediately allocated, then all resources held are preempted and added to the list of available resources
- Downsides?
  - Not all resources are preempt-able
  - Starvation is possible

## Attacking circular wait
- How could you prevent by focusing on the circular wait requirement?
- Impose a total ordering of all resource types
  - For example, resource types R1, R2, ..., Rn have ordering R1 < R2 < ... < Rn
  - A process that needs multiple resources must request them in increasing order of enumeration
- Downsides?
  - May be difficult to impose a meaningful ordering
  - May lead to reduced concurrency

## Deadlock prevention summary
- Which approach is best?
  - Attacking mutual exclusion is generally not feasible
  - Attacking hold and wait is wasteful and requires prescience
  - Attacking no preemption is difficult due to non-preemptable resources
  - Attacking circular wait is practical but may reduce concurrency - often the best choice and [most used](https://github.com/torvalds/linux/blob/f286757b644c226b6b31779da95a4fa7ab245ef5/mm/filemap.c#L80-L126)

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::

## Deadlock avoidance
- All of the prevention techniques can be heavy-handed, reducing concurrency and overall system throughput
- What if we had more information about process resource needs before allocation?
  - Could we make smarter decisions about resource allocation?
- This is the idea behind deadlock avoidance

## Avoidance via resource-allocation graph
:::: {.columns}
::: {.column width="63%"}
- Introduce the idea of a [claim edge]{.alert} (dashed line) from a process to a resource
  - Indicates that the process may request that resource in the future
- The system can maintain this graph, and only grant resources that will not create a cycle
- Any downsides / limitations?
  - Overhead of maintaining the graph and checking for cycles
  - Only applicable to single instance resources

:::
::: {.column width="2%"}
:::
::: {.column width="35%"}
![](images/RAG_claim.png)
:::
::::

## A note on Dijkstra's Banker's algorithm
- Most OS textbooks discuss Dijkstra's Banker's algorithm as a deadlock avoidance technique
- Each process must declare the maximum number of resources it may need
- When a process requests a resource, the system must determine if granting the request will leave the system in a safe state
  - A safe state is one where there exists a sequence of all processes such that each can obtain its maximum resources with the currently available resources plus those held by all preceding processes in the sequence
- If granting the request leads to an unsafe state, the process must wait
- Not often used in practice due to overhead and requirement for prescience

## Deadlock avoidance summary
- Do you think any of the avoidance methods are used in general purpose OSes? Why? Why not?
- Resource-allocation graph with claim edges is sometimes used for specific resource types
  - e.g., embedded systems with limited resources where you can predict maximum needs and the graph overhead is manageable
- Banker's algorithm is generally not used due to its overhead and requirements

## Detecting and recovering from deadlock
- Allow deadlocks to occur, then detect and recover
- In some cases, recovery is pretty simple. If your machine froze once per year (maybe it does?) what would you do?
  - Reboot
- What scenarios do you think complex detection and recovery would make sense?
  - Systems with high availability requirements where manual intervention is costly or impractical
    - telecommunications systems, financial transaction systems, healthcare systems
    - critical infrastructure systems

## Detection
- Use a wait-for graph: a simplified resource-allocation graph that removes resource nodes
  - An edge from process $P_i$ to $P_j$ indicates that $P_i$ is waiting for a resource held by $P_j$
  - A cycle in this graph indicates a deadlock
  - $O(n^2)$ algorithm to search for cycles (beyond the cost of maintaining the graph itself)
  - Only applies to single instance resources

## Detection (cont'd)
![](images/waitforgraph.png)

## Detection (cont'd)
- For multiple instance resources, we can use an algorithm similar to the Banker's algorithm to detect deadlock
- Question: How often should we run the detection algorithm?
  - Too often: wasteful overhead
  - Not often enough: long delays before recovery
  - What if we run it when a process requests a resource?
    - Could allow us to assign blame for deadlock to the requesting process
  - Heuristically (CPU utilization, etc.)
    - Less overhead, but harder to assign blame

## Recovery options
- Process termination
  - Abort all deadlocked processes (brute force)
  - Abort one process at a time until deadlock is resolved
    - How to choose which process to abort?
      - Priority, time running, resources used, etc.
- Resource preemption
  - Temporarily take resources away from some processes and give to others until deadlock is resolved
  - Highly dependent on the resource type
  - Rollback problem - processes may need to be rolled back to a safe state before resources can be reallocated
  - Starvation problem - same victims may be chosen repeatedly

## Handling deadlocks summary
- When to use which technique?
  - Prevention: when you can afford to limit concurrency and throughput for simplicity
  - Avoidance: when you have good information about process resource needs and can afford the overhead
  - Detection and recovery: when deadlocks are rare and the overhead of prevention/avoidance is unjustified
  - Do nothing: when deadlocks are extremely rare or tolerable and can be handled at the application level

## {background-color="#6E404F"}
::: {.r-fit-text}
What isn't clear? 

Comments? Thoughts? 
:::