[
  {
    "objectID": "slosh.html#slosh",
    "href": "slosh.html#slosh",
    "title": "CSC 453",
    "section": "SLOsh",
    "text": "SLOsh\n\nThis assignment should be a refresher of 357 topics\nskeleton code on Canvas\nYour minimal shell will support:\n\nbasic command execution\nbuilt-in commands\nsignal handling\nI/O redirection\npiping"
  },
  {
    "objectID": "slosh.html#requirements",
    "href": "slosh.html#requirements",
    "title": "CSC 453",
    "section": "Requirements",
    "text": "Requirements\n\nC99 POSIX\nMust compile / run on the unix* servers\nYou must create a functional Makefile\nSubmit a tar (.tgz) file in Canvas"
  },
  {
    "objectID": "slosh.html#command-execution",
    "href": "slosh.html#command-execution",
    "title": "CSC 453",
    "section": "Command execution",
    "text": "Command execution\n\nExecute external commands\n\nUse fork(), exec(), and waitpid() to manage process execution\n\nSupport command-line arguments\nHandle both relative and absolute paths to executables\nReport command execution errors appropriately"
  },
  {
    "objectID": "slosh.html#redirection-piping",
    "href": "slosh.html#redirection-piping",
    "title": "CSC 453",
    "section": "Redirection / piping",
    "text": "Redirection / piping\n\nUse open(), dup2(), and close() for file redirection\nUse pipe() for creating pipes between processes"
  },
  {
    "objectID": "slosh.html#signal-handling",
    "href": "slosh.html#signal-handling",
    "title": "CSC 453",
    "section": "Signal handling",
    "text": "Signal handling\n\nSignals are async. They can happen at any time\nCertain functions are async-safe, others are not\n\nprintf() contains internal buffers and state; an interruption can lead to corrupted buffers"
  },
  {
    "objectID": "slosh.html#handling-sigint",
    "href": "slosh.html#handling-sigint",
    "title": "CSC 453",
    "section": "Handling SIGINT",
    "text": "Handling SIGINT\n\nwrite() a newline or whatever to signify the signal was caught.\nIf there is not a child running, write() a new prompt"
  },
  {
    "objectID": "slosh.html#parent-vs-child",
    "href": "slosh.html#parent-vs-child",
    "title": "CSC 453",
    "section": "Parent vs child",
    "text": "Parent vs child\n\nThe child should immediately reset signal handling to the default\nLook up signal()’s man\nman 2 signal"
  },
  {
    "objectID": "slosh.html#sigaction",
    "href": "slosh.html#sigaction",
    "title": "CSC 453",
    "section": "Sigaction",
    "text": "Sigaction\n\nsigaction() is newer than signal()\nOffers more control and is more consistent across systems\nAllows specifying flags\n\nSA_RESTART (man 7 signal)\n\nWithout it, syscalls return with EINTR error if they are interrupted by a signal\nWith it, most syscalls automatically restart\n\n\nIs the POSIX-compliant approach\nEINTR can still happen, it’s wise to check for it and handle it\n\nWhen reading input from user"
  },
  {
    "objectID": "slosh.html#section",
    "href": "slosh.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day9.html#admin",
    "href": "day9.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nProgram 3: we need to cover page replacement first (should be Thursday)\n\nIt’s in C or python, your choice"
  },
  {
    "objectID": "day9.html#questions-to-consider",
    "href": "day9.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow can we detect when a deadlock has occurred?\nWhat are the trade-offs between different deadlock recovery strategies?\nHow should we handle deadlocks that occur through communication rather than resource contention?"
  },
  {
    "objectID": "day9.html#detecting-and-recovering-from-deadlock",
    "href": "day9.html#detecting-and-recovering-from-deadlock",
    "title": "CSC 453",
    "section": "Detecting and recovering from deadlock",
    "text": "Detecting and recovering from deadlock\n\nAllow deadlocks to occur, then detect and recover\nIn some cases, recovery is pretty simple. If your machine froze once per year (maybe it does?) what would you do?\n\nReboot\n\nWhat scenarios do you think complex detection and recovery would make sense?\n\nSystems with high availability requirements where manual intervention is costly or impractical\n\ntelecommunications systems, financial transaction systems, healthcare systems\ncritical infrastructure systems"
  },
  {
    "objectID": "day9.html#detection",
    "href": "day9.html#detection",
    "title": "CSC 453",
    "section": "Detection",
    "text": "Detection\n\nUse a wait-for graph: a simplified resource-allocation graph that removes resource nodes\n\nAn edge from process \\(P_i\\) to \\(P_j\\) indicates that \\(P_i\\) is waiting for a resource held by \\(P_j\\)\nA cycle in this graph indicates a deadlock\n\\(O(n^2)\\) algorithm to search for cycles (beyond the cost of maintaining the graph itself)\nOnly applies to single instance resources"
  },
  {
    "objectID": "day9.html#detection-contd",
    "href": "day9.html#detection-contd",
    "title": "CSC 453",
    "section": "Detection (cont’d)",
    "text": "Detection (cont’d)"
  },
  {
    "objectID": "day9.html#detection-contd-1",
    "href": "day9.html#detection-contd-1",
    "title": "CSC 453",
    "section": "Detection (cont’d)",
    "text": "Detection (cont’d)\n\nFor multiple instance resources, we can use an algorithm similar to the Banker’s algorithm to detect deadlock\nQuestion: How often should we run the detection algorithm?\n\nToo often: wasteful overhead\nNot often enough: long delays before recovery\nWhat if we run it when a process requests a resource?\n\nCould allow us to assign blame for deadlock to the requesting process\n\nHeuristically (CPU utilization, etc.)\n\nLess overhead, but harder to assign blame"
  },
  {
    "objectID": "day9.html#recovery-options",
    "href": "day9.html#recovery-options",
    "title": "CSC 453",
    "section": "Recovery options",
    "text": "Recovery options\n\nProcess termination\n\nAbort all deadlocked processes (brute force)\nAbort one process at a time until deadlock is resolved\n\nHow to choose which process to abort?\n\nPriority, time running, resources used, etc.\n\n\n\nResource preemption\n\nTemporarily take resources away from some processes and give to others until deadlock is resolved\nHighly dependent on the resource type\nRollback problem - processes may need to be rolled back to a safe state before resources can be reallocated\nStarvation problem - same victims may be chosen repeatedly"
  },
  {
    "objectID": "day9.html#communication-deadlocks",
    "href": "day9.html#communication-deadlocks",
    "title": "CSC 453",
    "section": "Communication deadlocks",
    "text": "Communication deadlocks\n\nExample: A sends a message to B and sleeps until a response; B sleeps until it receives a message; message is lost (packet dropped somewhere)\nThis is different than resource deadlock: A does not possess a resource B wants; in the above example, there aren’t even any resources\n\nyet this still meets our definition of deadlock: a set of processes are waiting for each other in a circular chain\n\nAs such, cannot be prevented using resource-based solution (ordering, preemption, mutual exclusion, etc)\nWhat should we do?"
  },
  {
    "objectID": "day9.html#communication-deadlocks-contd",
    "href": "day9.html#communication-deadlocks-contd",
    "title": "CSC 453",
    "section": "Communication deadlocks (cont’d)",
    "text": "Communication deadlocks (cont’d)\n\nOne option: use timeouts and retries\n\nTimers go off after some “expected response” time\n\nAt what interval?\nWhat do we do when timer goes off? Retransmit? How many times?\n\nIf there’s delay, and not loss, recipient may receive the same message twice\n\nWhat happens in these circumstance?\n\nRequires a protocol for handling (and largely out of the scope of this course)"
  },
  {
    "objectID": "day9.html#handling-deadlocks-summary",
    "href": "day9.html#handling-deadlocks-summary",
    "title": "CSC 453",
    "section": "Handling deadlocks summary",
    "text": "Handling deadlocks summary\n\nWhen to use which technique?\n\nPrevention: when you can afford to limit concurrency and throughput for simplicity\nAvoidance: when you have good information about process resource needs and can afford the overhead\nDetection and recovery: when deadlocks are rare and the overhead of prevention/avoidance is unjustified\nDo nothing: when deadlocks are extremely rare or tolerable and can be handled at the application level\n\nDepends on contention: if resources are highly contended, prevention/avoidance may be necessary to maintain performance"
  },
  {
    "objectID": "day9.html#section",
    "href": "day9.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day9.html#questions-to-consider-1",
    "href": "day9.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the requirements for memory that the OS must accomplish?\nWhat abstraction should the OS provide to processes?\nWhat problems does memory virtualization solve?"
  },
  {
    "objectID": "day9.html#memory-overview",
    "href": "day9.html#memory-overview",
    "title": "CSC 453",
    "section": "Memory overview",
    "text": "Memory overview\n\nMemory is required by all processes\nWhat users (developers) want:\n\nInfinite space, private, fast, and cheap\n\nReality: All memory is limited, only some is fast (and $$$), others are slow (but $)\n\nCreates a memory hierarchy\nSmall, fast, expensive (registers, cache, RAM) → Large, slow, cheap (ssd, disk, tape)\nIn order to support multiprogramming we must share and utilize memory hierarchy intelligently"
  },
  {
    "objectID": "day9.html#memory-hierarchy",
    "href": "day9.html#memory-hierarchy",
    "title": "CSC 453",
    "section": "Memory hierarchy",
    "text": "Memory hierarchy"
  },
  {
    "objectID": "day9.html#memory-preliminaries",
    "href": "day9.html#memory-preliminaries",
    "title": "CSC 453",
    "section": "Memory preliminaries",
    "text": "Memory preliminaries\n\nRemember: A process’s code & data must both be in memory\n\nCPU must fetch both as part of its instruction-execution cycle\n\nWhat memory can a CPU access directly?\n\nRegisters, caches, RAM\nTherefore, any data or instruction must be in these direct access devices in order to operate on them\n\nIn this discussion we’re focusing on RAM (caches + registers are hardware problems)\nMemory is an array of words (width of memory), kind of"
  },
  {
    "objectID": "day9.html#memory-requirements",
    "href": "day9.html#memory-requirements",
    "title": "CSC 453",
    "section": "Memory requirements",
    "text": "Memory requirements\n\nWhat does the OS need to provide?\nOld days?\n\nJust the OS libraries and a single process got the rest of the system memory\n\nBetween multiple processes? Processes and the kernel?\n\nTransparency: we don’t want processes to be aware of the virtualization.\n\nThey need to be presented with a simple address space\n\nEfficiency: memory is expensive and scarce\n\nNeed to be efficient in both space and time\n\nProtection / isolation: we need to ensure that processes can’t access other process’s address space (or the kernel’s)"
  },
  {
    "objectID": "day9.html#memory-requirements-contd",
    "href": "day9.html#memory-requirements-contd",
    "title": "CSC 453",
    "section": "Memory requirements (cont’d)",
    "text": "Memory requirements (cont’d)\n\nFrom a process point of view how should we address things?\n\nAbstraction, we need an address space\n\nWe present an address space to processes that is their unique view of the system memory\n\nCode, Heap, Stack, etc.\nProcess sees fake (virtual) addresses\nQ: We know that heap & stack grow towards one another. How does it work when we have multiple threads?"
  },
  {
    "objectID": "day9.html#section-1",
    "href": "day9.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day9.html#questions-to-consider-2",
    "href": "day9.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow can the OS provide isolation between processes?\nWhat are the trade-offs in when we bind virtual addresses to physical addresses?\nHow can hardware help the OS manage memory efficiently?"
  },
  {
    "objectID": "day9.html#base-and-bounds",
    "href": "day9.html#base-and-bounds",
    "title": "CSC 453",
    "section": "Base and bounds",
    "text": "Base and bounds\n\nOkay, we’re going to lie to processes. How should we achieve this abstraction?\nFirst approach: base and bounds (or base and limit) registers\n\nBase: smallest address; bounds: size of address space\nThis can help with protection / isolation\nWhere should the values be stored?\nThe CPU needs to check for every memory access\n\nStored in the PCB (we just added state that a context switch needs to account for)"
  },
  {
    "objectID": "day9.html#base-and-bounds-contd",
    "href": "day9.html#base-and-bounds-contd",
    "title": "CSC 453",
    "section": "Base and bounds (cont’d)",
    "text": "Base and bounds (cont’d)\n\nWhat will the OS need to keep track of?\n\nWhen a process is first run\n\nNeed to find space for it (i.e., must be tracking free space)\n\nWhen a process terminates\n\nReturn used memory to the free list\nClean up any data structures used to manage memory\n\nOn context switch?\n\nCPU only has one set of base and bounds registers\n\nWhen OS wants to relocate a process\n\nSet new registers\n\nWhen a process tries to address outside of its bound?\n\nexception handlers"
  },
  {
    "objectID": "day9.html#base-and-bounds-contd-1",
    "href": "day9.html#base-and-bounds-contd-1",
    "title": "CSC 453",
    "section": "Base and bounds (cont’d)",
    "text": "Base and bounds (cont’d)\n\nBase and bounds is simple, but has some issues:\n\nInternal fragmentation: if a process needs 10KB but we allocate 20KB, we have 10KB of wasted space\nExternal fragmentation: over time, as processes are loaded and unloaded, we can end up with slivers of memory that are not usable for new processes\nRelocation is expensive: moving a process in memory requires copying all of its data\n\nTo address these issues, we can use more sophisticated memory management techniques, such as paging and segmentation"
  },
  {
    "objectID": "day9.html#memory-address-binding",
    "href": "day9.html#memory-address-binding",
    "title": "CSC 453",
    "section": "Memory address binding",
    "text": "Memory address binding\n\nWhen does the OS bind virtual addresses to physical addresses?\n\nCompile time: if we know where the process will be loaded, we can bind addresses at compile time\n\nNot flexible\nif you need to change anything, you need to recompile\n\nLoad time: we can bind addresses when the process is loaded into memory\n\nMore flexible, but still not ideal\nIf you need to move the process, you need to reload it\n\nRuntime: we can bind addresses during execution, which allows for maximum flexibility and is the most common approach\n\nRequires some help"
  },
  {
    "objectID": "day9.html#runtime-address-binding",
    "href": "day9.html#runtime-address-binding",
    "title": "CSC 453",
    "section": "Runtime address binding",
    "text": "Runtime address binding\n\nTo support runtime address binding, we need to use a memory management unit (MMU)\n\nHardware component that translates virtual addresses to physical addresses on-the-fly\nCan also provide protection by checking access rights and ensuring that processes cannot access memory outside of their allocated space\n\nThe OS needs to maintain a data structure (e.g., page table) that the MMU can use for translation\nThis allows processes to have a uniform address space (e.g., starting at 0 and going to “max”)"
  },
  {
    "objectID": "day9.html#section-2",
    "href": "day9.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day9.html#questions-to-consider-3",
    "href": "day9.html#questions-to-consider-3",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow can we reduce memory footprint without limiting functionality?\nWhat are the benefits and challenges of sharing code across processes?\nWhat are the trade-offs in swapping processes to disk?"
  },
  {
    "objectID": "day9.html#dynamic-loading",
    "href": "day9.html#dynamic-loading",
    "title": "CSC 453",
    "section": "Dynamic loading",
    "text": "Dynamic loading\n\nTo further optimize memory usage, we can use dynamic loading\n\nOnly load parts of a process into memory when they are needed\n\nWhy would this be required?\n\nOtherwise, we’d be restricted to running processes strictly smaller than our physical memory\n\n\nThis can be done at the function level (e.g., load a function when it’s called) or at the module level (e.g., load a shared library when used)\n\nReduces the memory footprint of processes and allows for faster startup times, though it does add complexity\nAny scenarios where this would be particularly beneficial?\n\nGood for large, infrequently used routines (e.g., error handling code) or for plugins/extensions that may not be used in every execution"
  },
  {
    "objectID": "day9.html#dynamic-linking",
    "href": "day9.html#dynamic-linking",
    "title": "CSC 453",
    "section": "Dynamic linking",
    "text": "Dynamic linking\n\nInstead of statically linking a library at compile time, we can link it at runtime\nAllows multiple processes to share the same library code in memory, reducing overall memory usage (we’ve already seen this with shared libraries in pmap output)\nAllows for libraries to be updated without recompiling processes\nHowever, it can introduce complexity (e.g., “DLL Hell”)\nDoes require some support from the OS and the dynamic linker/loader to manage the shared libraries and ensure they are loaded correctly\nWhat could go wrong here?\n\nIf a required library is missing or incompatible, the process may fail to start or crash at runtime\nWhat if one process updates a shared library while another process is using it? This could lead to unpredictable behavior or crashes"
  },
  {
    "objectID": "day9.html#swapping",
    "href": "day9.html#swapping",
    "title": "CSC 453",
    "section": "Swapping",
    "text": "Swapping\n\nSwapping allows an entire process to be moved from main memory to a backing store (like disk)\nQ: Why swap?\n\nCan run far more processes than RAM can handle\n\nQ: When do we swap?\n\nWhen we want to run more processes than can fit into physical memory\n\nQ: When swapping back in, where does the process go?\n\nDepends on the memory binding\nIf runtime, then it can go anywhere (maximum flexibility)"
  },
  {
    "objectID": "day9.html#swapping-caveats",
    "href": "day9.html#swapping-caveats",
    "title": "CSC 453",
    "section": "Swapping caveats",
    "text": "Swapping caveats\n\nRemember though: disk is very slow, so we must be careful and clever about who, how, and when we swap\n\nThe amount of time we spend swapping is directly proportional to the amount of memory we want to swap\nTransfer time dominates (not context switching)\n\nThe state of a process matters\n\nE.g. if it’s blocked on I/O, we may 1) further delay the I/O by using the disk to swap, 2) a direct I/O request may return to the wrong process\nPrograms are growing larger, so quite expensive to swap\n\ne.g. 1GB program ~10 sec per swap to a spinning disk\n\n\nIn reality: we don’t really swap entire processes; too costly and unnecessary\n\nWe can swap pages, we’ll talk about this later"
  },
  {
    "objectID": "day9.html#section-3",
    "href": "day9.html#section-3",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day9.html#questions-to-consider-4",
    "href": "day9.html#questions-to-consider-4",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow do we keep track of free memory and decide where to place processes?\nWhat problems arise from fragmentation, and how can we address them?\nWhat are the trade-offs between different allocation strategies?"
  },
  {
    "objectID": "day9.html#memory-allocation-strategies",
    "href": "day9.html#memory-allocation-strategies",
    "title": "CSC 453",
    "section": "Memory allocation strategies",
    "text": "Memory allocation strategies\n\nHow do we find free memory for processes?\nHow do we keep track of free memory?\nHow do we decide which free block to allocate to a process?"
  },
  {
    "objectID": "day9.html#contiguous-allocation-1",
    "href": "day9.html#contiguous-allocation-1",
    "title": "CSC 453",
    "section": "Contiguous allocation",
    "text": "Contiguous allocation\n\nMemory is allocated in contiguous blocks\nOne approach: memory may be partitioned into fixed-sized partitions, each containing one process\n\nThis is very simple, but inflexible\nA fixed number of partitions means we can only run n processes, and the size of the partitions may not match the needs of the processes\n\nAnother approach: variable-sized partitions, where we allocate exactly as much memory as a process needs"
  },
  {
    "objectID": "day9.html#variable-partitioning",
    "href": "day9.html#variable-partitioning",
    "title": "CSC 453",
    "section": "Variable partitioning",
    "text": "Variable partitioning\n\nAny obvious problems with variable partitioning?\n\nExternal fragmentation: over time, as processes are loaded and unloaded, we can end up with small free blocks of memory that are not usable for new processes\n\nTo begin, we allocate memory for processes until none fit into any of the “holes”\nOnce there is no hole that is big enough to fit a process, what do we do?\n\nCan we rearrange memory to create enough space?\n\nCompaction: move processes around to create enough contiguous space for the new process\nThis is expensive"
  },
  {
    "objectID": "day9.html#allocation-strategies",
    "href": "day9.html#allocation-strategies",
    "title": "CSC 453",
    "section": "Allocation strategies",
    "text": "Allocation strategies\n\nHow do we decide which hole to use for a new process?\nFirst fit: allocate the first hole that is big enough\nBest fit: allocate the smallest hole that is big enough\nWorst fit: allocate the largest hole\nDownsides to these?\n\nFirst fit: can lead to fragmentation at the beginning of memory\nBest/worst fit: require full scan\nOne solution: Next fit: similar to first fit, but continues searching from the last allocated hole"
  },
  {
    "objectID": "day9.html#external-fragmentation",
    "href": "day9.html#external-fragmentation",
    "title": "CSC 453",
    "section": "External fragmentation",
    "text": "External fragmentation\n\nIdeally, we want all memory to be allocated, but\nIn reality, we’re left with many holes that are not one is big enough to allocate anything into\n\nAlthough, combined they may be\n\nAll the allocation strategies above can suffer from external fragmentation\nGenerally waste 1/3 of the average process size due to external frag using first-fit or best-fit\nOne solution: compaction, but this is expensive"
  },
  {
    "objectID": "day9.html#segmentation",
    "href": "day9.html#segmentation",
    "title": "CSC 453",
    "section": "Segmentation",
    "text": "Segmentation\n\nPrevious approaches have been focused on allocating contiguous blocks of memory, but what if we could allow processes to be allocated in non-contiguous segments?\nSegmentation divides a process’s address space into logical segments (e.g., code, data, stack) that can be allocated separately\nEach segment has a base and bounds, and the OS maintains a segment table for each process that maps virtual segment numbers to physical memory locations\nStill suffers from internal fragmentation if segments are not fully utilized\nCan also lead to external fragmentation, but less so than contiguous allocation since segments can be allocated in non-contiguous memory"
  },
  {
    "objectID": "day9.html#section-4",
    "href": "day9.html#section-4",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day1.html#who-am-i",
    "href": "day1.html#who-am-i",
    "title": "CSC 453",
    "section": "Who am I?",
    "text": "Who am I?\n\nhttps://pschmitt.net\nAcademics\n\nPhD at UCSB\nResearcher (summers) at ICSI\nPostdoc then research faculty at Princeton\nSome other stops… USC, Stanford, UH\n\nPrivacy startup co-founder & CEO, measurement startup COO\nMain focuses\n\nIntegrating privacy and security into systems that we all use\nML for network management\nConnectivity / privacy in challenging environments"
  },
  {
    "objectID": "day1.html#this-class-1",
    "href": "day1.html#this-class-1",
    "title": "CSC 453",
    "section": "This class",
    "text": "This class\n\nToo much to cover in one term: survey of important topics\nCourse Canvas: https://canvas.calpoly.edu/courses/168889\nSyllabus: https://schmittpaul.github.io/CSC453W26/syllabus.pdf\nWaitlists…\nWhat OSes do you all run?"
  },
  {
    "objectID": "day1.html#who-are-you",
    "href": "day1.html#who-are-you",
    "title": "CSC 453",
    "section": "Who are you?",
    "text": "Who are you?\n\nName / Major / Year\nWhere do you identify as your hometown?"
  },
  {
    "objectID": "day1.html#how-to-succeed-in-this-class",
    "href": "day1.html#how-to-succeed-in-this-class",
    "title": "CSC 453",
    "section": "How to succeed in this class",
    "text": "How to succeed in this class\n\nTurn things in on time\nAttend class\n\n… on time. Lectures will start at 10 after the hour\n\n\nAsk questions\n\nI’m very flexible about how much we cover this semester\nI would rather teach less and have everyone understand it\nOur back-and-forth during class is the one of the few indicators I have of how much you are absorbing\n\nTalk to me if you are struggling"
  },
  {
    "objectID": "day1.html#what-are-we-doing-here",
    "href": "day1.html#what-are-we-doing-here",
    "title": "CSC 453",
    "section": "What are we doing here?",
    "text": "What are we doing here?\n\n\n\nHow many of you have participated in OS development?\nHow many of you regularly program in languages that use operating system abstractions directly?\nAnd C is a decreasingly popular language!\nSo why study operating systems? Why is this class even offered? Why is it required?"
  },
  {
    "objectID": "day1.html#why-take-this-class",
    "href": "day1.html#why-take-this-class",
    "title": "CSC 453",
    "section": "Why take this class",
    "text": "Why take this class\n\nYou are required to do so in order to graduate\nReality: this is how computers really work, and as a computer scientist or engineer you should know how computers really work\nUbiquity: operating systems are everywhere and you are likely to eventually encounter them or their limitations\nBeauty: operating systems are examples of mature solutions to difficult design and engineering problems. Studying them will improve your ability to design and implement abstractions"
  },
  {
    "objectID": "day1.html#course-progression",
    "href": "day1.html#course-progression",
    "title": "CSC 453",
    "section": "Course progression",
    "text": "Course progression\n\nIntroduction to operating system abstractions and structures\nAbstracting and multiplexing:\n\nCPU: interrupts, context, threads, processes, processor scheduling, thread synchronization, deadlocks\nMemory: memory layout, address translation, paging and segmentation, address spaces, translation caching, page fault handling, page eviction, swapping\nFile systems and storage: disk scheduling, on-disk layout, files, buffer cache, crash and recovery\nSecurity (time permitting)"
  },
  {
    "objectID": "day1.html#questions-to-consider",
    "href": "day1.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat is an operating system?\nWhat do they do?\nHow did OSes evolve?\nHow do the requirements differ for different OSes?"
  },
  {
    "objectID": "day1.html#what-is-an-operating-system",
    "href": "day1.html#what-is-an-operating-system",
    "title": "CSC 453",
    "section": "What is an operating system?",
    "text": "What is an operating system?\n\n\n\nOperating System:\n\nA computer program that\nmultiplexes hardware resources and\nimplements useful abstractions.\n\nThe OS is just another computer program. Has the highest privilege. The core of the OS consists of the kernel\nMultiplexing allows multiple people or programs to use the same set of hardware resources - processors, memory, disks, network connection - safely and efficiently.\nAbstractions simplify the usage of hardware resources by organizing information or implementing new capabilities."
  },
  {
    "objectID": "day1.html#os-history---how-did-we-get-here",
    "href": "day1.html#os-history---how-did-we-get-here",
    "title": "CSC 453",
    "section": "OS history - how did we get here?",
    "text": "OS history - how did we get here?\n\n\n\nStarted out as libraries to provide common functionality across programs\n\nSee any issues with this approach?\n\nLater, evolved from procedure call to system call\n\nWhat’s the difference?\n\nEvolved from running a single program to multiple processes concurrently\n\nNew issues to solve?\n\n\n\n\n\n\n\n\n\nImagine you allowed any process to read anywhere from the disk or memory. There is no privacy.\nMemory protection, concurrency / scheduling issues"
  },
  {
    "objectID": "day1.html#types-of-operating-systems",
    "href": "day1.html#types-of-operating-systems",
    "title": "CSC 453",
    "section": "Types of operating systems",
    "text": "Types of operating systems\n\nDesktop\nTime share/Mainframe\nMobile\nWeb\nReal-time\nEmbedded\nVirtual Machines"
  },
  {
    "objectID": "day1.html#tldr",
    "href": "day1.html#tldr",
    "title": "CSC 453",
    "section": "Tl;dr",
    "text": "Tl;dr\nOSes continue to evolve as environments (i.e., constraints) change"
  },
  {
    "objectID": "day1.html#section-1",
    "href": "day1.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day1.html#questions-to-consider-1",
    "href": "day1.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the main abstractions OSes provide?\nWhat are the abstraction challenges?"
  },
  {
    "objectID": "day1.html#abstractions",
    "href": "day1.html#abstractions",
    "title": "CSC 453",
    "section": "Abstractions",
    "text": "Abstractions\n\nAbstractions simplify application design by:\n\nhiding undesirable properties,\nadding new capabilities, and\norganizing information\n\nAbstractions provide an interface to application programmers that separates policy—what the interface commits to accomplishing—from mechanism—how the interface is implemented."
  },
  {
    "objectID": "day1.html#what-are-the-abstractions",
    "href": "day1.html#what-are-the-abstractions",
    "title": "CSC 453",
    "section": "What are the abstractions?",
    "text": "What are the abstractions?\n\nCPUs\n\nProcesses, threads\n\nMemory\n\nAddress space\n\nDisk\n\nFiles"
  },
  {
    "objectID": "day1.html#example-os-abstraction-file-systems",
    "href": "day1.html#example-os-abstraction-file-systems",
    "title": "CSC 453",
    "section": "Example OS abstraction: file systems",
    "text": "Example OS abstraction: file systems\n\nWhat undesirable properties do file systems hide?\n\nDisks are slow!\nChunks of storage are actually distributed all over the disk\nDisk storage may fail!\n\nWhat new capabilities do files add?\n\nGrowth and shrinking\nOrganization into directories, searchability\n\nWhat information do files help organize?\n\nOwnership and permissions\nAccess time, modification time, type, etc."
  },
  {
    "objectID": "day1.html#abstraction-tradeoffs---discussion",
    "href": "day1.html#abstraction-tradeoffs---discussion",
    "title": "CSC 453",
    "section": "Abstraction tradeoffs - discussion",
    "text": "Abstraction tradeoffs - discussion\n\nIdentify undesirable properties hidden by, new capabilities added, and info organization provided with these abstractions:\n\nProcess / threads\nAddress space\n\n\n\nProcesses/Threads\n\nHiding undesirable properties:\n\nExample: The process abstraction hides the complexity of CPU scheduling and context switching. Applications don’t need to manage the low-level details of how the CPU switches between different tasks. Similarly, the thread abstraction hides the intricacies of managing multiple execution paths within a single process, allowing developers to focus on the logic of concurrent tasks.\n\nAdding new capabilities:\n\nExample: Processes provide isolation between different applications, ensuring that one misbehaving application doesn’t affect others. Threads within a process allow for parallel execution of tasks, improving performance and responsiveness. Additionally, operating systems often provide inter-process communication (IPC) mechanisms, enabling processes to coordinate and share data.\n\nOrganizing information:\n\nExample: The process abstraction organizes the execution environment by encapsulating the code, data, and resources needed for a program to run. Threads further organize execution by dividing tasks within a process into smaller, manageable units. This organization helps in structuring complex applications and improving their maintainability.\n\n\nMemory Address Space\n\nHiding undesirable properties:\n\nExample: The memory address space abstraction hides the physical memory layout from applications. Programs use virtual addresses, which the operating system maps to physical memory locations. This abstraction also hides the details of memory fragmentation and allocation, simplifying memory management for developers.\n\nAdding new capabilities:\n\nExample: Virtual memory allows applications to use more memory than physically available by swapping data to and from disk. This capability enables larger and more complex applications to run on systems with limited physical memory. Additionally, memory protection mechanisms prevent one process from accessing the memory of another, enhancing system stability and security.\n\nOrganizing information:\n\nExample: The memory address space abstraction organizes memory into segments such as code, data, heap, and stack. This organization helps in managing different types of data efficiently and ensures that memory is used in a structured manner. For instance, the stack is used for function calls and local variables, while the heap is used for dynamic memory allocation."
  },
  {
    "objectID": "day1.html#abstraction-pros-cons",
    "href": "day1.html#abstraction-pros-cons",
    "title": "CSC 453",
    "section": "Abstraction pros / cons",
    "text": "Abstraction pros / cons\n\nAdvantages of OS providing abstractions?\n\nAllow applications to reuse common facilities\nMake different devices look the same\nProvide higher-level or more useful functionality\n\nChallenges?\n\nWhat are the correct abstractions?\nHow much should be exposed?"
  },
  {
    "objectID": "day1.html#os-design-requirements---what-do-we-need",
    "href": "day1.html#os-design-requirements---what-do-we-need",
    "title": "CSC 453",
    "section": "OS design requirements - what do we need?",
    "text": "OS design requirements - what do we need?\n\nConvenience, abstraction of hardware resources for user programs\nEfficiency of usage of CPU, memory, etc.\nIsolation between multiple processes\nReliability, the OS must not fail\nOther:\n\nSecurity\nMobility"
  },
  {
    "objectID": "day1.html#section-2",
    "href": "day1.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day3.html#admin",
    "href": "day3.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nLab 1 due tonight\n\nWindows users: there are some settings to make the VM work if you missed lab\n\nProgramming assignment 1 due next Monday"
  },
  {
    "objectID": "day3.html#questions-to-consider",
    "href": "day3.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow do we ensure that a user process doesn’t harm others?\nHow do system calls work? How do they related to wrapper libraries like glibc?"
  },
  {
    "objectID": "day3.html#dual-mode-operation",
    "href": "day3.html#dual-mode-operation",
    "title": "CSC 453",
    "section": "Dual-mode operation",
    "text": "Dual-mode operation\n\nDual-mode operation allows OS to protect itself and components\n\nUser mode and kernel mode\n\nMode bit provided by hardware\n\nProvides ability to distinguish when system is running user code or kernel code.\nWhen a user is running → mode bit is “user”\nWhen kernel code is executing → mode bit is “kernel”\n\nSystem call changes mode to kernel, return from call resets it to user\nSome instructions are only executable in kernel mode"
  },
  {
    "objectID": "day3.html#system-calls",
    "href": "day3.html#system-calls",
    "title": "CSC 453",
    "section": "System calls",
    "text": "System calls\n\nThe OS offers a number of services. How do we (applications) interface with them?\n\nWe don’t want to deal with the details, just the abstraction\nThe OS has ultimate control over these operations\n\nSystem calls are the “language” of communication with the OS\nStandards\n\nWin32 (MS)\nPOSIX (nearly all Unix-based systems)\nJava API for the JVM"
  },
  {
    "objectID": "day3.html#system-calls-contd",
    "href": "day3.html#system-calls-contd",
    "title": "CSC 453",
    "section": "System calls (cont’d)",
    "text": "System calls (cont’d)\n\nLike a function call, we push arguments onto the stack, then we call into the library that provides the system call\nEach system call has a special number, placed into a register\nExecutes a TRAP instruction (switch to kernel mode)\nA logical separation of memory space\nKernel’s system call handler is invoked, once done (but may block) may be returned to the process"
  },
  {
    "objectID": "day3.html#system-calls-contd-1",
    "href": "day3.html#system-calls-contd-1",
    "title": "CSC 453",
    "section": "System calls (cont’d)",
    "text": "System calls (cont’d)\n\nTable defined in the kernel: https://github.com/torvalds/linux/blob/master/arch/x86/entry/ syscalls/syscall_32.tbl\n\nNote that system call tables can differ between architectures\n\nYou can run using the table values themselves using the syscall() wrapper\n\nQ: why does syscall() exist?\nIf you’re interested… There are debates https://lwn.net/Articles/771441/"
  },
  {
    "objectID": "day3.html#section",
    "href": "day3.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day3.html#questions-to-consider-1",
    "href": "day3.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat do processes contain?\nHow does the OS run multiple processes at the same time?\nHow are processes laid out in memory?\nHow does the OS store information about each process?"
  },
  {
    "objectID": "day3.html#processes",
    "href": "day3.html#processes",
    "title": "CSC 453",
    "section": "Processes",
    "text": "Processes\n\nMost fundamental OS abstraction\n\nProcesses organize information about other abstractions and represent a single thing the computer is “doing”\n\nWhen you run an executable program (passive), the OS creates a process == a running program (active)\nOne program can be multiple processes"
  },
  {
    "objectID": "day3.html#process-organization",
    "href": "day3.html#process-organization",
    "title": "CSC 453",
    "section": "Process organization",
    "text": "Process organization\n\n\n\nUnlike threads, address spaces and files, processes are not tied to a hardware component. Instead, they contain other abstractions\nProcesses contain:\n\none or more threads,\nan address space, and\nzero or more open file handles representing files"
  },
  {
    "objectID": "day3.html#multiprogramming",
    "href": "day3.html#multiprogramming",
    "title": "CSC 453",
    "section": "Multiprogramming",
    "text": "Multiprogramming\n\nProcesses are the core abstraction that allows for multiprogramming: the illusion of concurrency\nOS timeshares CPU across multiple processes: virtualizes CPU\nOS has a CPU scheduler that picks one of the many active processes to execute on a CPU\nPolicy:\n\nwhich process to run\n\nMechanism:\n\nhow to context switch between processes"
  },
  {
    "objectID": "day3.html#processs-view-of-the-world",
    "href": "day3.html#processs-view-of-the-world",
    "title": "CSC 453",
    "section": "Process’s view of the world",
    "text": "Process’s view of the world\n\n\n\nOwn memory with consistent addressing (divorced from physical addressing)\nIt has exclusivity over the CPU: It doesn’t have to worry about scheduling\nConversely, it doesn’t know when it will be scheduled, so real time events require special handling\nHas some identity: pid, gid, uid\nHas a set of services available to it via the OS\n\nData (via file system)\nCommunication (sockets, IPC)\nMore resources (e.g., memory)"
  },
  {
    "objectID": "day3.html#process-memory-layout",
    "href": "day3.html#process-memory-layout",
    "title": "CSC 453",
    "section": "Process memory layout",
    "text": "Process memory layout\n\n\n\nText segment: machine instructions; shareable between identical processes; read-only\nData segment: for initialized data; e.g., int count = 99;\nBSS (block started by symbol) segment: uninitialized data; e.g., int sum[10];\nHeap: dynamic memory allocation\nStack: initial arguments and environment; stack frames"
  },
  {
    "objectID": "day3.html#oss-view-of-the-process-world",
    "href": "day3.html#oss-view-of-the-process-world",
    "title": "CSC 453",
    "section": "OS’s view of the (process) world",
    "text": "OS’s view of the (process) world\n\n\n\nData for each process is held in a data structure known as a Process Control Block\nPartitioned memory:\n\ndedicated & shared address space\n\nperhaps non-contiguous\n\nProcess table holds PCBs"
  },
  {
    "objectID": "day3.html#section-1",
    "href": "day3.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day3.html#questions-to-consider-2",
    "href": "day3.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the different process states and what causes transitions?\nWhat is a context switch?\nWhat are the two general categories of processes and how do they differ?"
  },
  {
    "objectID": "day3.html#process-states",
    "href": "day3.html#process-states",
    "title": "CSC 453",
    "section": "Process states",
    "text": "Process states\n\nAs a process executes, it changes state\n\nNew: The process is being created\nRunning: Instructions are being executed\nWaiting: The process is waiting for some event (typically I/O or signal handling) to occur\nReady: The process is waiting to be assigned to a processor\nTerminated: The process has finished execution"
  },
  {
    "objectID": "day3.html#process-state-transitions",
    "href": "day3.html#process-state-transitions",
    "title": "CSC 453",
    "section": "Process state transitions",
    "text": "Process state transitions"
  },
  {
    "objectID": "day3.html#process-state-transitions-contd",
    "href": "day3.html#process-state-transitions-contd",
    "title": "CSC 453",
    "section": "Process state transitions (cont’d)",
    "text": "Process state transitions (cont’d)\n\n\n\nRunning process can move from running to terminated (exit or killed), moved to ready (time slice up), or blocked (signaled to wait, I/O)\nWhich state transitions could happen with these expensive actions?\n\nCompute a new RSA key?\nFind the largest value in a 1TB of data?\n\n\n\n\n\n\n\n\n\nRunning to Waiting: This transition occurs when a process cannot continue executing until a specific event occurs. Here are some examples:\n\nI/O Operations:\n\nExample: A process needs to read data from a disk. It issues an I/O request and then moves to the Waiting state until the data is read and available.\nReal-World Scenario: A web server process waiting for data to be read from a database.\n\nResource Availability:\n\nExample: A process requires a resource (like a printer) that is currently in use by another process. It moves to the Waiting state until the resource becomes available.\nReal-World Scenario: A document editing application waiting for access to a shared printer.\n\nInter-Process Communication (IPC):\n\nExample: A process is waiting for a message from another process. It moves to the Waiting state until the message is received.\nReal-World Scenario: A chat application waiting for a message from a server.\n\nSynchronization Primitives:\n\nExample: A process is waiting for a lock or semaphore to be released by another process. It moves to the Waiting state until the lock is available.\nReal-World Scenario: A banking application waiting for a transaction lock to be released.\n\n\nRunning to Ready: This transition occurs when a process is preempted by the scheduler, but it is still ready to run as soon as it gets CPU time again. Here are some examples:\n\nTime Slice Expiration:\n\nExample: A process has used up its allocated time slice. The scheduler preempts it and moves it to the Ready state, allowing another process to run.\nReal-World Scenario: A video streaming application being preempted to allow a background update process to run.\n\nHigher Priority Process:\n\nExample: A higher priority process becomes ready to run. The scheduler preempts the current process and moves it to the Ready state.\nReal-World Scenario: An emergency alert system preempting a running media player application.\n\nVoluntary Yield:\n\nExample: A process voluntarily yields the CPU, indicating it can be preempted. The scheduler moves it to the Ready state.\nReal-World Scenario: A background data synchronization process yielding the CPU to allow a user-initiated task to run."
  },
  {
    "objectID": "day3.html#process-scheduling",
    "href": "day3.html#process-scheduling",
    "title": "CSC 453",
    "section": "Process scheduling",
    "text": "Process scheduling\n\nOS process scheduler selects among available processes for next execution on CPU core\nGoal?\n\nMaximize CPU use, quickly switch processes onto CPU core\n\nMaintains scheduling queues of processes\n\nReady queue: set of all processes residing in main memory, ready and waiting to execute\nWait queues: set of processes waiting for an event (i.e., I/O)\n\nProcesses migrate among the various queues over their lifetime"
  },
  {
    "objectID": "day3.html#context-switching",
    "href": "day3.html#context-switching",
    "title": "CSC 453",
    "section": "Context switching",
    "text": "Context switching\n\nWhen CPU switches to another process, the system must save the state of the old process and load the saved state for the new process via a context switch\nContext of a process represented in the PCB\nContext-switch time is pure overhead; the system does no useful work while switching\n\nThe more complex the OS and the PCB → the longer the context switch\n\nTime dependent on hardware support\n\nSome hardware provides multiple sets of registers per CPU → multiple contexts loaded at once"
  },
  {
    "objectID": "day3.html#context-switching-overhead",
    "href": "day3.html#context-switching-overhead",
    "title": "CSC 453",
    "section": "Context switching overhead",
    "text": "Context switching overhead\n\nOn the order of milliseconds\nIf not done intelligently, you can spend more time context-switching than actual processing\nQuestion: Why shouldn’t processes control context switching?\n\n\n\nThey could refuse to give up CPU (processes are greedy)\nThey’re intentionally isolated, and don’t have enough information about other processes\nIt would cause too much complication (every process would have to implement its own context switch code)"
  },
  {
    "objectID": "day3.html#scheduling-basics",
    "href": "day3.html#scheduling-basics",
    "title": "CSC 453",
    "section": "Scheduling basics",
    "text": "Scheduling basics\n\nScheduler usually makes the transition decisions; hides the details from the process/user\nProcesses often characterized as one of two types by what state they spend most of their time in\n\nI/O bound: work is dependent on I/O; e.g., browser, db, media streaming\nCPU bound: work is dependent on CPU; e.g., scientific apps, cryptography\nWhy does this matter?\n\nUnderstanding which your process is allows for optimization\n\nCPU-bound? Faster CPU, parallelize.\nI/O? Faster I/O devices, use async\n\n\n\nScheduler must balance CPU- & I/O-bound processes\n\nReminder: the goal is to maximize CPU utilization"
  },
  {
    "objectID": "day3.html#aside-multiprocessing-in-mobile",
    "href": "day3.html#aside-multiprocessing-in-mobile",
    "title": "CSC 453",
    "section": "Aside: multiprocessing in mobile",
    "text": "Aside: multiprocessing in mobile\n\nSome mobile systems (e.g., early versions of iOS) allow only one process to run, others suspended\nDue to screen real estate, user interface limits iOS provides:\n\nSingle foreground process controlled via user interface\nMultiple background processes in memory, running, but not on the display, and with limits\n\nLimits include single, short task, receiving notification of events, specific long-running tasks like audio playback\n\n\nAndroid runs foreground and background, with fewer limits\n\nBackground process uses a service to perform tasks\nService can keep running even if background process is suspended\nService has no user interface, small memory use"
  },
  {
    "objectID": "day3.html#section-2",
    "href": "day3.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day2.html#admin",
    "href": "day2.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nQuiz 1 due Friday\n\nNOTE: this first quiz allows unlimited attempts. The rest will not.\n\nLab 1 due Monday\nAssignment 1 due Jan 19\n\nI’ll talk a bit about this during lab today\n\nI realize this seem like a lot, but time is short"
  },
  {
    "objectID": "day2.html#questions-to-consider",
    "href": "day2.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the main abstractions OSes provide?\nWhat are the abstraction challenges?"
  },
  {
    "objectID": "day2.html#abstractions",
    "href": "day2.html#abstractions",
    "title": "CSC 453",
    "section": "Abstractions",
    "text": "Abstractions\n\nAbstractions simplify application design by:\n\nhiding undesirable properties,\nadding new capabilities, and\norganizing information\n\nAbstractions provide an interface to application programmers that separates policy—what the interface commits to accomplishing—from mechanism—how the interface is implemented."
  },
  {
    "objectID": "day2.html#what-are-the-abstractions",
    "href": "day2.html#what-are-the-abstractions",
    "title": "CSC 453",
    "section": "What are the abstractions?",
    "text": "What are the abstractions?\n\nCPUs\n\nProcesses, threads\n\nMemory\n\nAddress space\n\nDisk\n\nFiles"
  },
  {
    "objectID": "day2.html#example-os-abstraction-file-systems",
    "href": "day2.html#example-os-abstraction-file-systems",
    "title": "CSC 453",
    "section": "Example OS abstraction: file systems",
    "text": "Example OS abstraction: file systems\n\nWhat undesirable properties do file systems hide?\n\nDisks are slow!\nChunks of storage are actually distributed all over the disk\nDisk storage may fail!\n\nWhat new capabilities do files add?\n\nGrowth and shrinking\nOrganization into directories, searchability\n\nWhat information do files help organize?\n\nOwnership and permissions\nAccess time, modification time, type, etc."
  },
  {
    "objectID": "day2.html#abstraction-tradeoffs---discussion",
    "href": "day2.html#abstraction-tradeoffs---discussion",
    "title": "CSC 453",
    "section": "Abstraction tradeoffs - discussion",
    "text": "Abstraction tradeoffs - discussion\n\nIdentify undesirable properties hidden by, new capabilities added, and info organization provided with these abstractions:\n\nProcess / threads\nAddress space\n\n\n\nProcesses/Threads\n\nHiding undesirable properties:\n\nExample: The process abstraction hides the complexity of CPU scheduling and context switching. Applications don’t need to manage the low-level details of how the CPU switches between different tasks. Similarly, the thread abstraction hides the intricacies of managing multiple execution paths within a single process, allowing developers to focus on the logic of concurrent tasks.\n\nAdding new capabilities:\n\nExample: Processes provide isolation between different applications, ensuring that one misbehaving application doesn’t affect others. Threads within a process allow for parallel execution of tasks, improving performance and responsiveness. Additionally, operating systems often provide inter-process communication (IPC) mechanisms, enabling processes to coordinate and share data.\n\nOrganizing information:\n\nExample: The process abstraction organizes the execution environment by encapsulating the code, data, and resources needed for a program to run. Threads further organize execution by dividing tasks within a process into smaller, manageable units. This organization helps in structuring complex applications and improving their maintainability.\n\n\nMemory Address Space\n\nHiding undesirable properties:\n\nExample: The memory address space abstraction hides the physical memory layout from applications. Programs use virtual addresses, which the operating system maps to physical memory locations. This abstraction also hides the details of memory fragmentation and allocation, simplifying memory management for developers.\n\nAdding new capabilities:\n\nExample: Virtual memory allows applications to use more memory than physically available by swapping data to and from disk. This capability enables larger and more complex applications to run on systems with limited physical memory. Additionally, memory protection mechanisms prevent one process from accessing the memory of another, enhancing system stability and security.\n\nOrganizing information:\n\nExample: The memory address space abstraction organizes memory into segments such as code, data, heap, and stack. This organization helps in managing different types of data efficiently and ensures that memory is used in a structured manner. For instance, the stack is used for function calls and local variables, while the heap is used for dynamic memory allocation."
  },
  {
    "objectID": "day2.html#abstraction-pros-cons",
    "href": "day2.html#abstraction-pros-cons",
    "title": "CSC 453",
    "section": "Abstraction pros / cons",
    "text": "Abstraction pros / cons\n\nAdvantages of OS providing abstractions?\n\nAllow applications to reuse common facilities\nMake different devices look the same\nProvide higher-level or more useful functionality\n\nChallenges?\n\nWhat are the correct abstractions?\nHow much should be exposed?"
  },
  {
    "objectID": "day2.html#os-design-requirements---what-do-we-need",
    "href": "day2.html#os-design-requirements---what-do-we-need",
    "title": "CSC 453",
    "section": "OS design requirements - what do we need?",
    "text": "OS design requirements - what do we need?\n\nConvenience, abstraction of hardware resources for user programs\nEfficiency of usage of CPU, memory, etc.\nIsolation between multiple processes\nReliability, the OS must not fail\nOther:\n\nSecurity\nMobility"
  },
  {
    "objectID": "day2.html#section",
    "href": "day2.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day2.html#questions-to-consider-1",
    "href": "day2.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow does the OS manage access to resources?"
  },
  {
    "objectID": "day2.html#os-as-a-resource-manager",
    "href": "day2.html#os-as-a-resource-manager",
    "title": "CSC 453",
    "section": "OS as a resource manager",
    "text": "OS as a resource manager\n\nAnother view: resource manager - shares resources “well”\nAdvantages of the OS managing resources?\n\nProtect applications from one another\nProvide efficient access to resources (cost, time, energy)\nProvide fair access to resources\n\nChallenges?\n\nWhat are the correct mechanisms?\nWhat are the correct policies?"
  },
  {
    "objectID": "day2.html#resources-are-managed-via-services",
    "href": "day2.html#resources-are-managed-via-services",
    "title": "CSC 453",
    "section": "Resources are managed via services",
    "text": "Resources are managed via services\n\nProgram Execution (loading, running, monitoring, terminating)\nPerformance (optimizing resources under constraints)\nCorrectness (overseeing critical operations, preventing interference)\nFairness (access to and allocation of resources)\nError detection & recovery (network partition & media failure)"
  },
  {
    "objectID": "day2.html#services-contd",
    "href": "day2.html#services-contd",
    "title": "CSC 453",
    "section": "Services (cont’d)",
    "text": "Services (cont’d)\n\nCommunication (inter-process, software-to-hardware, hardware-to-hardware, system-to-system, wide-area)\nI/O: reading & writing, support for various mediums, devices, performance, and protections\nData Organization (naming), Services (search) & Protection (access control)\nSecurity (isolation, enforcement, services, authentication, accounting and logging, trust)\nUser interfaces (command-line, GUIs, multiple users)"
  },
  {
    "objectID": "day2.html#each-service-has-challenges-and-tensions",
    "href": "day2.html#each-service-has-challenges-and-tensions",
    "title": "CSC 453",
    "section": "Each service has challenges and tensions",
    "text": "Each service has challenges and tensions\nExample 1: We have limited RAM, and we want to run more programs that can be stored.\n\nHow do we allocate space?\nWho stays?\nWho goes?\nWhat if we’re wrong?\nWhat if the system is under extremely heavy load?\nIs there a way to predict the future?"
  },
  {
    "objectID": "day2.html#each-service-has-challenges-and-tensions-1",
    "href": "day2.html#each-service-has-challenges-and-tensions-1",
    "title": "CSC 453",
    "section": "Each service has challenges and tensions",
    "text": "Each service has challenges and tensions\nExample 2: We have two process (producer / consumer); how do they communicate?\n\nMessage passing? Shared memory?\nHow do they synchronize?\n\nHow to we prevent over-production? Over-consumption?\nContext-switching?"
  },
  {
    "objectID": "day2.html#section-1",
    "href": "day2.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day2.html#questions-to-consider-2",
    "href": "day2.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat is the chain of events that takes place before you are able to run a process?\nWhere do the different parts of the chain reside? How are they called?"
  },
  {
    "objectID": "day2.html#boot-is-like-a-relay-race",
    "href": "day2.html#boot-is-like-a-relay-race",
    "title": "CSC 453",
    "section": "Boot is like a relay race",
    "text": "Boot is like a relay race\n\nA sequence of programs\nEach stage:\n\nHas slightly more power\nLoads the next stage\nJumps to it"
  },
  {
    "objectID": "day2.html#power-on",
    "href": "day2.html#power-on",
    "title": "CSC 453",
    "section": "Power-On",
    "text": "Power-On\n\nCPU resets\nInstruction pointer set to a fixed address\nExecution begins in firmware (ROM)\nThe CPU does not know what an OS is"
  },
  {
    "objectID": "day2.html#firmware-bios-uefi",
    "href": "day2.html#firmware-bios-uefi",
    "title": "CSC 453",
    "section": "Firmware (BIOS / UEFI)",
    "text": "Firmware (BIOS / UEFI)\n\nInitializes RAM\nInitializes minimal hardware\nFinds one program to run (bootloader)\nLoads it into memory\nJumps to it"
  },
  {
    "objectID": "day2.html#bootloaders-job-grub-example",
    "href": "day2.html#bootloaders-job-grub-example",
    "title": "CSC 453",
    "section": "Bootloader’s job (GRUB Example)",
    "text": "Bootloader’s job (GRUB Example)\n\nUnderstand filesystems\nLoad the kernel image\nLoad the initramfs\nPass arguments to the kernel\nJump to the kernel entry point\nProvides kernel command line args\nroot=/dev/sda1\ninit=/sbin/init\nconsole=ttyS0"
  },
  {
    "objectID": "day2.html#what-the-bootloader-does-not-do",
    "href": "day2.html#what-the-bootloader-does-not-do",
    "title": "CSC 453",
    "section": "What the bootloader does not do",
    "text": "What the bootloader does not do\n\nDoes not schedule processes\nDoes not manage memory long-term\nDoes not run the OS"
  },
  {
    "objectID": "day2.html#kernel",
    "href": "day2.html#kernel",
    "title": "CSC 453",
    "section": "Kernel",
    "text": "Kernel\nThink of the kernel in phases\n\nSelf-setup\nHardware abstraction\nUserspace handoff"
  },
  {
    "objectID": "day2.html#kernel-self-setup",
    "href": "day2.html#kernel-self-setup",
    "title": "CSC 453",
    "section": "Kernel self-setup",
    "text": "Kernel self-setup\n\nSets up page tables\nEnables virtual memory\nInitializes scheduler\nSets up interrupts\n\n\nThe kernel cannot rely on anything yet: it is building the world."
  },
  {
    "objectID": "day2.html#kernel-hardware-abstractions",
    "href": "day2.html#kernel-hardware-abstractions",
    "title": "CSC 453",
    "section": "Kernel hardware abstractions",
    "text": "Kernel hardware abstractions\nThis is where hardware becomes an abstraction.\n\nDetects hardware\nLoads drivers\nTurns devices into files:\n\n/dev/sda\n/dev/tty\n\nCreates kernel threads"
  },
  {
    "objectID": "day2.html#userspace-handoff",
    "href": "day2.html#userspace-handoff",
    "title": "CSC 453",
    "section": "Userspace handoff",
    "text": "Userspace handoff\n\nMounts the root filesystem\nChooses one program to run\nExecutes it with execve()\nexecve(\"/sbin/init\", ...);"
  },
  {
    "objectID": "day2.html#init-pid-1",
    "href": "day2.html#init-pid-1",
    "title": "CSC 453",
    "section": "Init (PID 1)",
    "text": "Init (PID 1)\n\nFirst userspace process\nAlways PID 1\nParent of all other processes\n\n\nIf PID 1 exits?\n\nThe kernel panics or shuts down"
  },
  {
    "objectID": "day2.html#section-2",
    "href": "day2.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day2.html#questions-to-consider-3",
    "href": "day2.html#questions-to-consider-3",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the different kernel paradigms?\nWhy would you choose one over the other?"
  },
  {
    "objectID": "day2.html#paradigms",
    "href": "day2.html#paradigms",
    "title": "CSC 453",
    "section": "Paradigms",
    "text": "Paradigms\n\nThe OS offers a number of services. What should go in the kernel?\n\nIPC\nVFS\nFile system\nScheduler\nVirtual Memory\nDevice drivers"
  },
  {
    "objectID": "day2.html#monolithic-kernels",
    "href": "day2.html#monolithic-kernels",
    "title": "CSC 453",
    "section": "Monolithic kernels",
    "text": "Monolithic kernels\n\nOldest, very common design (Linux, Windows 9x, BSDs)\nSingle piece of code in memory\nLimited information hiding\n\nOne part of the kernel can directly access data and functions of other parts"
  },
  {
    "objectID": "day2.html#monolithic-kernels-contd",
    "href": "day2.html#monolithic-kernels-contd",
    "title": "CSC 453",
    "section": "Monolithic kernels (cont’d)",
    "text": "Monolithic kernels (cont’d)\n\nQ: What happens when you need something new supported (new hardware device, new system call, new filesystem)?\nModules (loadable kernel modules - LKMs) allow for flexibility, customization, support\n\nPros?\n\nMemory savings\nFlexibility\nMinimal downtime\n\nCons?\n\n(minor) fragmentation: the base kernel can be loaded contiguously in memory\nSecurity (https://github.com/m0nad/Diamorphine DO NOT USE THIS, IT’S SIMPLY TO SHOW YOU)"
  },
  {
    "objectID": "day2.html#layered-kernels",
    "href": "day2.html#layered-kernels",
    "title": "CSC 453",
    "section": "Layered kernels",
    "text": "Layered kernels\n\nDijkstra created the THE OS in the 60s, introducing the concept Each inner layer is more privileged; required a trap to move down layers\nHardware-enforcement possible\nIntel announced in May 2024 that the new architectures will only have rings 0 and 3"
  },
  {
    "objectID": "day2.html#microkernels",
    "href": "day2.html#microkernels",
    "title": "CSC 453",
    "section": "Microkernels",
    "text": "Microkernels\n\n\n\nPopular research area long ago, didn’t win (although people remain interested in the principles)\nAll non-essential components removed from the kernel, for modularization, extensibility, isolation, security, and ease of management\nA collection of OS services running in user space\nDownsides?\n\nHeavy communication costs through message passing (marshaled through the kernel)"
  },
  {
    "objectID": "day2.html#monolithic-vs-microkernel",
    "href": "day2.html#monolithic-vs-microkernel",
    "title": "CSC 453",
    "section": "Monolithic vs Microkernel",
    "text": "Monolithic vs Microkernel"
  },
  {
    "objectID": "day2.html#section-3",
    "href": "day2.html#section-3",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day10.html#admin",
    "href": "day10.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nProgram 3: we need to cover page replacement first (should be Thursday)\n\nIt’s in C or python, your choice"
  },
  {
    "objectID": "day10.html#swapping",
    "href": "day10.html#swapping",
    "title": "CSC 453",
    "section": "Swapping",
    "text": "Swapping\n\nSwapping allows an entire process to be moved from main memory to a backing store (like disk)\nQ: Why swap?\n\nCan run far more processes than RAM can handle\n\nQ: When do we swap?\n\nWhen we want to run more processes than can fit into physical memory\n\nQ: When swapping back in, where does the process go?\n\nDepends on the memory binding\nIf runtime, then it can go anywhere (maximum flexibility)"
  },
  {
    "objectID": "day10.html#swapping-caveats",
    "href": "day10.html#swapping-caveats",
    "title": "CSC 453",
    "section": "Swapping caveats",
    "text": "Swapping caveats\n\nRemember though: disk is very slow, so we must be careful and clever about who, how, and when we swap\n\nThe amount of time we spend swapping is directly proportional to the amount of memory we want to swap\nTransfer time dominates (not context switching)\n\nThe state of a process matters\n\nE.g. if it’s blocked on I/O, we may 1) further delay the I/O by using the disk to swap, 2) a direct I/O request may return to the wrong process\nPrograms are growing larger, so quite expensive to swap\n\ne.g. 1GB program ~10 sec per swap to a spinning disk\n\n\nIn reality: we don’t really swap entire processes; too costly and unnecessary\n\nWe can swap pages, we’ll talk about this later"
  },
  {
    "objectID": "day10.html#section",
    "href": "day10.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day10.html#questions-to-consider",
    "href": "day10.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow do we keep track of free memory and decide where to place processes?\nWhat problems arise from fragmentation, and how can we address them?\nWhat are the trade-offs between different allocation strategies?"
  },
  {
    "objectID": "day10.html#memory-allocation-strategies",
    "href": "day10.html#memory-allocation-strategies",
    "title": "CSC 453",
    "section": "Memory allocation strategies",
    "text": "Memory allocation strategies\n\nHow do we find free memory for processes?\nHow do we keep track of free memory?\nHow do we decide which free block to allocate to a process?"
  },
  {
    "objectID": "day10.html#contiguous-allocation-1",
    "href": "day10.html#contiguous-allocation-1",
    "title": "CSC 453",
    "section": "Contiguous allocation",
    "text": "Contiguous allocation\n\nMemory is allocated in contiguous blocks\nOne approach: memory may be partitioned into fixed-sized partitions, each containing one process\n\nThis is very simple, but inflexible\nA fixed number of partitions means we can only run n processes, and the size of the partitions may not match the needs of the processes\n\nAnother approach: variable-sized partitions, where we allocate exactly as much memory as a process needs"
  },
  {
    "objectID": "day10.html#variable-partitioning",
    "href": "day10.html#variable-partitioning",
    "title": "CSC 453",
    "section": "Variable partitioning",
    "text": "Variable partitioning\n\nAny obvious problems with variable partitioning?\n\nExternal fragmentation: over time, as processes are loaded and unloaded, we can end up with small free blocks of memory that are not usable for new processes\n\nTo begin, we allocate memory for processes until none fit into any of the “holes”\nOnce there is no hole that is big enough to fit a process, what do we do?\n\nCan we rearrange memory to create enough space?\n\nCompaction: move processes around to create enough contiguous space for the new process\nThis is expensive"
  },
  {
    "objectID": "day10.html#allocation-strategies",
    "href": "day10.html#allocation-strategies",
    "title": "CSC 453",
    "section": "Allocation strategies",
    "text": "Allocation strategies\n\nHow do we decide which hole to use for a new process?\nFirst fit: allocate the first hole that is big enough\nBest fit: allocate the smallest hole that is big enough\nWorst fit: allocate the largest hole\nDownsides to these?\n\nFirst fit: can lead to fragmentation at the beginning of memory\nBest/worst fit: require full scan\nOne solution: Next fit: similar to first fit, but continues searching from the last allocated hole"
  },
  {
    "objectID": "day10.html#external-fragmentation",
    "href": "day10.html#external-fragmentation",
    "title": "CSC 453",
    "section": "External fragmentation",
    "text": "External fragmentation\n\nIdeally, we want all memory to be allocated, but\nIn reality, we’re left with many holes that are not one is big enough to allocate anything into\n\nAlthough, combined they may be\n\nAll the allocation strategies above can suffer from external fragmentation\nGenerally waste 1/3 of the average process size due to external frag using first-fit or best-fit\nOne solution: compaction, but this is expensive"
  },
  {
    "objectID": "day10.html#segmentation",
    "href": "day10.html#segmentation",
    "title": "CSC 453",
    "section": "Segmentation",
    "text": "Segmentation\n\nPrevious approaches have been focused on allocating contiguous blocks of memory, but what if we could allow processes to be allocated in non-contiguous segments?\nSegmentation divides a process’s address space into logical segments (e.g., code, data, stack) that can be allocated separately\nEach segment has a base and bounds, and the OS maintains a segment table for each process that maps virtual segment numbers to physical memory locations\nStill suffers from internal fragmentation if segments are not fully utilized\nCan also lead to external fragmentation, but less so than contiguous allocation since segments can be allocated in non-contiguous memory"
  },
  {
    "objectID": "day10.html#section-1",
    "href": "day10.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day10.html#questions-to-consider-1",
    "href": "day10.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow does paging eliminate external fragmentation while supporting multiple processes?\nHow does the hardware (MMU) translate virtual addresses to physical addresses?\nWhat information must the OS maintain to support paging?"
  },
  {
    "objectID": "day10.html#paging-1",
    "href": "day10.html#paging-1",
    "title": "CSC 453",
    "section": "Paging",
    "text": "Paging\n\nContiguous allocation schemes have many issues (particularly with finding / managing places to put processes), what should we do?\n\nBe non-contiguous!\n\nOf course this introduces many new challenges, but alas\n\n\nTo completely eliminate external fragmentation, we can use paging\n\nNon-contiguous memory allocation scheme that divides memory into fixed-size blocks called pages\nRequires hardware support (MMU) to translate virtual addresses to physical addresses using a page table"
  },
  {
    "objectID": "day10.html#paging-contd",
    "href": "day10.html#paging-contd",
    "title": "CSC 453",
    "section": "Paging (cont’d)",
    "text": "Paging (cont’d)\n\nJargon!\n\nPhysical memory is broken into fixed-sized regions: frames; logical memory is broken into fixed-sized regions: pages; backing store is also addressed as fixed-sized blocks\n\nThe paging system handles the mapping of pages to frames\nPages may be logically contiguous, whereas the backing frames and blocks are not\n~Typically |frames| = |pages| = |blocks|; typically between 512K-16MB\n\nMost common size is 4KB these days"
  },
  {
    "objectID": "day10.html#paging-contd-1",
    "href": "day10.html#paging-contd-1",
    "title": "CSC 453",
    "section": "Paging (cont’d)",
    "text": "Paging (cont’d)\n\n\n\nAddresses are divided into two parts: page number and page offset\n\nPage number is simply an index to a page\nOffset is for addressing within the given page\n\nRecall that the process point of view is using virtual addressing\n\nThis means we need to bolt address translation into this. What part of the address should we translate?\nPage number only. Offset remains the offset"
  },
  {
    "objectID": "day10.html#paging-contd-2",
    "href": "day10.html#paging-contd-2",
    "title": "CSC 453",
    "section": "Paging (cont’d)",
    "text": "Paging (cont’d)\n\nNow we need a directory to convert between virtual page numbers and physical page frames… The page table\n\nCan be any of a number of different data structures\nThe MMU uses the page table to perform address translation on every memory access\n\nMapping is completely transparent to the user / process. OS is in control of the page table\nPage tables are kept by OS for each process\n\nWhere should it be stored?\nPointer held in the PCB; more to deal with on context switch"
  },
  {
    "objectID": "day10.html#page-tables",
    "href": "day10.html#page-tables",
    "title": "CSC 453",
    "section": "Page tables",
    "text": "Page tables\n\n\n\n\\(2^m\\) is the size of the address space (in bytes), and page size is \\(2^n\\) bytes, then the higher \\(m-n\\) bits designate page number; \\(n\\) low-order bits are page offset\n\n\\(2^4\\) (this example) = 16 pages; page size \\(2^{12}\\) = 4K\n32-bit?\n\n\\(2^{20}\\) pages (1M), 4K pages = max 4GB RAM\n\n64-bit?\n\nWe’ll touch on it later, it isn’t (currently) \\(2^{52}\\)\n\n\n\n\n\n\n\n\n\nUsing n offset bits, we can address all 4096 bytes within the page"
  },
  {
    "objectID": "day10.html#examples",
    "href": "day10.html#examples",
    "title": "CSC 453",
    "section": "Examples",
    "text": "Examples\n\nA system uses a 32-bit virtual address and 8 bits are used for the offset within a page. How many pages? Size of each page? Total size?\n\n\\(2^{24}\\) pages (~16M), 256 byte pages, 4GB total\n\nVirtual address is 24 bits long. If 10 bits used for the page index.\n\n\\(2^{10}\\) = 1024 pages, \\(2^{14}\\) = 16KB pages, 16MB total size\n\nA system has 256 pages and each page is 8 KB.\n\n8 bits for index (\\(2^8\\) = 256), 13 bits for offset (\\(2^{13}\\) = 8KB), 21 bit total space = \\(2^{21}\\) = 2MB\n\nA system uses a 36-bit virtual address. If the page size is 4 KB\n\n\\(2^{24}\\) pages (16MB), 12-bit offset, ~64GB total"
  },
  {
    "objectID": "day10.html#page-tables-contd",
    "href": "day10.html#page-tables-contd",
    "title": "CSC 453",
    "section": "Page tables (cont’d)",
    "text": "Page tables (cont’d)\n\nPage Size\n\nDepends greatly on system usage\nSmaller provides granularity, but a larger page table, more overhead\nLarger increases throughput and minimizes disk I/O\n\nHow do pages affect fragmentation?\n\nNo external frag\nBut now we have internal fragmentation; unless a process is incredibly using some multiple of page size\nOn average: \\(1/2\\) page size per process"
  },
  {
    "objectID": "day10.html#page-table-entries",
    "href": "day10.html#page-table-entries",
    "title": "CSC 453",
    "section": "Page table entries",
    "text": "Page table entries\n\nPage table entry: what goes into one?\n\nPage frame number (obvi)\nPresent/absent bit: is the page frame number valid?\nProtection bits: What kinds of access are permitted\nModified/Dirty bit: Has this page been modified, perhaps needing to get written to disk before eviction\nReferenced bit: Has the page been referenced; used for eviction\nCaching disable bit: Is cache disabled for this page (for direct I/O)\n\nWhat doesn’t go into one?\n\nBacking store addresses: managed by the file system\nWe only want things needed for address translation by hardware"
  },
  {
    "objectID": "day10.html#paging-summary",
    "href": "day10.html#paging-summary",
    "title": "CSC 453",
    "section": "Paging summary",
    "text": "Paging summary\n\nPages allow us to:\n\nLoad processes at a finer granularity\nNot experience external fragmentation\nSwap at page granularity (often termed “paging” rather than “swapping”)\n\nBut leads us to have some questions:\n\nHow do I know which pages are in memory, and which are not?\nWhen I need to swap page, which go and which stay?\nHow do I know which pages contain modified data, and I need to write to disk?"
  },
  {
    "objectID": "day10.html#section-2",
    "href": "day10.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day10.html#questions-to-consider-2",
    "href": "day10.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat makes a good page replacement strategy, and why?\nHow can we approximate optimal page replacement without knowing the future?\nWhat are the practical implementation challenges for different page replacement algorithms?"
  },
  {
    "objectID": "day10.html#page-replacement-policies",
    "href": "day10.html#page-replacement-policies",
    "title": "CSC 453",
    "section": "Page replacement policies",
    "text": "Page replacement policies\n\nWhen a running process needs a page, but physical memory is full, we must evict a frame to make room; this is page replacement\nWhich frame do we evict?\nThe frame to evict is called the victim\n\nIn some cases, victims may be simply overwritten in memory. When would that make sense?\n\nIf they are read-only or haven’t been modified\n\nOr may need to be written to swap (because they have been modified)"
  },
  {
    "objectID": "day10.html#page-replacement-1",
    "href": "day10.html#page-replacement-1",
    "title": "CSC 453",
    "section": "Page replacement",
    "text": "Page replacement\n\nKeep in mind: Page replacement is a costly operation: at least two I/O operations, so its important to minimize\n\nIf we’re not careful in how we select our victims, we may further delay the system\n\nOddly enough, dirty pages may be good victims. Why?\n\nBecause it has to be written anyways\n\nPotential downside?\n\nIt forces the write which may have better optimized with other dirty blocks (potentially disallowing principle of locality benefits)\nDirty blocks also are indicative of activity"
  },
  {
    "objectID": "day10.html#page-replacement-algorithms-opt",
    "href": "day10.html#page-replacement-algorithms-opt",
    "title": "CSC 453",
    "section": "Page replacement algorithms: OPT",
    "text": "Page replacement algorithms: OPT\n\nOptimal Page Replacement (OPT)\n\nWe really want to evict the page that will not be used longest\nEach page could be labeled with the number of instructions that will be executed BEFORE page is referenced\nOf course, this is impossible (akin to SJF as optimal), but useful as a benchmark\nExample: RAM with 3 slots, following reference pattern:"
  },
  {
    "objectID": "day10.html#page-replacement-algorithms-fifo",
    "href": "day10.html#page-replacement-algorithms-fifo",
    "title": "CSC 453",
    "section": "Page replacement algorithms: FIFO",
    "text": "Page replacement algorithms: FIFO\n\nFirst-In-First-Out (FIFO)\nSimple: first page in (oldest) will be evicted\nDownsides?\n\nIndiscriminate of use: might throw out important pages\n\nCan lead to Belady’s anomaly: adding more frames can lead to more page faults\n\nWhy? Because it doesn’t consider use at all (the stack property)\nTry this reference pattern with 3 frames and then 4 frames to see the anomaly:"
  },
  {
    "objectID": "day10.html#page-replacement-algorithms-lru",
    "href": "day10.html#page-replacement-algorithms-lru",
    "title": "CSC 453",
    "section": "Page replacement algorithms: LRU",
    "text": "Page replacement algorithms: LRU\n\nWe can’t tell the future, what should we do?\n\nLook at the past\n\nLeast Recently Used (LRU)\n\nEach page has some age with respect to use; replace page that hasn’t been used in the longest time\nLike OPT, but only looking backwards\n\nUnfortunately, there is a chance that the page you evict is needed immediately"
  },
  {
    "objectID": "day10.html#lru-contd",
    "href": "day10.html#lru-contd",
    "title": "CSC 453",
    "section": "LRU (cont’d)",
    "text": "LRU (cont’d)\n\nLRU does not exhibit Belady’s anomaly\nHow can we implement LRU?\n\nCounters: each entry has an associated clock\n\nNo, waste of space, takes time to search\n\nOrdered queue\n\nLess space wasted, but a lot more memory accesses (pointers) to keep up-to-date\n\nBoth are impractical without specialized hardware\nWe can approximate LRU with a single bit in the page table entry: reference bit\n\nBit set when page is referenced\nBits set to zero initially and on context switch"
  },
  {
    "objectID": "day10.html#page-replacement-algorithms-others",
    "href": "day10.html#page-replacement-algorithms-others",
    "title": "CSC 453",
    "section": "Page replacement algorithms: others",
    "text": "Page replacement algorithms: others\n\nSecond Chance\n\nUse a FIFO queue and a reference bit\n\nIf bit is 0, replace the page\nIf bit is 1, set to 0 and move to the end of the queue\n\nDownside?\n\nMoving pages around is expensive\n\n\nClock\n\nPage frames in a circular list, and have a clock “hand” point to the newest page\nWhen evicting, look at page pointed to by hand\n\nIf reference bit is 0, replace page\nIf bit is 1, set to 0, and advance hand\n\nA nice approximation of LRU"
  },
  {
    "objectID": "day10.html#page-replacement-algorithms-others-contd",
    "href": "day10.html#page-replacement-algorithms-others-contd",
    "title": "CSC 453",
    "section": "Page replacement algorithms: others (cont’d)",
    "text": "Page replacement algorithms: others (cont’d)\n\nLeast Frequently Used\n\nKeep / increment counter for each page\nOne with lowest value\nDownside?\n\nIf something is used a lot at program startup, then no longer. Answer to this is aging\n\n\nMost Frequently Used\n\nSame as above only evict the page with highest value\nDownside?\n\nOne with the smallest value just arrived, yet to be used\n\n\nBoth are bad ideas. They do not approximate OPT and they are expensive"
  },
  {
    "objectID": "day10.html#page-replacement-algorithms-summary",
    "href": "day10.html#page-replacement-algorithms-summary",
    "title": "CSC 453",
    "section": "Page replacement algorithms: summary",
    "text": "Page replacement algorithms: summary\n\nOPT is optimal but impossible. LRU is a good approximation.\nMany different page replacement algorithms (many not covered here), with different performance characteristics and hardware requirements\ne.g., Linux: LRU 2Q\n\nTwo FIFO lists, each simulating the reference bit state\nNo hardware requirement\n\nNote that the concept of page replacement is seen at all interfaces of the memory hierarchy, just at different time scales; and, within certain applications\n\nWe focus on the disk/RAM interface because the difference in access time is so great"
  },
  {
    "objectID": "day10.html#section-3",
    "href": "day10.html#section-3",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day10.html#questions-to-consider-3",
    "href": "day10.html#questions-to-consider-3",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhy is page table size a critical concern for memory efficiency?\nHow can hardware support (like the TLB) improve address translation performance?\nWhat are the advantages and disadvantages of different page table storage locations?"
  },
  {
    "objectID": "day10.html#page-table-size",
    "href": "day10.html#page-table-size",
    "title": "CSC 453",
    "section": "Page table size",
    "text": "Page table size\n\nIf we have a 32-bit address space and 4KB pages, we have:\n\n\\(2^{20}\\) pages (1M)\nEach page table entry is typically 4 bytes\nTotal page table size = 4MB per process\nIf we have 100 processes, that’s 400MB just for page tables. Yikes\n\nWe’ll come back to this later. Bottom line: we do not use linear page tables (what we’ve talked about so far, e.g., the page table as an array)"
  },
  {
    "objectID": "day10.html#page-table-size-contd",
    "href": "day10.html#page-table-size-contd",
    "title": "CSC 453",
    "section": "Page table size (cont’d)",
    "text": "Page table size (cont’d)\n\nTo be efficient: we’re going to require some hardware support and clever structures\nWhy do we care?\n\nReason 1 (Speed): Translations must be done on every memory reference\nReason 2 (Cost): memory is getting larger:\n\n32-bit words, 4K page: 1 million entries at 4 bytes each = 4MB per process;\n64-bit words, 4K page: \\(2^{52}\\) entries at 8 bytes each = 30M GB (30 PB)"
  },
  {
    "objectID": "day10.html#page-table-access",
    "href": "day10.html#page-table-access",
    "title": "CSC 453",
    "section": "Page table access",
    "text": "Page table access\n\nWhere should the page table be stored?\n\nOld solution: registers and special hardware (not scalable)\nReal answer: in main memory\n\nPCB holds pointer to page table; context switch needs to account for this\n\nSee any downsides to this?\n\nIf the page table is large, it can consume a lot of memory\nRequires two memory accesses for each actual memory access (one for the page table, one for the data)\nHow do we speed this up?\n\nHardware"
  },
  {
    "objectID": "day10.html#translation-lookaside-buffer-tlb",
    "href": "day10.html#translation-lookaside-buffer-tlb",
    "title": "CSC 453",
    "section": "Translation lookaside buffer (TLB)",
    "text": "Translation lookaside buffer (TLB)\n\nUse associative memory\n\nCan someone tell me what’s special about associative (a.k.a. content-addressable) memory?\n\nParallel search: All key values can be queried at once; if found, value is returned\n\n\nComprised of key(tag)-value pairs\n\nUltimately it is a cache for the page table\n\nExpensive, so TLB only contains a small number of entries"
  },
  {
    "objectID": "day10.html#tlb-contd",
    "href": "day10.html#tlb-contd",
    "title": "CSC 453",
    "section": "TLB (cont’d)",
    "text": "TLB (cont’d)\n\n\n\nHow it works: logical address from CPU (say, a process is looking to load a variable stored at address 100 in its address space)\nIf it’s a miss (not in TLB); we must fetch the entry from the page table, perhaps replacing an existing entry\n\nsoft miss: page is in main memory\nhard miss: page is on disk (swapped, also known as a page fault)"
  },
  {
    "objectID": "day10.html#tlb-contd-1",
    "href": "day10.html#tlb-contd-1",
    "title": "CSC 453",
    "section": "TLB (cont’d)",
    "text": "TLB (cont’d)\n\nIf it’s a hit (in TLB), we can directly get the physical address and access memory\n\nTLB is fast enough that a hit results in one memory access (for the data), while a miss results in two memory accesses (one for the page table, one for the data)\n\nHit ratio determines effective access time\nExample: 80% hit rate; 10ns to access memory\n\nA hit = 10ns; a miss = 20ns\nEAT = \\((.8 * 10) + (.2 * 20) = 12ns\\)\n99% hit? = \\((.99 * 10) + (.01 * 20) = 10.1ns\\)\n\nWhat about processes that we’d like to keep in the TLB? (kernel)\n\n“Wired down” i.e., cannot be replaced"
  },
  {
    "objectID": "day10.html#tlb-contd-2",
    "href": "day10.html#tlb-contd-2",
    "title": "CSC 453",
    "section": "TLB (cont’d)",
    "text": "TLB (cont’d)\n\nWait, we have multiple processes with virtual addressing and one small TLB. What happens on a context switch?\n\nE.g., virtual page 1 for process one != virtual page 1 for process 2\n\nCould flush: empty on context switch\n\nDownside?\n\nYou lose a lot of the goodness of caching. Needs to be rebuilt every time\n\n\nOther idea?\n\nAddress-space identifiers (ASIDs) will bind TLB entries to a particular process\n\nPreventing a process from access a page that doesn’t belong to it, but allowing pages from multiple processes to coexist in the TLB"
  },
  {
    "objectID": "day10.html#section-4",
    "href": "day10.html#section-4",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day10.html#questions-to-consider-4",
    "href": "day10.html#questions-to-consider-4",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow can we organize page tables to handle large address spaces efficiently?\nWhat are the trade-offs between space overhead and lookup complexity?\nWhen and why would we choose alternative page table designs?"
  },
  {
    "objectID": "day10.html#page-table-structures-1",
    "href": "day10.html#page-table-structures-1",
    "title": "CSC 453",
    "section": "Page table structures",
    "text": "Page table structures\n\n\n\nLinear page tables are wasteful; particularly if you have a number of unused pages (likely)\nAnswer?\n\nMultilevel page tables"
  },
  {
    "objectID": "day10.html#multilevel-page-tables",
    "href": "day10.html#multilevel-page-tables",
    "title": "CSC 453",
    "section": "Multilevel page tables",
    "text": "Multilevel page tables\n\n\n\nExample: Two-level page table: Split the page table address into two\n\n10-bit PT1, 10-bit PT2, and 12-bit offset field\n\nTop level page table references 1024 2nd tier page tables\nEach 2nd tier page table references 1024, 4K pages\n\n\n\n\n\n\n\nBenefit?\n\n2nd tier tables need not be resident in memory if unused\n\\(2^{20}\\) addressable, with only 4 tables resident (16KB rather than 4MB)"
  },
  {
    "objectID": "day10.html#multilevel-page-tables-contd",
    "href": "day10.html#multilevel-page-tables-contd",
    "title": "CSC 453",
    "section": "Multilevel page tables (cont’d)",
    "text": "Multilevel page tables (cont’d)\n\n\n\nThis is expandable to more levels\n\nNote that 64-bit doesn’t use the full 64-bit\n48-bits allow us to address 256TB"
  },
  {
    "objectID": "day10.html#inverted-page-tables",
    "href": "day10.html#inverted-page-tables",
    "title": "CSC 453",
    "section": "Inverted page tables",
    "text": "Inverted page tables\n\n\n\nWhat we’ve seen so far: one page table per process\nAlternative: one page table for the entire system, with an entry for each frame of physical memory (inverted page table)\n\nEach entry contains the virtual address of the page stored in that frame, along with information about the process that owns that page\nEntry holds which pid owns the frame, and its virtual address"
  },
  {
    "objectID": "day10.html#inverted-page-tables-contd",
    "href": "day10.html#inverted-page-tables-contd",
    "title": "CSC 453",
    "section": "Inverted page tables (cont’d)",
    "text": "Inverted page tables (cont’d)\n\nReduces size, but increases lookup complexity\n\nmust do a full search of the page table (slow)\n\nWe can use a hash table to index into page table, or combine with a TLB to speed up frequent lookups\nNot commonly used in practice\n\nOnce RAM became cheaper, the size of page tables became less of an issue, and the complexity of inverted page tables outweighed their benefits"
  },
  {
    "objectID": "day10.html#section-5",
    "href": "day10.html#section-5",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day10.html#questions-to-consider-5",
    "href": "day10.html#questions-to-consider-5",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow does virtual memory enable processes to use more memory than physically available?\nWhat strategies can we use to determine which pages should be in memory at any given time?\nWhat problems occur when memory contention is too high, and how can we detect and prevent them?"
  },
  {
    "objectID": "day10.html#virtual-memory-summary-1",
    "href": "day10.html#virtual-memory-summary-1",
    "title": "CSC 453",
    "section": "Virtual memory summary",
    "text": "Virtual memory summary\n\nPrevious (naïve) discussions assumed that all of a process’s pages are present in memory when running\nVirtual Memory is system built around the main ideas supported by paging\nAllows the system to present a large, logically contiguous memory to every process, while being non-contiguous in physical memory\nSupported by pages + swap"
  },
  {
    "objectID": "day10.html#virtual-memory-summary-contd",
    "href": "day10.html#virtual-memory-summary-contd",
    "title": "CSC 453",
    "section": "Virtual memory summary (cont’d)",
    "text": "Virtual memory summary (cont’d)\n\nMany advantages\n\nProcesses see the same logical, contiguous address space, making programming easier\nLogical memory may be sparse; i.e. a hole in the logical space does not (necessarily) mean a hole in the physical space\nPages may be shared among processes (shared libraries, shared memory or fork()’d processes)\n\nLogical memory (for a single or many processes) may actually be bigger than physical memory"
  },
  {
    "objectID": "day10.html#memory-residency",
    "href": "day10.html#memory-residency",
    "title": "CSC 453",
    "section": "Memory residency",
    "text": "Memory residency\n\nNot all process pages can reside in memory at once; further, we many not need all pages in memory at once\nBut… we need a page to be in main memory to be accessed\nWe’ve talked about choosing victims to replace in memory, How do we select pages to be in main memory?"
  },
  {
    "objectID": "day10.html#demand-paging",
    "href": "day10.html#demand-paging",
    "title": "CSC 453",
    "section": "Demand paging",
    "text": "Demand paging\n\n\n\nWe can load pages into memory only when they are needed, which is called demand paging\nHere we see why the valid bit is useful\n\nValid implies “allocated and in memory”\nInvalid implies “not allocated or not in memory”"
  },
  {
    "objectID": "day10.html#demand-paging-contd",
    "href": "day10.html#demand-paging-contd",
    "title": "CSC 453",
    "section": "Demand paging (cont’d)",
    "text": "Demand paging (cont’d)\n\nIf process has a page fault, we trap to the OS, which\n\ninterrupts the process\nfinds a free frame (if one exists)\nrequests the block from the backing store or swap space\nbrings the page into memory\nupdates the page table\nrestarts the processes\n\nNon-resident pages may have never been in memory (so in the file system) or were once resident and swapped out (to swap space)"
  },
  {
    "objectID": "day10.html#pure-demand-paging",
    "href": "day10.html#pure-demand-paging",
    "title": "CSC 453",
    "section": "Pure demand paging",
    "text": "Pure demand paging\n\nMost extreme scheme\nIn pure demand paging, all pages are non-resident at the start of execution\nThis is not common in practice, as it can lead to a large number of page faults at the start of execution, which can significantly degrade performance"
  },
  {
    "objectID": "day10.html#working-set",
    "href": "day10.html#working-set",
    "title": "CSC 453",
    "section": "Working set",
    "text": "Working set\n\nTo mitigate the performance issues of pure demand paging, we can use the concept of a working set\nTakes advantage of the principle of locality: processes tend to access a relatively small set of pages over a short period of time\nWorking-set model:\n\nDefine a window \\(\\Delta\\) (most recent page references)\nIf a page is referenced within the window, it’s in the working set; otherwise, it’s not\n\nAllows for prepaging pages that are likely to be used soon, improving performance by reducing page faults\n\njust outside of the working set, the OS can see “the working set is expanding in this direction, so let’s prefetch some pages in that direction”"
  },
  {
    "objectID": "day10.html#thrashing",
    "href": "day10.html#thrashing",
    "title": "CSC 453",
    "section": "Thrashing",
    "text": "Thrashing\n\nIf the working set of a process exceeds the available physical memory, the process will experience a high rate of page faults, leading to a condition called thrashing\nWhen the page fault time exceeds the time spent executing, we are said to be thrashing\nProblem: CPU scheduler sees the decreasing CPU utilization and increases the degree of multiprogramming; makes thrashing worse\nSolutions?\n\nLocal replacement algorithm (each process can only select victims from its set of allocated frames)\n\ni.e. cannot steal frames from another process and cause the latter to thrash as well\nDecrease the degree of multiprogramming (reduce the number of processes)"
  },
  {
    "objectID": "day10.html#optimizing-shared-pages",
    "href": "day10.html#optimizing-shared-pages",
    "title": "CSC 453",
    "section": "Optimizing shared pages",
    "text": "Optimizing shared pages\n\nRemember how fork() and exec() work?\n\nFork leads to a copy of the parent’s address space\n… but exec() means that a lot of children immediately replace, making a copy wasteful\n\nWhat should we do?\n\nShare the pages initially\nIf either the parent or the child writes to the shared page, then you actually make a copy (copy-on-write)\nCopy-on-write significantly speeds up fork operation; particularly if they will soon exec"
  },
  {
    "objectID": "day10.html#huge-pages",
    "href": "day10.html#huge-pages",
    "title": "CSC 453",
    "section": "Huge pages",
    "text": "Huge pages\n\nAs we discussed, page tables can be large, and TLBs are small. This can lead to a high TLB miss rate, which can significantly degrade performance.\nOne solution is to use larger page sizes, known as huge pages\nBy using huge pages (e.g., 2MB instead of 4KB), we can reduce the number of pages, and thus the size of the page table, and increase the TLB hit rate\nNewer kernels support transparent huge pages, which automatically use huge pages when possible without requiring changes to applications\nDanger: internal fragmentation can be much worse with huge pages, so they are not ideal for all workloads"
  },
  {
    "objectID": "day10.html#linux-memory-security",
    "href": "day10.html#linux-memory-security",
    "title": "CSC 453",
    "section": "Linux memory security",
    "text": "Linux memory security\n\nLinux provides several features to enhance memory security, such as:\n\nAddress Space Layout Randomization (ASLR): randomizes the memory addresses used by a process, making it more difficult for attackers to predict where code or data is located\nKernel Address Space Layout Randomization (KASLR): randomizes the memory addresses used by the kernel\nData Execution Prevention (DEP): marks certain areas of memory as non-executable, preventing code from being executed from those regions (e.g., the stack)\n\nNX bit: hardware support for DEP held in the page table entry"
  },
  {
    "objectID": "day10.html#section-6",
    "href": "day10.html#section-6",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day4.html#admin",
    "href": "day4.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nQuiz 2 due Friday\nLab 2 due Monday\nSLOsh due Monday\nNo class/lab Tuesday"
  },
  {
    "objectID": "day4.html#questions-to-consider",
    "href": "day4.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhich system calls are related to process management and lifecycles?\nHow does the process hierarchy work?\nWhat are zombies and orphans? Why do zombies exist?"
  },
  {
    "objectID": "day4.html#unix-process-apis",
    "href": "day4.html#unix-process-apis",
    "title": "CSC 453",
    "section": "UNIX process APIs",
    "text": "UNIX process APIs\n\nfork() creates a new child process\n\nAll processes are created by forking from a parent\nThe init process is ancestor of all processes\n\nRun pstree in a terminal to see\n\n\nexec() makes a process execute a given executable (effectively replaces the process)\nexit() terminates a process\nwait() causes a parent to block until child terminates\nMany variants exist of the above system calls with different arguments"
  },
  {
    "objectID": "day4.html#what-happens-during-a-fork",
    "href": "day4.html#what-happens-during-a-fork",
    "title": "CSC 453",
    "section": "What happens during a fork()?",
    "text": "What happens during a fork()?\n\nA new process is created by making a copy of parent’s memory image\nBoth parent and child have unique address spaces (isolated from each other, allowing for independent processing)\nThe new process is added to the OS process list and scheduled\nParent and child start execution just after fork (with different return values)\nParent and child execute and modify the memory data independently"
  },
  {
    "objectID": "day4.html#process-management-1",
    "href": "day4.html#process-management-1",
    "title": "CSC 453",
    "section": "Process management",
    "text": "Process management"
  },
  {
    "objectID": "day4.html#process-creation",
    "href": "day4.html#process-creation",
    "title": "CSC 453",
    "section": "Process creation",
    "text": "Process creation\n\nDifferent execution models\n\nParent & child may execute independently\nParent may wait for child\nChild may create more children (Process hierarchies)\nParent may kill children\n\nChild often invokes exec() to change its memory image to a new program\nWhy two steps (fork() then exec())?\n\nAllows the child to change file descriptors and other settings before exec()"
  },
  {
    "objectID": "day4.html#process-destruction",
    "href": "day4.html#process-destruction",
    "title": "CSC 453",
    "section": "Process destruction",
    "text": "Process destruction\n\nSome operating systems do not allow child to exist if its parent has terminated. If a process terminates, then all its children must also be terminated\n\nCascading termination: All children, grandchildren, etc., are terminated.\nThe termination is initiated by the operating system\n\nThe parent process may wait for termination of a child process by using the wait() system call. The call returns status information and the pid of the terminated process\npid = wait(&status);"
  },
  {
    "objectID": "day4.html#zombies-and-orphans",
    "href": "day4.html#zombies-and-orphans",
    "title": "CSC 453",
    "section": "Zombies and orphans",
    "text": "Zombies and orphans\n\n\n\nIf no parent waiting (did not invoke wait()), and process completes, process is a zombie\n\nZombie = dead but not yet reaped (exit status hasn’t been read)\nStill has an entry in the process table\nWe need zombies: so the kernel can preserve a child’s exit status until the parent calls wait(), even if the child exits first\n\nIf parent terminated without invoking wait(), process is an orphan\n\nOrphan = alive but parent is gone\ninit benevolently adopts orphans\n\n\n\n\n\n\n\n\nChild exits → zombie\nParent exits → zombie becomes orphan\ninit adopts it → init calls wait() → zombie disappears"
  },
  {
    "objectID": "day4.html#section",
    "href": "day4.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day4.html#questions-to-consider-1",
    "href": "day4.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are namespaces and cgroups?\nHow do they differ from virtual machines?\nHow do containers use them to isolate processes?"
  },
  {
    "objectID": "day4.html#isolation-without-full-virtualization",
    "href": "day4.html#isolation-without-full-virtualization",
    "title": "CSC 453",
    "section": "Isolation without full virtualization",
    "text": "Isolation without full virtualization\n\nVirtual machines provide complete isolation by emulating entire hardware + OS\n\nHeavier resource overhead (multiple OS instances)\nBetter isolation between workloads\n\nContainers provide lightweight isolation using OS-level mechanisms\n\nShare the same kernel\nMuch lower overhead than VMs\nLinux kernel provides the building blocks: namespaces and cgroups"
  },
  {
    "objectID": "day4.html#namespaces-logical-isolation",
    "href": "day4.html#namespaces-logical-isolation",
    "title": "CSC 453",
    "section": "Namespaces: logical isolation",
    "text": "Namespaces: logical isolation\n\nNamespaces partition global system resources so they appear as separate isolated instances\nEach process belongs to a namespace and only sees resources in that namespace\nTypes of namespaces:\n\nPID: process IDs (what processes can a process see?)\nNetwork: network interfaces, ports, routing tables\nMount: filesystem mounts (what can a process access?)\nIPC: IPC objects, message queues\nUTS: hostname and domain name\nUser: user and group IDs (who owns the process?)"
  },
  {
    "objectID": "day4.html#namespaces-example",
    "href": "day4.html#namespaces-example",
    "title": "CSC 453",
    "section": "Namespaces example",
    "text": "Namespaces example\n\nTwo processes in separate PID namespaces think they are PID 1 (init)\nEach sees only processes within their own namespace\nFrom the host OS perspective, they have different global PIDs\nEnables the illusion that each container has its own isolated process tree"
  },
  {
    "objectID": "day4.html#seeing-namespaces-in-action",
    "href": "day4.html#seeing-namespaces-in-action",
    "title": "CSC 453",
    "section": "Seeing namespaces in action",
    "text": "Seeing namespaces in action\n\nView namespaces a process belongs to:\nls -l /proc/self/ns/\nUse unshare to create a new PID namespace:\nunshare -pf --mount-proc bash      # creates new PID namespace, your shell is PID 1\nps aux               # only sees processes in this namespace\nexit                 # back to host namespace\nps aux               # will show all processes on the host\nCompare namespace inodes before and after (same inode = same namespace):\nls -i /proc/self/ns/pid\nunshare -pf --mount-proc bash -c 'ls -i /proc/self/ns/pid'  # different inode"
  },
  {
    "objectID": "day4.html#cgroups-resource-limits",
    "href": "day4.html#cgroups-resource-limits",
    "title": "CSC 453",
    "section": "Cgroups: resource limits",
    "text": "Cgroups: resource limits\n\ncgroups (control groups) limit, prioritize, and account for resource usage of process groups\nKey capabilities:\n\nCPU limits: restrict how much CPU time a group can use\nMemory limits: cap memory usage; OOM killer invoked if exceeded\nI/O limits: restrict disk I/O bandwidth\nDevice access: restrict which devices a process can access\n\nAll processes in a cgroup share the same resource limitations"
  },
  {
    "objectID": "day4.html#seeing-cgroups-in-action",
    "href": "day4.html#seeing-cgroups-in-action",
    "title": "CSC 453",
    "section": "Seeing cgroups in action",
    "text": "Seeing cgroups in action\n\nView what cgroup a process belongs to:\ncat /proc/self/cgroup\nCheck your current limits:\ncat /proc/self/limits  # shows per-process limits (some enforced by cgroups)\nIn practice, cgroups are invisible to users, kernel enforces limits automatically when a process exceeds allocated resources"
  },
  {
    "objectID": "day4.html#cgroups-vs.-namespaces",
    "href": "day4.html#cgroups-vs.-namespaces",
    "title": "CSC 453",
    "section": "Cgroups vs. namespaces",
    "text": "Cgroups vs. namespaces\n\nNamespaces: about visibility—what can a process see?\n\nLogical isolation of resources\n\ncgroups: about limits—how much can a process use?\n\nResource accounting and enforcement\n\nTogether: processes appear isolated AND are prevented from consuming excessive resources"
  },
  {
    "objectID": "day4.html#containers-as-a-building-block",
    "href": "day4.html#containers-as-a-building-block",
    "title": "CSC 453",
    "section": "Containers as a building block",
    "text": "Containers as a building block\n\ncgroups and namespaces are mechanisms, containers allow us to apply policy through orchestration\nContainers (e.g. Docker) combine namespaces + cgroups + layered filesystems\nResults in lightweight, portable process isolation\nSingle kernel, multiple isolated environments\nMuch cheaper than VMs, but with less isolation guarantees"
  },
  {
    "objectID": "day4.html#section-1",
    "href": "day4.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day4.html#questions-to-consider-2",
    "href": "day4.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the two main strategies for IPC?\nHow do they differ?\nIn what situations would you choose one over the other?"
  },
  {
    "objectID": "day4.html#processes-give-us-a-protection-boundary",
    "href": "day4.html#processes-give-us-a-protection-boundary",
    "title": "CSC 453",
    "section": "Processes give us a protection boundary",
    "text": "Processes give us a protection boundary\n\nThe operating system is responsible for isolating processes from each other\nWhat you do in your own process is your own business but it shouldn’t be able to crash the machine or affect other processes, or at least processes started by other users\nThus: safe intra-process communication is your problem; safe inter-process communication is an operating system problem"
  },
  {
    "objectID": "day4.html#why-do-we-need-ipc-what-are-the-benefits",
    "href": "day4.html#why-do-we-need-ipc-what-are-the-benefits",
    "title": "CSC 453",
    "section": "Why do we need IPC? What are the benefits?",
    "text": "Why do we need IPC? What are the benefits?\n\nData Sharing: IPC allows processes to share data efficiently, which is crucial for applications requiring real-time data exchange\nModularity: It promotes modularity by enabling different parts of a system to communicate, making the system easier to manage and scale\nResource Utilization: IPC can help optimize resource utilization by allowing processes to coordinate their use of shared resources\nConcurrency (scalability): It supports concurrent execution of processes, improving the overall performance and responsiveness of applications"
  },
  {
    "objectID": "day4.html#what-are-the-disadvantages-of-ipc",
    "href": "day4.html#what-are-the-disadvantages-of-ipc",
    "title": "CSC 453",
    "section": "What are the disadvantages of IPC?",
    "text": "What are the disadvantages of IPC?\n\nComplexity: Implementing IPC can add complexity to the system, requiring careful design and management to avoid issues like deadlocks and race conditions\nOverhead: IPC mechanisms can introduce overhead, potentially impacting performance, especially if the communication is frequent or involves large amounts of data\nSecurity: Ensuring secure IPC can be challenging, as it involves protecting data from unauthorized access and ensuring the integrity of the communication\nDebugging: Debugging IPC-related issues can be difficult, as problems may arise from interactions between multiple processes, making them harder to isolate and resolve"
  },
  {
    "objectID": "day4.html#what-are-the-two-main-categories-of-ipc",
    "href": "day4.html#what-are-the-two-main-categories-of-ipc",
    "title": "CSC 453",
    "section": "What are the two main categories of IPC?",
    "text": "What are the two main categories of IPC?\n\nMessage passing\n\nHigh-level abstraction for exchanging packets of information over some interconnect\n\nShared memory\n\nRegion of memory available to different processes; writable by at least one process"
  },
  {
    "objectID": "day4.html#message-passing",
    "href": "day4.html#message-passing",
    "title": "CSC 453",
    "section": "Message passing",
    "text": "Message passing\n\nKernel establishes and oversees all communication\n\nProcess copies data to buffer, then issue system call to request transfer\nKernel copies data into its memory\nLater, process issues system call to retrieve\n\nTwo primitives: send() and recv()\nBeyond intra-computer communication, facilitates processes over a network; link implementation is unimportant"
  },
  {
    "objectID": "day4.html#pros-and-cons-of-message-passing",
    "href": "day4.html#pros-and-cons-of-message-passing",
    "title": "CSC 453",
    "section": "Pros and cons of message passing?",
    "text": "Pros and cons of message passing?\n\nPros:\n\nEasier to implement and manage, especially in distributed systems\nProvides clear boundaries between processes, enhancing security and modularity\n\nCons:\n\nCan introduce overhead due to the need for message formatting and transmission\nMay be slower compared to shared memory for large volumes of data"
  },
  {
    "objectID": "day4.html#shared-memory",
    "href": "day4.html#shared-memory",
    "title": "CSC 453",
    "section": "Shared memory",
    "text": "Shared memory\n\nKernel plays a role in establishing and attaching the address space, but does not control read/write access beyond that\nHow the memory is shared, and kept consistent, is left up to the processes"
  },
  {
    "objectID": "day4.html#pros-and-cons-of-shared-memory",
    "href": "day4.html#pros-and-cons-of-shared-memory",
    "title": "CSC 453",
    "section": "Pros and cons of shared memory?",
    "text": "Pros and cons of shared memory?\n\nPros:\n\nOffers high-speed data exchange, as processes can directly read and write to the shared memory\nEfficient for large volumes of data\n\nCons:\n\nRequires careful synchronization to avoid conflicts and ensure data consistency\nCan be more complex to implement and debug"
  },
  {
    "objectID": "day4.html#message-passing-vs.-shared-memory",
    "href": "day4.html#message-passing-vs.-shared-memory",
    "title": "CSC 453",
    "section": "Message passing vs. shared memory",
    "text": "Message passing vs. shared memory\n\n\n\nWhich do you choose?\n\nIf you have few messages?\nIf you have millions?\nIf you need to communicate across systems?\nIf you need in-order delivery but don’t want to code it yourself?\n\nConsiderations:\n\nCost to establish\nCost per message\n\n\n\n\n\n “Gemini, make an image in the style of a video game pitting pipes versus shared memory”"
  },
  {
    "objectID": "day4.html#section-2",
    "href": "day4.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day7.html#admin",
    "href": "day7.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nBreak from programming assignments this week\nMidterm results are on Gradescope, please submit all regrade requests by tomorrow (2/4/2026) at 23:59"
  },
  {
    "objectID": "day7.html#questions-to-consider",
    "href": "day7.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow do user threads and kernel threads relate?\nWhat are the different kernel thread models and how do they compare?\n\nWhen should you use each?"
  },
  {
    "objectID": "day7.html#first-things-first",
    "href": "day7.html#first-things-first",
    "title": "CSC 453",
    "section": "First things first",
    "text": "First things first\n\nA kernel thread is the unit of execution that the OS can run on a CPU core\nA process can only make progress if at least one of its kernel threads is scheduled on a core\nCPUs run kernel threads, not processes"
  },
  {
    "objectID": "day7.html#user-space-threads",
    "href": "day7.html#user-space-threads",
    "title": "CSC 453",
    "section": "User space threads",
    "text": "User space threads\n\nTotally unknown to the OS\nThread library manages thread table and scheduling\nContext switch is a function call within the process\nUser-level threads must “borrow” a kernel thread to run\nWhat happens when a pure user space thread makes an I/O-bound system call?\n\nAll threads will block, because the process is blocked\nSometimes a thread blocking a process is unavoidable: page fault: more later"
  },
  {
    "objectID": "day7.html#kernel-threads",
    "href": "day7.html#kernel-threads",
    "title": "CSC 453",
    "section": "Kernel threads",
    "text": "Kernel threads\n\nThread libraries can also have kernel support (this is the common case today)\nThere is no user space runtime environment or thread table: all is managed within the kernel\nSupport for multiple cores\nAll thread interfaces are system calls handled by the kernel"
  },
  {
    "objectID": "day7.html#kernel-threads-contd",
    "href": "day7.html#kernel-threads-contd",
    "title": "CSC 453",
    "section": "Kernel threads (cont’d)",
    "text": "Kernel threads (cont’d)\n\nInstead of blocking on a system call, the kernel now has the intelligence to schedule another thread\nCreating and destroying threads comes at a higher cost (a kernel TRAP)\n\nWhat should we do?\n\nThread pools: a collection of pre-allocated threads, assigned as needed"
  },
  {
    "objectID": "day7.html#thread-design-models-many-to-one-m1",
    "href": "day7.html#thread-design-models-many-to-one-m1",
    "title": "CSC 453",
    "section": "Thread design models: many-to-one (M:1)",
    "text": "Thread design models: many-to-one (M:1)\n\nKernel threads must support user level threads. There are multiple ways to pull this off\nMany-to-one\n\nA single kernel level thread supports many user level threads\nSwitching between threads is fast (done in user level)\nNo parallelism (kernel thread is supporting only a single user thread at a time)\nIf any user thread makes an I/O blocking call, all user threads in that process are blocked\n\nWhere does this make sense?\n\nIf you need complete control over scheduling\nIf you have no kernel or minimal RTOS kernel"
  },
  {
    "objectID": "day7.html#thread-models-many-to-many-mn",
    "href": "day7.html#thread-models-many-to-many-mn",
    "title": "CSC 453",
    "section": "Thread models: many-to-many (M:N)",
    "text": "Thread models: many-to-many (M:N)\n\nSet of user threads supported by &lt;= number of kernel\nUser thread isn’t bound to a particular kernel thread\n\nIf kernel thread has to block and was supporting 3 user threads, the others can migrate\n\nAllows parallelism\nSounds like the best of all worlds, right?\n\nCan be hard to implement without decent language support\nNow you have two schedulers to deal with (user space and kernel)\ngoroutines are a notable example of M:N in reality (though they are achieved through the Go runtime and not the kernel itself)\n\nWhen to use?\n\nWhen you need maximum concurrency (thousands to millions of threads) and have custom scheduling needs"
  },
  {
    "objectID": "day7.html#thread-models-one-to-one-11",
    "href": "day7.html#thread-models-one-to-one-11",
    "title": "CSC 453",
    "section": "Thread models: one-to-one (1:1)",
    "text": "Thread models: one-to-one (1:1)\n\nNumber of kernel-level threads is equal to the number of user-level threads (dominant model today)\nCan operate in parallel\nIf one blocks, others can continue\nDownsides?\n\nLose the advantage of fast switching between user threads\nAny new user thread requires kernel thread creation: expensive\nProgrammer loses scheduling control: kernel makes decisions\n\nVery popular model: Linux & Windows\n\nEasy to implement\nMost machines have multiple cores so we can support a lot of kernel threads"
  },
  {
    "objectID": "day7.html#which-models-make-sense",
    "href": "day7.html#which-models-make-sense",
    "title": "CSC 453",
    "section": "Which models make sense?",
    "text": "Which models make sense?\n\nDistributed scientific computing\n\n1:1 - In scientific computing, you want predictable, full-speed access to hardware, not an extra runtime scheduler in the way\n\nEmbedded system\n\nM:1 - In embedded systems, simplicity and determinism matter more than scalability. You may only have a single core\n\nNGINX web servers\n\nM:N - NGINX multiplexes connections (user-level work) onto a small number of kernel threads"
  },
  {
    "objectID": "day7.html#section",
    "href": "day7.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day7.html#questions-to-consider-1",
    "href": "day7.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the requirements for a critical section synchronization solution?\nWhy do naive implementations like a simple boolean lock fail, and what must happen atomically instead?\nWhat are the practical limitations of Peterson’s solution, and why don’t they work well on modern architectures?"
  },
  {
    "objectID": "day7.html#where-do-we-stand",
    "href": "day7.html#where-do-we-stand",
    "title": "CSC 453",
    "section": "Where do we stand?",
    "text": "Where do we stand?\n\nProcess model allows us an abstraction of a program (and the state to pause it)\nScheduling allows us concurrency and marshaled access to a scarce resource: CPU\nMechanisms for process communication and cooperation (shared-memory or message passing)\nThreads allow concurrency within a process and shared memory\n\nWith shared memory, there is potential for inconsistency"
  },
  {
    "objectID": "day7.html#problem",
    "href": "day7.html#problem",
    "title": "CSC 453",
    "section": "Problem",
    "text": "Problem\n\nTwo processes accessing a reservation system, where the number of open seats is tracked by a counter\n\nA: Releasing Seat\nB: Reserving Seat\n\nCounter at 10; Process A counter++ = 11; Process B counter– = 9;\nWhat could go wrong?\nmov 0x8049a1c, %eax\nadd $0x1, %eax\nmov %eax, 0x8049a1c\n\nmov 0x8049a1c, %eax\nsub $0x1, %eax\nmov %eax, 0x8049a1c"
  },
  {
    "objectID": "day7.html#race-conditions",
    "href": "day7.html#race-conditions",
    "title": "CSC 453",
    "section": "Race conditions",
    "text": "Race conditions\n\nIf interleaved, whoever goes last wins. Either way, 11 or 9 is an incorrect value. This is a race condition\nVery common in multi-programming environments: allocating disk blocks or memory pages, writing to a file, network buffers, etc.\nHow can we solve race conditions?\n\nMutual Exclusion (one at a time) on Critical Sections (the contention data/code)"
  },
  {
    "objectID": "day7.html#challenges-we-face",
    "href": "day7.html#challenges-we-face",
    "title": "CSC 453",
    "section": "Challenges we face",
    "text": "Challenges we face\n\nHow large should a critical section be?\nHow long can a process be in a critical section\n\nWhat happens if they crash while within a critical section?\n\nHow do we implement? Who enforces entrance into critical sections?"
  },
  {
    "objectID": "day7.html#beware-naïve-implementations",
    "href": "day7.html#beware-naïve-implementations",
    "title": "CSC 453",
    "section": "Beware naïve implementations",
    "text": "Beware naïve implementations\n\nWhy not use a simple bool?\nbool lock = FALSE\ndo {\n  while (lock == TRUE);\n  lock = TRUE;\n  //CRITICAL SECTION\n  lock = FALSE;\n}while(TRUE);\nThis implementation requires TWO operations: a read (test) and a write (set) that must be atomic"
  },
  {
    "objectID": "day7.html#critical-section-solution-requirements",
    "href": "day7.html#critical-section-solution-requirements",
    "title": "CSC 453",
    "section": "Critical section solution requirements",
    "text": "Critical section solution requirements\n\nMutual exclusion: only one process can execute at a time\nProgress: if no process is executing in its critical section and there exist some processes that wish to enter their critical section, then the selection of the process that will enter the critical section next cannot be postponed indefinitely\n\nE.g., A process cannot immediately re-enter the critical section if the other process want to\n\nBounded waiting: In addition to guaranteeing entrance, limits on the amount of time in a critical section must be established\n\nNo assumptions on the speed or number of CPUs"
  },
  {
    "objectID": "day7.html#petersons-solution",
    "href": "day7.html#petersons-solution",
    "title": "CSC 453",
    "section": "Peterson’s solution",
    "text": "Peterson’s solution\n\nTwo processes: \\(P_i\\) and \\(P_j\\)\nTwo shared data items: int turn; bool flag[2];\nPis code:\ndo {\n  flag[i] = TRUE;                // I want to enter critical section\n  turn = j;                      // let Pj go first if it wants\n  while (flag[j] && turn == j);  // busy wait\n  //CRITICAL SECTION\n  flag[i] = FALSE;               // Im leaving critical section\n  //REMAINDER\n}while(TRUE);\n\nturn indicates whose turn it is: turn == i → \\(P_i\\)’s turn\nif flag[i] == true → \\(P_i\\) is ready for the critical section\n\nTo enter: \\(P_i\\) sets flag[i] = true and turn = j\n\ni.e., \\(P_i\\) demurs to \\(P_j\\); if they are both ready turn will get set to?\n\nWhomever runs last sets the turn to the other process"
  },
  {
    "objectID": "day7.html#petersons-solution-contd",
    "href": "day7.html#petersons-solution-contd",
    "title": "CSC 453",
    "section": "Peterson’s solution (cont’d)",
    "text": "Peterson’s solution (cont’d)\nPis code:\ndo {\n  flag[i] = TRUE;                // I want to enter critical section\n  turn = j;                      // let Pj go first if it wants\n  while (flag[j] && turn == j);  // busy wait\n  //CRITICAL SECTION\n  flag[i] = FALSE;               // Im leaving critical section\n  //REMAINDER\n}while(TRUE);\n\nDoes this meet the three solution requirements?\nMutual exclusion: under what conditions can a process be in the critical section?\n\n\\(P_i\\) only enters if flag[j] is false or turn == i\nConversely, if \\(P_i\\) and \\(P_j\\) are in the CS, then flag[i] == flag[j]; this implies both \\(P_i\\) and \\(P_j\\) terminated their whiles at the same time; BUT, in order for this to be true, turn must be both 0 and 1 (Contradiction)"
  },
  {
    "objectID": "day7.html#petersons-solution-contd-1",
    "href": "day7.html#petersons-solution-contd-1",
    "title": "CSC 453",
    "section": "Peterson’s solution (cont’d)",
    "text": "Peterson’s solution (cont’d)\nPis code:\ndo {\n  flag[i] = TRUE;                // I want to enter critical section\n  turn = j;                      // let Pj go first if it wants\n  while (flag[j] && turn == j);  // busy wait\n  //CRITICAL SECTION\n  flag[i] = FALSE;               // Im leaving critical section\n  //REMAINDER\n}while(TRUE);\n\nProgress: Is there a condition where \\(P_i\\) can’t enter the CS?\n\nThere is no condition under which \\(P_i\\) cannot (eventually) enter the CS; either the other process will set turn == i or it is already set\n\nBounded Waiting: How long will \\(P_i\\) wait in the best/worst case?\n\n\\(P_i\\) will enter after at most one entry by \\(P_j\\)"
  },
  {
    "objectID": "day7.html#petersons-solution-contd-2",
    "href": "day7.html#petersons-solution-contd-2",
    "title": "CSC 453",
    "section": "Peterson’s solution (cont’d)",
    "text": "Peterson’s solution (cont’d)\nPis code:\ndo {\n  flag[i] = TRUE;                // I want to enter critical section\n  turn = j;                      // let Pj go first if it wants\n  while (flag[j] && turn == j);  // busy wait\n  //CRITICAL SECTION\n  flag[i] = FALSE;               // Im leaving critical section\n  //REMAINDER\n}while(TRUE);\n\nDo you see any issues with this solution?\n\nLimitation: Only works for two processes\nModern architectures may also break this solution\n\nProcessors and/or compilers can reorder reads and writes that have no dependencies\nMultithreaded applications could lead to issues"
  },
  {
    "objectID": "day7.html#section-1",
    "href": "day7.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day7.html#questions-to-consider-2",
    "href": "day7.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow do synchronization solutions compare in implementation / function?\nWhy can busy-waiting primitives cause problems like priority inversion, and how do blocking primitives help address this?\nWhen would you choose a counting semaphore versus a binary semaphore or mutex, and what distinguishes them?"
  },
  {
    "objectID": "day7.html#hardware-solutions-atomicity",
    "href": "day7.html#hardware-solutions-atomicity",
    "title": "CSC 453",
    "section": "Hardware solutions: atomicity",
    "text": "Hardware solutions: atomicity\n\nOne way: use atomic instructions (all-or-none actions)\nBaked into modern hardware\n\ntest_and_set()\ncompare_and_swap()\nThese both lock the memory bus (lighter weight than the olden days when we could alternatively disable interrupts)\n\nDisabling interrupts only really works on a single CPU, modern architectures make it untenable\n\n\nEasy enough for simple operations\nNot realistic for complex operations\n\nEx. “atomic update of a B-tree”: do we really want to bake such an instruction into the hardware? No"
  },
  {
    "objectID": "day7.html#hardware-solutions-atomicity-contd",
    "href": "day7.html#hardware-solutions-atomicity-contd",
    "title": "CSC 453",
    "section": "Hardware solutions: atomicity (cont’d)",
    "text": "Hardware solutions: atomicity (cont’d)\nbool test_and_set(bool *lock){\n  bool ret = *lock;\n  *lock = TRUE;\n  return ret;\n}\n\nlock = FALSE;\ndo{\n  while(test_and_set(&lock));\n  // CRITICAL SECTION\n  lock = FALSE;\n}while(true)\n\nDoes this test_and_set() solution meet the requirements?\nMutual exclusion?\n\nYes\n\nBounded wait/Progress?\n\nNo: you could end up with a situation where an unlucky process is endlessly waiting based on the scheduler’s decisions"
  },
  {
    "objectID": "day7.html#mutex-locks",
    "href": "day7.html#mutex-locks",
    "title": "CSC 453",
    "section": "Mutex locks",
    "text": "Mutex locks\n\nPrevious solutions are complicated and generally not used by application programmers (kernel hackers only)\nAny solution to the critical section problem requires a lock\n\nPeterson’s solution is an example (in software)\ntest_and_set() / compare_and_swap() are hardware implementations\n\nSimplest commonly used solution is mutex lock\n\nBoolean variable indicating if lock is available or not"
  },
  {
    "objectID": "day7.html#mutex-locks-contd",
    "href": "day7.html#mutex-locks-contd",
    "title": "CSC 453",
    "section": "Mutex locks (cont’d)",
    "text": "Mutex locks (cont’d)\n\nProtect a critical section by\n\nFirst acquire() a lock\nThen release() the lock\n\nWhat’s going on under the hood?\nvoid lock(lock_t *lock) {\n  while (test_and_set(&lock-&gt;flag, 1) == 1)\n  ; // spin-wait (do nothing)\n}\n\ntest_and_set() or compare_and_swap()"
  },
  {
    "objectID": "day7.html#mutex-locks-contd-1",
    "href": "day7.html#mutex-locks-contd-1",
    "title": "CSC 453",
    "section": "Mutex locks (cont’d)",
    "text": "Mutex locks (cont’d)\n\nCalls to acquire() and release() must be atomic\nBut this solution requires busy waiting\n\nThis type of mutex is therefore often called a spinlock\n\nNOT ALWAYS TERRIBLE: spinlocks are preferable in some cases. When do you think?\n\nWhen the lock is likely to be held for &lt;= the time for two context switches\n\n\n\nThere are also mutex implementations (e.g., futex) that block to avoid busy-waiting, and some that do both\nNote: mutexes are owned by the thread that locks them. Only the thread that acquired the mutex can release it"
  },
  {
    "objectID": "day7.html#busy-waiting-consequence",
    "href": "day7.html#busy-waiting-consequence",
    "title": "CSC 453",
    "section": "Busy waiting consequence",
    "text": "Busy waiting consequence\nIn 1997, NASA’s Mars Pathfinder started having mysterious resets on Mars. From Earth, engineers saw the system repeatedly rebooting for no obvious reason. Not ideal when your computer is 250 million km away.\nThe cause turned out to be priority inversion in the operating system.\n\nWhat was happening:\n\nA low-priority task was holding a shared resource (a mutex).\n\nA high-priority task needed that resource and blocked, waiting.\nMeanwhile, a medium-priority task—which didn’t need the resource at all—kept preempting the low-priority task.\nResult: the low-priority task never got CPU time to release the resource, so the high-priority task was effectively starved.\n\n\nThe system interpreted this long delay as a fault and triggered a watchdog reset. Over and over."
  },
  {
    "objectID": "day7.html#priority-inversion",
    "href": "day7.html#priority-inversion",
    "title": "CSC 453",
    "section": "Priority inversion",
    "text": "Priority inversion\n\nAny ideas on how to fix?\n\nPriority inheritance: low priority processes are temporarily given priorities that match those waiting on them"
  },
  {
    "objectID": "day7.html#section-2",
    "href": "day7.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day7.html#semaphores",
    "href": "day7.html#semaphores",
    "title": "CSC 453",
    "section": "Semaphores",
    "text": "Semaphores\n\n\n\nSynchronization tool that provides more sophisticated ways (than mutex locks) for processes to synchronize their activities\nSemaphore S: integer variable\nCan only be accessed via two atomic operations\n\nwait() and signal()\n\nOriginally called P() and V() (because, Dutch - another Dijkstra invention)\n\n\nDo not have ownership, any thread can signal (increment) or wait (decrement)\n\n\n\n\nwait(S) { \n    while (S &lt;= 0)\n       ; // busy\n    S--;\n}\n\nsignal(S) { \n    S++;\n}"
  },
  {
    "objectID": "day7.html#semaphores-contd",
    "href": "day7.html#semaphores-contd",
    "title": "CSC 453",
    "section": "Semaphores (cont’d)",
    "text": "Semaphores (cont’d)\n\n\n\nBinary semaphore: integer value can range only between 0 and 1\n\nFunctionally the same as a mutex (often when people call something a mutex it’s actually a binary semaphore)\n\n\n\n\n\ndo{\n  wait(mutex);\n  //CS\n  signal(mutex);\n}while(TRUE);\n\n\nCounting semaphore: integer value can range over an unrestricted domain\n\nWhen would this make sense?\n\nProtect a finite set of resources rather than a single one (e.g., you have a pool of db connections that can be shared by processes)\nInitialize S to the number of resources\nDecrement S each time someone grabs a resource, increment when they release"
  },
  {
    "objectID": "day7.html#semaphores-contd-1",
    "href": "day7.html#semaphores-contd-1",
    "title": "CSC 453",
    "section": "Semaphores (cont’d)",
    "text": "Semaphores (cont’d)\n\n\n\nCan also be used to force synchronization\nConsider \\(P_1\\) and \\(P_2\\) that with two statements \\(S_1\\) and \\(S_2\\) and the requirement that \\(S_1\\) to happen before \\(S_2\\)\n\n\n\n\nP1:\n   S1;\n   signal(sync);\nP2:\n   wait(sync);\n   S2;"
  },
  {
    "objectID": "day7.html#blocking-semaphores",
    "href": "day7.html#blocking-semaphores",
    "title": "CSC 453",
    "section": "Blocking semaphores",
    "text": "Blocking semaphores\n\n\n\nWe add sleep() and wakeup() to the underlying implementation\nCall to wait, and semaphore not available, process is blocked with sleep() (wait state) and placed on a waiting queue\nBlocked processes are notified of an available semaphore by the wakeup() operation\n\ngoes from waiting to ready\nAble to achieve bounded wait and progress with FIFO queue\n\n\n\n\n\nwait(semaphore *S) { \n   S-&gt;value--; \n   if (S-&gt;value &lt; 0) {      \n      add process to S-&gt;list; \n      sleep(); \n   } \n}\n\nsignal(semaphore *S) { \n   S-&gt;value++; \n   if (S-&gt;value &lt;= 0) {      \n      remove P from S-&gt;list; \n      wakeup(P); \n   } \n}"
  },
  {
    "objectID": "day7.html#mutexes-vs.-semaphores",
    "href": "day7.html#mutexes-vs.-semaphores",
    "title": "CSC 453",
    "section": "Mutexes vs. semaphores",
    "text": "Mutexes vs. semaphores\n\nMutexes are generally lighter weight / faster\nSemaphores can support multiple instances\nSemaphores don’t have the ownership limitations"
  },
  {
    "objectID": "day7.html#choose-your-primitive",
    "href": "day7.html#choose-your-primitive",
    "title": "CSC 453",
    "section": "Choose your primitive",
    "text": "Choose your primitive\n\nFor each, choose between: atomic instructions; futexes; spin lock mutexes; semaphores\nScenario 1: You need to protect a critical section where only one thread should execute at a time, and the critical section is expected to be held for a relatively long duration.\n\nFutex\n\nScenario 2: You have a pool of database connections, and you need to limit the number of threads that can access these connections simultaneously.\n\nCounting semaphore"
  },
  {
    "objectID": "day7.html#choose-your-primitive-contd",
    "href": "day7.html#choose-your-primitive-contd",
    "title": "CSC 453",
    "section": "Choose your primitive (cont’d)",
    "text": "Choose your primitive (cont’d)\n\nFor each, choose between: atomic instructions; futexes; spin lock mutexes; semaphores\nScenario 3: You need to increment a shared counter frequently, and the operation is very quick.\n\nAtomic instruction\n\nScenario 4: You need to protect a critical section where only one thread should execute at a time, but the critical section is expected to be held for a very short duration.\n\nSpin lock mutex"
  },
  {
    "objectID": "day7.html#beware-mistakes-are-easy-to-make",
    "href": "day7.html#beware-mistakes-are-easy-to-make",
    "title": "CSC 453",
    "section": "Beware: mistakes are easy to make",
    "text": "Beware: mistakes are easy to make\n\nIncorrect use of semaphore operations\n\nwrong order: signal(mutex) … wait(mutex)\nrepeating: wait(mutex) … wait(mutex)\nOmitting of wait(mutex) and/or signal(mutex)\n\nBe careful"
  },
  {
    "objectID": "day7.html#monitors",
    "href": "day7.html#monitors",
    "title": "CSC 453",
    "section": "Monitors",
    "text": "Monitors\n\nSubtle mistakes with semaphores can lead to deadlocks, leading to monitors\nCan think of monitors as a library with an API (abstract data type)\n\nProcesses share the library, but not internal data (directly)\nThis requires language specific understanding of a monitor (C doesn’t have them, natively)\nMore relevant in languages like Java and other high-level languages that provide built-in monitor support"
  },
  {
    "objectID": "day7.html#monitors-contd",
    "href": "day7.html#monitors-contd",
    "title": "CSC 453",
    "section": "Monitors (cont’d)",
    "text": "Monitors (cont’d)\n\n\n\nMain idea: only one processes can be active within a monitor at any instant\n\nUp to the compilers to ensure mutual exclusion on monitor procedures\n\nIt can use other sync primitives to achieve this: e.g. a semaphore or mutex\n\nWe’re offloading synchronization correctness to the compiler, (hopefully) lessening the chance for error by the user\n\nMonitor variables are private"
  },
  {
    "objectID": "day7.html#condition-variables",
    "href": "day7.html#condition-variables",
    "title": "CSC 453",
    "section": "Condition variables",
    "text": "Condition variables\n\nMonitors often have condition variables\nCondition variables have wait() and signal() operations\n\nx.wait(): a process that invokes the operation is suspended until x.signal()\nx.signal(): resumes one of processes (if any) that invoked x.wait()\n\nIf no x.wait() on the variable, then it has no effect on the variable\n\n\nBig benefit of condition variables: x.broadcast()"
  },
  {
    "objectID": "day7.html#mutexes-semaphores-monitors-condition-variables",
    "href": "day7.html#mutexes-semaphores-monitors-condition-variables",
    "title": "CSC 453",
    "section": "Mutexes, semaphores, Monitors, Condition variables",
    "text": "Mutexes, semaphores, Monitors, Condition variables\n\nMutexes and Semaphores are good for:\n\nSimple mutual exclusion\nSimple counting resources\n\nMonitors are good for:\n\nComplex synchronization between many threads\nThread-safe operations (only allow one thread into the monitor at a time)\n\nCondition variables are good for:\n\nProducer-consumer problems (consumer threads waiting on some condition, signaled when ready)\nWe want to make one or more threads sleep until a resource is ready"
  },
  {
    "objectID": "day7.html#section-3",
    "href": "day7.html#section-3",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day6.html#admin",
    "href": "day6.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nMidterm 1 Thursday\n\nReminder: all raw slide content is in the GitHub repo as *.qmd\n\nNo quiz this week\nLab 4 due Monday\nProgramming assignment 2 due Monday"
  },
  {
    "objectID": "day6.html#questions-to-consider",
    "href": "day6.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the key differences between batch and interactive scheduling algorithms?\nHow does Round Robin improve response time compared to SJF, and what tradeoff does it introduce?\nWhy might a system benefit from using multiple scheduling queues rather than a single algorithm?"
  },
  {
    "objectID": "day6.html#batch-vs.-interactive-scheduling",
    "href": "day6.html#batch-vs.-interactive-scheduling",
    "title": "CSC 453",
    "section": "Batch vs. interactive scheduling",
    "text": "Batch vs. interactive scheduling\n\n\nBatch Scheduling\n\nOptimizes for: throughput, turnaround time, waiting time\nContext: data centers, HPC, background jobs\nUsers don’t interact with running jobs\n\n\n\n\nInteractive Scheduling\n\nOptimizes for: response time, fairness\nContext: desktop/laptop systems, servers\nUsers expect quick feedback to their actions"
  },
  {
    "objectID": "day6.html#what-about-response-time",
    "href": "day6.html#what-about-response-time",
    "title": "CSC 453",
    "section": "What about response time?",
    "text": "What about response time?\n\n\n\nSRTF is good if we know job lengths and we’re only worried about turnaround / waiting time\nSJF: poor response\nRR: better response"
  },
  {
    "objectID": "day6.html#interactive-algorithm-round-robin-rr",
    "href": "day6.html#interactive-algorithm-round-robin-rr",
    "title": "CSC 453",
    "section": "Interactive algorithm: Round Robin (RR)",
    "text": "Interactive algorithm: Round Robin (RR)\n\nFCFS with preemption\nBased on a time quantum (time slice)\n\nTypically 10-100 milliseconds\nHow do we pick a quantum?\n\nVery short: a lot of context switching (need a large quantum, otherwise overhead is too much to be worth it)\nVery long -&gt; becomes FCFS: long wait times, long turnaround times\n\nCircular queue\n\nNew processes are added to the tail\nIf a process doesn’t complete during its quantum, context switch and added to the tail"
  },
  {
    "objectID": "day6.html#rr-example",
    "href": "day6.html#rr-example",
    "title": "CSC 453",
    "section": "RR example",
    "text": "RR example\n\n\n\nAverage waiting time:  \\[[(10-4) + 4 + 7] = 17/3 = 5.66\\]\nPros:\n\nRR is fair, but do we really want fair???\nTypically, higher average turnaround than SJF, but better response\n\nCons?\n\nLong average waiting times\n\n\n\n\n\nProcess Burst Time\n  P1        24\n  P2        3\n  P3        3   \n\n  Quantum = 4"
  },
  {
    "objectID": "day6.html#gaming-rr",
    "href": "day6.html#gaming-rr",
    "title": "CSC 453",
    "section": "Gaming RR",
    "text": "Gaming RR\n\nHow could a programmer “cheat” RR?\n\nSpin up many processes (split tasks up and fork children)\nJob A: 9 processes\nJob B: 1 process\nA gets 90% of the CPU in RR\n\nThis actually happens in many systems that aim for rudimentary fairness"
  },
  {
    "objectID": "day6.html#fcfs-sjf-srtf-rr",
    "href": "day6.html#fcfs-sjf-srtf-rr",
    "title": "CSC 453",
    "section": "FCFS, SJF, SRTF, RR",
    "text": "FCFS, SJF, SRTF, RR\n\nAll have downsides\nThose that optimize turnaround / wait, can harm response time\nThose that optimize response time, can harm turnaround, wait\nWhat should we do?"
  },
  {
    "objectID": "day6.html#interactive-algorithms-multi-level-queue-mlq",
    "href": "day6.html#interactive-algorithms-multi-level-queue-mlq",
    "title": "CSC 453",
    "section": "Interactive algorithms: Multi-Level Queue (MLQ)",
    "text": "Interactive algorithms: Multi-Level Queue (MLQ)\n\nWe have classes of process, with different needs. Why not multiple schedulers satisfying those needs?\nMultilevel queue scheduler defined by the following parameters:\n\n# of queues\nScheduling algorithms for each queue\nMethod used to determine which queue a process will enter when that process needs service\nScheduling among the queues"
  },
  {
    "objectID": "day6.html#mlq",
    "href": "day6.html#mlq",
    "title": "CSC 453",
    "section": "MLQ",
    "text": "MLQ\n\n\n\nHow do we schedule this?\n\nStrict priority: low priority could starve\nTypical: time slice among queues (e.g., real-time get 50%, system gets 30%, interactive 15%, batch 5%)\nEach queue can implement a separate scheduling policy\n\nMLQ cons:\n\nStarvation\nInflexibility"
  },
  {
    "objectID": "day6.html#interactive-algorithms-multi-level-feedback-queue-mlfq",
    "href": "day6.html#interactive-algorithms-multi-level-feedback-queue-mlfq",
    "title": "CSC 453",
    "section": "Interactive algorithms: Multi-Level Feedback Queue (MLFQ)",
    "text": "Interactive algorithms: Multi-Level Feedback Queue (MLFQ)\n\nA process can move between the various queues (goal is to avoid starvation present in MLQ)\nMetrics for movement:\n\nProcess requirements (we serve fast processes quickly)\nOver consumption\nChange in priority\nAge"
  },
  {
    "objectID": "day6.html#mlfq-rules",
    "href": "day6.html#mlfq-rules",
    "title": "CSC 453",
    "section": "MLFQ rules",
    "text": "MLFQ rules\n\nRule 1: If Priority(A) &gt; Priority(B), A runs (B doesn’t)\nRule 2: If Priority(A)=Priority(B), A & B run in RR\nRule 3: When a job enters the system, it is placed at the highest priority (the topmost queue)\nRule 4a: If a job uses up its allotment while running, its priority is reduced (i.e., it moves down one queue)\nRule 4b: If a job gives up the CPU (for example, by performing an I/O operation) before the allotment is up, it stays at the same priority level (i.e., its allotment is reset)\nAny problems with these???"
  },
  {
    "objectID": "day6.html#mlfq-example-one-process",
    "href": "day6.html#mlfq-example-one-process",
    "title": "CSC 453",
    "section": "MLFQ example: one process",
    "text": "MLFQ example: one process"
  },
  {
    "objectID": "day6.html#mlfq-example-two-processes",
    "href": "day6.html#mlfq-example-two-processes",
    "title": "CSC 453",
    "section": "MLFQ example: two processes",
    "text": "MLFQ example: two processes\n\n\n\nScenario 1: Perfectly fine"
  },
  {
    "objectID": "day6.html#mlfq-example-two-processes-1",
    "href": "day6.html#mlfq-example-two-processes-1",
    "title": "CSC 453",
    "section": "MLFQ example: two processes",
    "text": "MLFQ example: two processes\n\n\n\nScenario 1: Perfectly fine\nScenario 2: programmer can game the algorithm to remain at high priority"
  },
  {
    "objectID": "day6.html#mlfq-example-two-processes-2",
    "href": "day6.html#mlfq-example-two-processes-2",
    "title": "CSC 453",
    "section": "MLFQ example: two processes",
    "text": "MLFQ example: two processes\n\n\n\nScenario 1: Perfectly fine\nScenario 2: programmer can game the algorithm to remain at high priority\nScenario 3: multiple small processes can lead to starvation"
  },
  {
    "objectID": "day6.html#mlfq-how-can-we-solve-gaming",
    "href": "day6.html#mlfq-how-can-we-solve-gaming",
    "title": "CSC 453",
    "section": "MLFQ: how can we solve gaming?",
    "text": "MLFQ: how can we solve gaming?"
  },
  {
    "objectID": "day6.html#mlfq-solving-gaming",
    "href": "day6.html#mlfq-solving-gaming",
    "title": "CSC 453",
    "section": "MLFQ: solving gaming",
    "text": "MLFQ: solving gaming\n\n\n\nRule 4 (new): Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue)"
  },
  {
    "objectID": "day6.html#mlfq-how-can-we-avoid-starvation",
    "href": "day6.html#mlfq-how-can-we-avoid-starvation",
    "title": "CSC 453",
    "section": "MLFQ: how can we avoid starvation?",
    "text": "MLFQ: how can we avoid starvation?"
  },
  {
    "objectID": "day6.html#mlfq-solving-starvation",
    "href": "day6.html#mlfq-solving-starvation",
    "title": "CSC 453",
    "section": "MLFQ: solving starvation",
    "text": "MLFQ: solving starvation\n\n\n\nRule 5: After some time period, move all the jobs in the system to the topmost queue\n\nSolves starvation\nBonus: if a long running process evolves to be more interactive, it gets promoted"
  },
  {
    "objectID": "day6.html#what-scheduler-should-we-use",
    "href": "day6.html#what-scheduler-should-we-use",
    "title": "CSC 453",
    "section": "What scheduler should we use?",
    "text": "What scheduler should we use?\n\nTicket booking system\n\nFCFS: fairness\n\nPrint server\n\nSJF could make sense\n\nWeb server\n\nRR: fairness and short response time\n\nGeneral operating systems\n\nMLFQ: need to handle a mix"
  },
  {
    "objectID": "day6.html#linux-scheduling",
    "href": "day6.html#linux-scheduling",
    "title": "CSC 453",
    "section": "Linux scheduling",
    "text": "Linux scheduling\n\nCompletely Fair Scheduler (CFS)\nFair-share scheduling (see lottery and stride scheduling in the text if you want to learn more)\nBased on vruntime (how long any process has run): lowest vruntime runs next\nDivide sched_latency by # processes to determine a dynamic quantum (floor set by min_granularity)\n\nWhy do we need a floor?"
  },
  {
    "objectID": "day6.html#linux-cfs",
    "href": "day6.html#linux-cfs",
    "title": "CSC 453",
    "section": "Linux CFS",
    "text": "Linux CFS\n\nRed-Black tree includes only running (or ready) processes\nBalanced such that operations are \\(O(log n)\\)\nVery straightforward to find the next job (smallest vruntime) to run\nSleeper fairness: processes waiting on I/O are given “credit” for their wait time\nPeople are actively working on new features"
  },
  {
    "objectID": "day6.html#section",
    "href": "day6.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day6.html#questions-to-consider-1",
    "href": "day6.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the differences between processes and threads?\nWhen are threads beneficial?\nHow are threads limited by Amdahl’s Law?"
  },
  {
    "objectID": "day6.html#motivation-context-switching-is-expensive",
    "href": "day6.html#motivation-context-switching-is-expensive",
    "title": "CSC 453",
    "section": "Motivation: context switching is expensive",
    "text": "Motivation: context switching is expensive\n\nconsider the modern word processor, which concurrently:\n\naccepts user input,\nperforms auto-correct/spell checking;\nauto-detects formatting\nauto-save (nothing could be entered until save was complete);\n\nAll impossible (or at least very inconvenient) without threads."
  },
  {
    "objectID": "day6.html#processes-vs-threads",
    "href": "day6.html#processes-vs-threads",
    "title": "CSC 453",
    "section": "Processes vs threads",
    "text": "Processes vs threads\n\nPotentially confusing due to overlapping terminology: we can describe both a process and a thread as running\nTerminology can be helpful for remembering the distinction:\n\nA computing process requires multiple resources: the CPU, memory, files, etc.\nA thread of execution abstracts CPU state"
  },
  {
    "objectID": "day6.html#processes-vs-threads-contd",
    "href": "day6.html#processes-vs-threads-contd",
    "title": "CSC 453",
    "section": "Processes vs threads (cont’d)",
    "text": "Processes vs threads (cont’d)\n\nProcesses contain threads; threads belong to a process\n\nOnly one exception: the kernel may have threads of execution not associated with any user process\n\nThreads each have their own stack and registers\n\nShare code, data, files held by the process\n\nA process is considered to be running when one or more of its threads are running\nDifferent operating systems use different terminology, but share common ideas"
  },
  {
    "objectID": "day6.html#intra-process-communication",
    "href": "day6.html#intra-process-communication",
    "title": "CSC 453",
    "section": "Intra-process communication",
    "text": "Intra-process communication\n\nCommunication between multiple threads in a process is usually accomplished using shared memory (since they naturally share it)\n\nPotential issues?\n\nSynchronization (we’ll come back to this)\n\n\nThreads within a process also share open file handles and both static and dynamically-allocated global variables.\nThread stacks and thus thread local variables are typically private."
  },
  {
    "objectID": "day6.html#why-do-we-use-threads-pros",
    "href": "day6.html#why-do-we-use-threads-pros",
    "title": "CSC 453",
    "section": "Why do we use threads? Pros",
    "text": "Why do we use threads? Pros\n\nTo support multiple activities within a single process\nResponsiveness: a process may continue to run, even if part of it is blocked (depends on thread implementation)\nResource sharing: Process are isolated so can only communicate with help from the kernel; threads share a memory space and a process’s resources (e.g. files)\nEconomy: Allocating resources for multiple processes is costly, because it involves the kernel. Threads can be handled entirely in user space and are much faster to allocate and destroy. Allows for pop-up threads, dynamically created threads to support load\nHardware support: modern CPUs support multithreading, where threads can run in parallel"
  },
  {
    "objectID": "day6.html#thread-cons",
    "href": "day6.html#thread-cons",
    "title": "CSC 453",
    "section": "Thread cons",
    "text": "Thread cons\n\nThis is hard. Burdens programmer needs to solve:\n\nDividing activities\nBalance\nData splitting\nData dependency\nTesting and debugging\n\nShare the same address space and global variable: loss of isolation. A runaway thread can wipe out other threads\nNo built-in mechanism for pre-emption, so threads should be well-behaved (unlike greedy processes)\nn threads see 1/n of a single CPU; CPU-bound processes make thread moot, or detrimental"
  },
  {
    "objectID": "day6.html#what-makes-more-sense-threads-or-process",
    "href": "day6.html#what-makes-more-sense-threads-or-process",
    "title": "CSC 453",
    "section": "What makes more sense, threads or process?",
    "text": "What makes more sense, threads or process?\n\nWeb server\nGUI apps\nMultimedia apps\nDB servers\nOS services"
  },
  {
    "objectID": "day6.html#what-makes-more-sense-threads-or-process-1",
    "href": "day6.html#what-makes-more-sense-threads-or-process-1",
    "title": "CSC 453",
    "section": "What makes more sense, threads or process?",
    "text": "What makes more sense, threads or process?\n\nWeb server - thread (through there are many hybrid implementations)\nGUI apps - thread\nMultimedia apps - thread\nDB servers - both: postgres uses processes, MySQL is multithreaded\nOS services - process"
  },
  {
    "objectID": "day6.html#side-note-fork-and-threading",
    "href": "day6.html#side-note-fork-and-threading",
    "title": "CSC 453",
    "section": "Side note: fork() and threading",
    "text": "Side note: fork() and threading\n\nWhat happens to threads when you fork()?\nShould a child inherit the threads of their parent?\nWhat happens if two threads are competing for the same resource? E.g., who gets the input from a keyboard or established network connection?\nIn reality (Linux): a child process, only the calling thread is replicated."
  },
  {
    "objectID": "day6.html#a-word-of-caution-amdahls-law",
    "href": "day6.html#a-word-of-caution-amdahls-law",
    "title": "CSC 453",
    "section": "A word of caution: Amdahl’s Law",
    "text": "A word of caution: Amdahl’s Law\n\nThreads are awesome, let’s parallelize everything, right?\nAmdahl’s Law identifies performance gains from adding additional cores to an application that has both serial and parallel components\n\n\\(S\\) is serial portion\n\\(N\\) processing cores \\[speedup \\le \\frac{1}{S + \\frac{(1-S)}{N}}\\]\n\nThat is, if application is 75% parallel / 25% serial, moving from 1 to 2 cores results in speedup of \\(1.6 \\times\\)\nAs \\(N\\) approaches infinity, speedup approaches \\(1 / S\\)\nSerial portion has a disproportionate effect on performance"
  },
  {
    "objectID": "day6.html#section-1",
    "href": "day6.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day6.html#questions-to-consider-2",
    "href": "day6.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat is the difference between user threads and kernel threads\nWhat are the different kernel thread models and how do they compare?"
  },
  {
    "objectID": "day6.html#first-things-first",
    "href": "day6.html#first-things-first",
    "title": "CSC 453",
    "section": "First things first",
    "text": "First things first\n\nA kernel thread is the unit of execution that the OS can run on a CPU core\nA process can only make progress if at least one of its kernel threads is scheduled on a core\nCPUs run kernel threads, not processes"
  },
  {
    "objectID": "day6.html#posix-threads-pthreads",
    "href": "day6.html#posix-threads-pthreads",
    "title": "CSC 453",
    "section": "POSIX threads (pthreads)",
    "text": "POSIX threads (pthreads)\n\n60 calls, but the important ones are: pthread*\n\ncreate, exit, yield, join (Look familiar?)\n\nPthreads were historically (pre 2003) a user space library: all functionality happens in user space, and the kernel knew nothing about them\n\ncan run on kernels or CPUs with no thread support\norders of magnitude faster than a kernel trap (everything is a local function call)\ncustom schedulers"
  },
  {
    "objectID": "day6.html#pure-user-space-threads",
    "href": "day6.html#pure-user-space-threads",
    "title": "CSC 453",
    "section": "Pure user space threads",
    "text": "Pure user space threads\n\nTotally unknown to the OS\nUser-level threads must “borrow” a kernel thread to run\nWhat happens when a thread makes an I/O-bound system call?\n\nAll threads will block, because the process is blocked\nSometimes a thread blocking a process is unavoidable: page fault: more later\n\nWhere we typically want threads is where there is a lot of I/O blocking or system calls: the web server example"
  },
  {
    "objectID": "day6.html#kernel-threads",
    "href": "day6.html#kernel-threads",
    "title": "CSC 453",
    "section": "Kernel threads",
    "text": "Kernel threads\n\nThread libraries can also have kernel support (this is the common case today)\nThere is no user space runtime environment or thread table: all is managed within the kernel\nSupport for multiple cores\nAll thread interfaces are system calls handled by the kernel"
  },
  {
    "objectID": "day6.html#kernel-threads-contd",
    "href": "day6.html#kernel-threads-contd",
    "title": "CSC 453",
    "section": "Kernel threads (cont’d)",
    "text": "Kernel threads (cont’d)\n\nInstead of blocking on a system call, the kernel now has the intelligence to schedule another thread\nCreating and destroying threads comes at a higher cost (the kernel trap we were trying to avoid above)\n\nWhat should we do?\n\nThread pools: a collection of pre-allocated threads, assigned as needed"
  },
  {
    "objectID": "day6.html#thread-design-models-many-to-one-m1",
    "href": "day6.html#thread-design-models-many-to-one-m1",
    "title": "CSC 453",
    "section": "Thread design models: many-to-one (M:1)",
    "text": "Thread design models: many-to-one (M:1)\n\nKernel threads must support user level threads. There are multiple ways to pull this off\nMany-to-one\n\nA single kernel level thread supports many user level threads\nSwitching between threads is fast (done in user level)\nNo parallelism (kernel thread is supporting only a single user thread at a time)\nIf any user thread makes an I/O blocking call, all user threads in that process are blocked\n\nWhere does this make sense?\n\nIf you need complete control over scheduling\nIf you have no kernel or minimal RTOS kernel"
  },
  {
    "objectID": "day6.html#thread-models-many-to-many-mn",
    "href": "day6.html#thread-models-many-to-many-mn",
    "title": "CSC 453",
    "section": "Thread models: many-to-many (M:N)",
    "text": "Thread models: many-to-many (M:N)\n\nSet of user threads supported by &lt;= number of kernel\nUser thread isn’t bound to a particular kernel thread\n\nIf kernel thread has to block and was supporting 3 user threads, the others can migrate\n\nAllows parallelism\nProgrammer has more control (scheduling in user space)\nSounds like the best of all worlds, right?\n\nCan be hard to implement without decent language support\nNow you have two schedulers to deal with (user space and kernel)\ngoroutines are a notable example of M:M in reality (though they are achieved through the Go runtime and not the kernel itself)"
  },
  {
    "objectID": "day6.html#thread-models-one-to-one-11",
    "href": "day6.html#thread-models-one-to-one-11",
    "title": "CSC 453",
    "section": "Thread models: one-to-one (1:1)",
    "text": "Thread models: one-to-one (1:1)\n\nNumber of kernel-level threads is equal to the number of user-level threads (dominant model today)\nCan operate in parallel\nIf one blocks, others can continue\nDownsides?\n\nLose the advantage of fast switching between user threads\nAny new user thread requires kernel thread creation: expensive\nProgrammer loses scheduling control: kernel makes decisions\n\nVery popular model: Linux & Windows\n\nEasy to implement\nMost machines have multiple cores so we can support a lot of kernel threads"
  },
  {
    "objectID": "day6.html#which-models-make-sense",
    "href": "day6.html#which-models-make-sense",
    "title": "CSC 453",
    "section": "Which models make sense?",
    "text": "Which models make sense?\n\nDistributed scientific computing\n\n1:1 - In scientific computing, you want predictable, full-speed access to hardware, not an extra runtime scheduler in the way\n\nEmbedded system\n\nM:1 - In embedded systems, simplicity and determinism matter more than scalability. You may only have a single core\n\nNGINX web servers\n\nM:N - NGINX multiplexes connections (user-level work) onto a small number of kernel threads"
  },
  {
    "objectID": "day6.html#section-2",
    "href": "day6.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day5.html#admin",
    "href": "day5.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nQuiz 3 due Friday\nLab 3 due Monday\nProgramming assignment 2 due Feb 2\nMidterm question"
  },
  {
    "objectID": "day5.html#questions-to-consider",
    "href": "day5.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow do pipes differ from FIFOs and when would you use each?\nWhat considerations matter when choosing between pipes, FIFOs, and memory-mapped files?"
  },
  {
    "objectID": "day5.html#pipes-anonymous-pipes",
    "href": "day5.html#pipes-anonymous-pipes",
    "title": "CSC 453",
    "section": "Pipes (anonymous pipes)",
    "text": "Pipes (anonymous pipes)\n\nPipes are unidirectional; one end must be designated as the reading end and the other as the writing end\nPipes are order preserving; all data read from the receiving end of the pipe will match the order in which it was written into the pipe\nPipes have a limited capacity and they use blocking I/O; if a pipe is full, any additional writes to the pipe will block the process until some of the data has been read\nPipes send data as unstructured byte streams. There are no pre-defined characteristics to the data exchanged, such as a predictable message length"
  },
  {
    "objectID": "day5.html#pipes-contd",
    "href": "day5.html#pipes-contd",
    "title": "CSC 453",
    "section": "Pipes (cont’d)",
    "text": "Pipes (cont’d)\n\nPipes create a producer-consumer buffer between two processes\nCannot be accessed outside of the creating process (child inherits the pipe since it’s a fd)\nThe operating system manages a queue for each pipe to accommodate different input and output rates\nFacilitates the canonical chaining together of small UNIX utilities to do more sophisticated processing"
  },
  {
    "objectID": "day5.html#pipe-bugs",
    "href": "day5.html#pipe-bugs",
    "title": "CSC 453",
    "section": "Pipe bugs",
    "text": "Pipe bugs\nint pipefd[2];\npipe (pipefd);\n\nif (fork () == 0)\n  exit (0);\n\nchar buffer[10];\nread (pipefd[0], buffer, sizeof (buffer));\n\nWhat will happen here?\n\nParent will block until an EOF is written into the pipe. Since the child is the only other process that could write to the pipe and the child exits without writing anything, and the parent has not closed its write end, the parent will block indefinitely."
  },
  {
    "objectID": "day5.html#named-pipes-also-known-as-fifos",
    "href": "day5.html#named-pipes-also-known-as-fifos",
    "title": "CSC 453",
    "section": "Named pipes (also known as FIFOs)",
    "text": "Named pipes (also known as FIFOs)\n\nOf course there is another type that don’t share the same characteristics\nNamed pipes are bidirectional, don’t have the parent-child relationship\n\nCreates a persistent file-like name\nRequire a reader and writer"
  },
  {
    "objectID": "day5.html#named-pipes-contd",
    "href": "day5.html#named-pipes-contd",
    "title": "CSC 453",
    "section": "Named pipes (cont’d)",
    "text": "Named pipes (cont’d)\n\nReally a data stream (ordering, buffering, reliability, authentication all implied)\nThey are not regular files, though they look like them\n\nOnce data has been read from a FIFO, the data is discarded and cannot be read again\nCannot broadcast: only one read()\nNot wise to use bidirectionally, why?"
  },
  {
    "objectID": "day5.html#shared-memory-with-mmap",
    "href": "day5.html#shared-memory-with-mmap",
    "title": "CSC 453",
    "section": "Shared memory with mmap",
    "text": "Shared memory with mmap\n\n\n\nMemory-mapped files allow for multiple processes to share read-only access to a common file. Example: libc.so mapped into all running C programs\nMemory-mapped files bypass the kernel’s buffer cache (as done with a normal read()), and the data is copied directly into the user-mode portion of memory\n\n\n\n\n\n\n\nProvide extremely fast IPC data exchange. i.e., when one process writes to the region, that data is immediately accessible by the other process without having to invoke a system call\nUnlike pipes, memory-mapped files create persistent IPC. Once the data is written to the shared region, it can be repeatedly accessed by other processes"
  },
  {
    "objectID": "day5.html#memory-mapped-files-posix-and-system-v",
    "href": "day5.html#memory-mapped-files-posix-and-system-v",
    "title": "CSC 453",
    "section": "Memory mapped files: POSIX and System V",
    "text": "Memory mapped files: POSIX and System V\n\nThese two ultimately mmap a file, but do some trickery beforehand and use special files\nPOSIX == named, RAM-backed file descriptors\n\nname → fd → mmap\nObject survives until the last reference is gone\nusually backed by tmpfs (/dev/shm)\n\nSystem V shared memory\n\nPredates POSIX - designed before file descriptors were a universal abstraction\nKernel-persistent objects, you must clean up manually\n\nProcess exits ≠ memory freed"
  },
  {
    "objectID": "day5.html#posix-vs.-system-v",
    "href": "day5.html#posix-vs.-system-v",
    "title": "CSC 453",
    "section": "POSIX vs. System V",
    "text": "POSIX vs. System V\n\nPOSIX is great, right!?\n\nPOSIX (e.g., shm_open()) IPC may not work in your favor in macOS\nSome questionable engineer (obviously not a CP grad) decided to provide the header files for certain things, but they are empty stubs\n\nIt will compile, but could be bad\n\n\nSystem V is “fine”\n\nshmget(): allocate\nshmat(): attach\nshmdt(): detach\nshmctl(): control (destroy with IPC_RMID)"
  },
  {
    "objectID": "day5.html#message-passing-vs.-shared-memory",
    "href": "day5.html#message-passing-vs.-shared-memory",
    "title": "CSC 453",
    "section": "Message passing vs. shared memory",
    "text": "Message passing vs. shared memory\n\n\n\nWhich do you choose?\n\nIf you have few messages?\nIf you have millions?\nIf you need to communicate across systems?\nIf you need in-order delivery but don’t want to code it yourself?\n\nConsiderations:\n\nCost to establish\nCost per message\n\n\n\n\n\n “Gemini, make an image in the style of a video game pitting pipes versus shared memory”"
  },
  {
    "objectID": "day5.html#section",
    "href": "day5.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day5.html#questions-to-consider-1",
    "href": "day5.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the differences / tradeoffs between preemptive and non-preemptive scheduling algorithms?\nWhat are the metrics we can attempt to optimize scheduling for a given scenario?"
  },
  {
    "objectID": "day5.html#preemptive-vs.-non-preemptive-scheduling",
    "href": "day5.html#preemptive-vs.-non-preemptive-scheduling",
    "title": "CSC 453",
    "section": "Preemptive vs. non-preemptive scheduling",
    "text": "Preemptive vs. non-preemptive scheduling\n\nNon-Preemptive: The scheduler only makes scheduling decisions when a process voluntarily gives up the CPU (e.g., by blocking on I/O, completing, or explicitly yielding).\nPreemptive: The scheduler can interrupt a running process and move it to the ready queue at any time (based on time slices, priority changes, etc.), even while it’s actively executing.\nNon-preemptive is easier to implement, but\n\n… doesn’t support multiprogramming very well\n\nPreemptive can be complicated: correctness, utilization, flexibility\n\nSay a process P is preempted while in the middle of inserting an element in a data structure that another process (which is chosen by the scheduler) is going to process"
  },
  {
    "objectID": "day5.html#scheduling-metrics",
    "href": "day5.html#scheduling-metrics",
    "title": "CSC 453",
    "section": "Scheduling metrics",
    "text": "Scheduling metrics\n\nCPU utilization: keep the CPU as busy as possible\nThroughput: # of processes that complete their execution per time unit\nTurnaround time: amount of time to execute a particular process\nWaiting time: amount of time a process has been waiting in the ready queue\nResponse time: amount of time it takes from when a request was submitted until the first response is produced."
  },
  {
    "objectID": "day5.html#scheduling-scenarios",
    "href": "day5.html#scheduling-scenarios",
    "title": "CSC 453",
    "section": "Scheduling scenarios",
    "text": "Scheduling scenarios\nWhich metric would you optimize for these situations?\n\n\n\nYou run a data center that charges based on jobs completed\n\nMax throughput: maximize the number of jobs processed per unit time\n\nYou run GeForce Now\n\nMin response time: user experience is the main concern\n\nYou run Github Actions or Travis CI\n\nMin turnaround time: developers need feedback quickly\n\nYou run a supercomputing center\n\nMaximize CPU usage: this stuff is expensive, use it efficiently\n\n\n\n\n\n\nCPU utilization\nThroughput\nTurnaround time\nWaiting time\nResponse time"
  },
  {
    "objectID": "day5.html#what-does-the-os-scheduler-know-about-a-process",
    "href": "day5.html#what-does-the-os-scheduler-know-about-a-process",
    "title": "CSC 453",
    "section": "What does the OS scheduler know about a process?",
    "text": "What does the OS scheduler know about a process?\n\nProcess characteristics that we’d like to know in order to achieve our goals\n\nProcessing Time (Burst Time)\nI/O Requirements\nPriority\nAge\nDependencies\n\nThe scheduler knows very little of the above\nIn many cases we are hoping to predict the future. Easy, right?"
  },
  {
    "objectID": "day5.html#section-1",
    "href": "day5.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day5.html#questions-to-consider-2",
    "href": "day5.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow do FCFS, SJF, and SRTF compare in terms of tradeoffs between waiting time and response time?\nWhy does SJF require predicting future CPU bursts, and how can we estimate them?\nWhat is starvation in the context of scheduling, and how can we prevent it?"
  },
  {
    "objectID": "day5.html#batch-scheduling-fcfs",
    "href": "day5.html#batch-scheduling-fcfs",
    "title": "CSC 453",
    "section": "Batch scheduling: FCFS",
    "text": "Batch scheduling: FCFS\n\n\n\nFirst-Come, First-Served (FCFS)\nNon-preemptive\nPros:\n\nEasy to understand, easy to implement\n\nCons?\n\nWaiting time & turnaround time have high variance\nExample: 1 long CPU-bound process and many I/O bound processes\n\nConvoy effect"
  },
  {
    "objectID": "day5.html#fcfs-example",
    "href": "day5.html#fcfs-example",
    "title": "CSC 453",
    "section": "FCFS example",
    "text": "FCFS example\n\n\n\nCalculate the average waiting time:\nOrder: P1, P2, P3 \nWaiting time P1 = 0; P2 = 24; P3 = 27\nAverage waiting time: \\((0 + 24 + 27)/3 = 17\\)\nOrder P2, P3, P1 \nWaiting time P1 = 6; P2 = 0; P3 = 3\nAverage waiting time: \\((6 + 0 + 3)/3 = 3\\)\n\n\n\n\nProcess Burst Time  \n  P1         24\n  P2          3\n  P3          3"
  },
  {
    "objectID": "day5.html#okay-fcfs-can-be-bad",
    "href": "day5.html#okay-fcfs-can-be-bad",
    "title": "CSC 453",
    "section": "Okay, FCFS can be bad",
    "text": "Okay, FCFS can be bad\nCan we think of a better algorithm to deal with the reality that jobs run for different amounts of time?"
  },
  {
    "objectID": "day5.html#batch-scheduling-shortest-job-first-sjf",
    "href": "day5.html#batch-scheduling-shortest-job-first-sjf",
    "title": "CSC 453",
    "section": "Batch scheduling: shortest job first (SJF)",
    "text": "Batch scheduling: shortest job first (SJF)\n\n\n\nOrdered by length of the process’s next CPU burst\nNon-preemptive\nPros?\n\nOptimal average waiting time\n\nCons?\n\nRequires knowing the future (potentially okay in some situations; examples?)\n\nScientific jobs, batch jobs\n\n\nQuestion: how do we know the length of the upcoming CPU burst?\n\nAsk the process? Estimate? How?"
  },
  {
    "objectID": "day5.html#sjf-how-can-we-predict-the-future",
    "href": "day5.html#sjf-how-can-we-predict-the-future",
    "title": "CSC 453",
    "section": "SJF: how can we predict the future?",
    "text": "SJF: how can we predict the future?\n\nWe can’t trust a process to tell the truth\nWe can only estimate, how?\n\nThe past (with the hope that the process will act like it has before)\n\nExponential weighted moving average: \\[\nEWMA_t = \\alpha \\times x_t + (1 - \\alpha) \\times EWMA_{t-1}\n\\]\n\\(\\alpha = 0\\)? New measurement does not get taken into account\n\\(\\alpha = 1\\)? History does not get taken into account\n\\(\\alpha\\) is often set to .5"
  },
  {
    "objectID": "day5.html#sjf-example",
    "href": "day5.html#sjf-example",
    "title": "CSC 453",
    "section": "SJF example",
    "text": "SJF example\n\n\n\nGantt: \nAverage waiting time: \\((3 + 16 + 9 + 0)/4 = 7\\)\nVersus FCFS: \\((0 + 6 + 14 + 21)/4 = 10.25\\)\n\n\n\n\n    Process Burst Time  \n      P1          6\n      P2          8\n      P3          7\n      P4          3"
  },
  {
    "objectID": "day5.html#do-you-see-any-problems-with-sjf",
    "href": "day5.html#do-you-see-any-problems-with-sjf",
    "title": "CSC 453",
    "section": "Do you see any problems with SJF?",
    "text": "Do you see any problems with SJF?\n\nWhat do we do if a short process arrives after SJF has started a long running process? \nWhat should we do?\n\nPreempt"
  },
  {
    "objectID": "day5.html#shortest-remaining-time-first-srtf",
    "href": "day5.html#shortest-remaining-time-first-srtf",
    "title": "CSC 453",
    "section": "Shortest remaining time first (SRTF)",
    "text": "Shortest remaining time first (SRTF)\n\n\n\nPreemptive version of SJF\nWhenever a new process arrives in the ready queue, the decision on which process to schedule next is redone using the SJF algorithm\nQuestion: is SRTF more optimal than SJF for any metrics?\n\nYes, average waiting time is minimized"
  },
  {
    "objectID": "day5.html#srtf-example",
    "href": "day5.html#srtf-example",
    "title": "CSC 453",
    "section": "SRTF example",
    "text": "SRTF example\n    Process      Arrival Time   Burst Time\n     P1               0             8\n     P2               1             4\n     P3               2             9\n     P4               3             5\n\nAverage waiting time = \\([(0+9)+(0)+(15)+(2)]/4 = 26/4 = 6.5\\)"
  },
  {
    "objectID": "day5.html#do-you-see-any-problems-with-srtf",
    "href": "day5.html#do-you-see-any-problems-with-srtf",
    "title": "CSC 453",
    "section": "Do you see any problems with SRTF?",
    "text": "Do you see any problems with SRTF?\n\nComputers aren’t static. What if short jobs continuously arrive?\n\nLarge jobs can starve\nUrban legend about IBM 7074 at MIT: when shut down in 1973, low-priority processes were found which had been submitted in 1967 and had not yet been run…"
  },
  {
    "objectID": "day5.html#priority-scheduling",
    "href": "day5.html#priority-scheduling",
    "title": "CSC 453",
    "section": "Priority scheduling",
    "text": "Priority scheduling\n\n“Shortest” algos are examples of priority scheduling\nI.e., scheduling is based on some metric of priority\nDownsides\n\nIf not implemented carefully, indefinite blocking / starvation\nHow do we prevent starvation?\n\nAging: gradually increase the priority of processes that wait in the system for a long time"
  },
  {
    "objectID": "day5.html#section-2",
    "href": "day5.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day5.html#questions-to-consider-3",
    "href": "day5.html#questions-to-consider-3",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the key differences between batch and interactive scheduling algorithms?\nHow does Round Robin improve response time compared to SJF, and what tradeoff does it introduce?\nWhy might a system benefit from using multiple scheduling queues rather than a single algorithm?"
  },
  {
    "objectID": "day5.html#batch-vs.-interactive-scheduling",
    "href": "day5.html#batch-vs.-interactive-scheduling",
    "title": "CSC 453",
    "section": "Batch vs. interactive scheduling",
    "text": "Batch vs. interactive scheduling\n\n\nBatch Scheduling\n\nOptimizes for: throughput, turnaround time, waiting time\nContext: data centers, HPC, background jobs\nUsers don’t interact with running jobs\n\n\n\n\nInteractive Scheduling\n\nOptimizes for: response time, fairness\nContext: desktop/laptop systems, servers\nUsers expect quick feedback to their actions"
  },
  {
    "objectID": "day5.html#what-about-response-time",
    "href": "day5.html#what-about-response-time",
    "title": "CSC 453",
    "section": "What about response time?",
    "text": "What about response time?\n\n\n\nSRTF is good if we know job lengths and we’re only worried about turnaround / waiting time\nSJF: poor response\nRR: better response"
  },
  {
    "objectID": "day5.html#interactive-algorithm-round-robin-rr",
    "href": "day5.html#interactive-algorithm-round-robin-rr",
    "title": "CSC 453",
    "section": "Interactive algorithm: Round Robin (RR)",
    "text": "Interactive algorithm: Round Robin (RR)\n\nFCFS with preemption\nBased on a time quantum (time slice)\n\nTypically 10-100 milliseconds\nHow do we pick a quantum?\n\nVery short: a lot of context switching (need a large quantum, otherwise overhead is too much to be worth it)\nVery long -&gt; becomes FCFS: long wait times, long turnaround times\n\nCircular queue\n\nNew processes are added to the tail\nIf a process doesn’t complete during its quantum, context switch and added to the tail"
  },
  {
    "objectID": "day5.html#rr-example",
    "href": "day5.html#rr-example",
    "title": "CSC 453",
    "section": "RR example",
    "text": "RR example\n\n\n\nAverage waiting time:  \\[[(10-4) + 4 + 7] = 17/3 = 5.66\\]\nPros:\n\nRR is fair, but do we really want fair???\nTypically, higher average turnaround than SJF, but better response\n\nCons?\n\nLong average waiting times\n\n\n\n\n\nProcess Burst Time\n  P1        24\n  P2        3\n  P3        3   \n\n  Quantum = 4"
  },
  {
    "objectID": "day5.html#gaming-rr",
    "href": "day5.html#gaming-rr",
    "title": "CSC 453",
    "section": "Gaming RR",
    "text": "Gaming RR\n\nHow could a programmer “cheat” RR?\n\nSpin up many processes (split tasks up and fork children)\nJob A: 9 processes\nJob B: 1 process\nA gets 90% of the CPU in RR\n\nThis actually happens in many systems that aim for rudimentary fairness"
  },
  {
    "objectID": "day5.html#fcfs-sjf-srtf-rr",
    "href": "day5.html#fcfs-sjf-srtf-rr",
    "title": "CSC 453",
    "section": "FCFS, SJF, SRTF, RR",
    "text": "FCFS, SJF, SRTF, RR\n\nAll have downsides\nThose that optimize turnaround / wait, can harm response time\nThose that optimize response time, can harm turnaround, wait\nWhat should we do?"
  },
  {
    "objectID": "day5.html#interactive-algorithms-multi-level-queue-mlq",
    "href": "day5.html#interactive-algorithms-multi-level-queue-mlq",
    "title": "CSC 453",
    "section": "Interactive algorithms: Multi-Level Queue (MLQ)",
    "text": "Interactive algorithms: Multi-Level Queue (MLQ)\n\nWe have classes of process, with different needs. Why not multiple schedulers satisfying those needs?\nMultilevel queue scheduler defined by the following parameters:\n\n# of queues\nScheduling algorithms for each queue\nMethod used to determine which queue a process will enter when that process needs service\nScheduling among the queues"
  },
  {
    "objectID": "day5.html#mlq",
    "href": "day5.html#mlq",
    "title": "CSC 453",
    "section": "MLQ",
    "text": "MLQ\n\n\n\nHow do we schedule this?\n\nStrict priority: low priority could starve\nTypical: time slice among queues (e.g., real-time get 50%, system gets 30%, interactive 15%, batch 5%)\nEach queue can implement a separate scheduling policy\n\nMLQ cons:\n\nStarvation\nInflexibility"
  },
  {
    "objectID": "day5.html#interactive-algorithms-multi-level-feedback-queue-mlfq",
    "href": "day5.html#interactive-algorithms-multi-level-feedback-queue-mlfq",
    "title": "CSC 453",
    "section": "Interactive algorithms: Multi-Level Feedback Queue (MLFQ)",
    "text": "Interactive algorithms: Multi-Level Feedback Queue (MLFQ)\n\nA process can move between the various queues\nMetrics for movement:\n\nProcess requirements (we serve fast processes quickly)\nOver consumption\nChange in priority\nAge"
  },
  {
    "objectID": "day5.html#mlfq-rules",
    "href": "day5.html#mlfq-rules",
    "title": "CSC 453",
    "section": "MLFQ rules",
    "text": "MLFQ rules\n\nRule 1: If Priority(A) &gt; Priority(B), A runs (B doesn’t)\nRule 2: If Priority(A)=Priority(B), A & B run in RR\nRule 3: When a job enters the system, it is placed at the highest priority (the topmost queue)\nRule 4a: If a job uses up its allotment while running, its priority is reduced (i.e., it moves down one queue)\nRule 4b: If a job gives up the CPU (for example, by performing an I/O operation) before the allotment is up, it stays at the same priority level (i.e., its allotment is reset)\nAny problems with these???"
  },
  {
    "objectID": "day5.html#mlfq-example-one-process",
    "href": "day5.html#mlfq-example-one-process",
    "title": "CSC 453",
    "section": "MLFQ example: one process",
    "text": "MLFQ example: one process"
  },
  {
    "objectID": "day5.html#mlfq-example-two-processes",
    "href": "day5.html#mlfq-example-two-processes",
    "title": "CSC 453",
    "section": "MLFQ example: two processes",
    "text": "MLFQ example: two processes\n\n\n\nScenario 1: Perfectly fine"
  },
  {
    "objectID": "day5.html#mlfq-example-two-processes-1",
    "href": "day5.html#mlfq-example-two-processes-1",
    "title": "CSC 453",
    "section": "MLFQ example: two processes",
    "text": "MLFQ example: two processes\n\n\n\nScenario 1: Perfectly fine\nScenario 2: programmer can game the algorithm to remain at high priority"
  },
  {
    "objectID": "day5.html#mlfq-example-two-processes-2",
    "href": "day5.html#mlfq-example-two-processes-2",
    "title": "CSC 453",
    "section": "MLFQ example: two processes",
    "text": "MLFQ example: two processes\n\n\n\nScenario 1: Perfectly fine\nScenario 2: programmer can game the algorithm to remain at high priority\nScenario 3: multiple small processes keep lead to starvation"
  },
  {
    "objectID": "day5.html#mlfq-solving-gaming",
    "href": "day5.html#mlfq-solving-gaming",
    "title": "CSC 453",
    "section": "MLFQ: solving gaming",
    "text": "MLFQ: solving gaming\n\n\n\nRule 4 (new): Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue)"
  },
  {
    "objectID": "day5.html#mlfq-solving-starvation",
    "href": "day5.html#mlfq-solving-starvation",
    "title": "CSC 453",
    "section": "MLFQ: solving starvation",
    "text": "MLFQ: solving starvation\n\n\n\nRule 5: After some time period, move all the jobs in the system to the topmost queue\n\nSolves starvation\nIf a long running process evolves to be more interactive, it gets promoted"
  },
  {
    "objectID": "day5.html#what-scheduler-should-we-use",
    "href": "day5.html#what-scheduler-should-we-use",
    "title": "CSC 453",
    "section": "What scheduler should we use?",
    "text": "What scheduler should we use?\n\nTicket booking system\n\nFCFS: fairness\n\nPrint server\n\nSJF could make sense\n\nWeb server\n\nRR: fairness\n\nStreaming service\n\nSRTF: need to quickly respond to something going wrong e.g., buffering\n\nGeneral operating systems\n\nMLFQ: need to handle a mix"
  },
  {
    "objectID": "day5.html#section-3",
    "href": "day5.html#section-3",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day8.html#admin",
    "href": "day8.html#admin",
    "title": "CSC 453",
    "section": "Admin",
    "text": "Admin\n\nQuiz due Friday\nLab (synchronization and deadlock) due Monday"
  },
  {
    "objectID": "day8.html#questions-to-consider",
    "href": "day8.html#questions-to-consider",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nHow do synchronization solutions compare in implementation / function?\nWhy can busy-waiting primitives cause problems like priority inversion, and how do blocking primitives help address this?\nWhen would you choose a counting semaphore versus a binary semaphore or mutex, and what distinguishes them?"
  },
  {
    "objectID": "day8.html#semaphores",
    "href": "day8.html#semaphores",
    "title": "CSC 453",
    "section": "Semaphores",
    "text": "Semaphores\n\n\n\nSynchronization tool that provides more sophisticated ways (than mutex locks) for processes to synchronize their activities\nSemaphore S: integer variable\nCan only be accessed via two atomic operations\n\nwait() and signal()\n\nOriginally called P() and V() (because, Dutch - another Dijkstra invention)\n\n\nDo not have ownership, any thread can signal (increment) or wait (decrement)\n\n\n\n\nwait(S) { \n    while (S &lt;= 0)\n       ; // busy\n    S--;\n}\n\nsignal(S) { \n    S++;\n}"
  },
  {
    "objectID": "day8.html#semaphores-contd",
    "href": "day8.html#semaphores-contd",
    "title": "CSC 453",
    "section": "Semaphores (cont’d)",
    "text": "Semaphores (cont’d)\n\n\n\nBinary semaphore: integer value can range only between 0 and 1\n\nFunctionally the same as a mutex (often when people call something a mutex it’s actually a binary semaphore)\n\n\n\n\n\ndo{\n  wait(mutex);\n  //CS\n  signal(mutex);\n}while(TRUE);\n\n\nCounting semaphore: integer value can range over an unrestricted domain\n\nWhen would this make sense?\n\nProtect a finite set of resources rather than a single one (e.g., you have a pool of db connections that can be shared by processes)\nInitialize S to the number of resources\nDecrement S each time someone grabs a resource, increment when they release"
  },
  {
    "objectID": "day8.html#semaphores-contd-1",
    "href": "day8.html#semaphores-contd-1",
    "title": "CSC 453",
    "section": "Semaphores (cont’d)",
    "text": "Semaphores (cont’d)\n\n\n\nCan also be used to force synchronization\nConsider \\(P_1\\) and \\(P_2\\) that with two statements \\(S_1\\) and \\(S_2\\) and the requirement that \\(S_1\\) to happen before \\(S_2\\)\n\n\n\n\nP1:\n   S1;\n   signal(sync);\nP2:\n   wait(sync);\n   S2;"
  },
  {
    "objectID": "day8.html#blocking-semaphores",
    "href": "day8.html#blocking-semaphores",
    "title": "CSC 453",
    "section": "Blocking semaphores",
    "text": "Blocking semaphores\n\n\n\nWe add sleep() and wakeup() to the underlying implementation\nCall to wait, and semaphore not available, process is blocked with sleep() (wait state) and placed on a waiting queue\nBlocked processes are notified of an available semaphore by the wakeup() operation\n\ngoes from waiting to ready\nAble to achieve bounded wait and progress with FIFO queue\n\n\n\n\n\nwait(semaphore *S) { \n   S-&gt;value--; \n   if (S-&gt;value &lt; 0) {      \n      add process to S-&gt;list; \n      sleep(); \n   } \n}\n\nsignal(semaphore *S) { \n   S-&gt;value++; \n   if (S-&gt;value &lt;= 0) {      \n      remove P from S-&gt;list; \n      wakeup(P); \n   } \n}"
  },
  {
    "objectID": "day8.html#mutexes-vs.-semaphores",
    "href": "day8.html#mutexes-vs.-semaphores",
    "title": "CSC 453",
    "section": "Mutexes vs. semaphores",
    "text": "Mutexes vs. semaphores\n\nMutexes are generally lighter weight / faster\nSemaphores can support multiple instances\nSemaphores don’t have the ownership limitations"
  },
  {
    "objectID": "day8.html#choose-your-primitive",
    "href": "day8.html#choose-your-primitive",
    "title": "CSC 453",
    "section": "Choose your primitive",
    "text": "Choose your primitive\n\nFor each, choose between: atomic instructions; futexes; spin lock mutexes; semaphores\nScenario 1: You need to protect a critical section where only one thread should execute at a time, and the critical section is expected to be held for a relatively long duration.\n\nFutex\n\nScenario 2: You have a pool of database connections, and you need to limit the number of threads that can access these connections simultaneously.\n\nCounting semaphore"
  },
  {
    "objectID": "day8.html#choose-your-primitive-contd",
    "href": "day8.html#choose-your-primitive-contd",
    "title": "CSC 453",
    "section": "Choose your primitive (cont’d)",
    "text": "Choose your primitive (cont’d)\n\nFor each, choose between: atomic instructions; futexes; spin lock mutexes; semaphores\nScenario 3: You need to increment a shared counter frequently, and the operation is very quick.\n\nAtomic instruction\n\nScenario 4: You need to protect a critical section where only one thread should execute at a time, but the critical section is expected to be held for a very short duration.\n\nSpin lock mutex"
  },
  {
    "objectID": "day8.html#beware-mistakes-are-easy-to-make",
    "href": "day8.html#beware-mistakes-are-easy-to-make",
    "title": "CSC 453",
    "section": "Beware: mistakes are easy to make",
    "text": "Beware: mistakes are easy to make\n\nIncorrect use of semaphore operations\n\nwrong order: signal(mutex) … wait(mutex)\nrepeating: wait(mutex) … wait(mutex)\nOmitting of wait(mutex) and/or signal(mutex)\n\nBe careful"
  },
  {
    "objectID": "day8.html#monitors",
    "href": "day8.html#monitors",
    "title": "CSC 453",
    "section": "Monitors",
    "text": "Monitors\n\nSubtle mistakes with semaphores can lead to deadlocks, leading to monitors\nCan think of monitors as a library with an API (abstract data type)\n\nProcesses share the library, but not internal data (directly)\nThis requires language specific understanding of a monitor (C doesn’t have them, natively)\nMore relevant in languages like Java and other high-level languages that provide built-in monitor support"
  },
  {
    "objectID": "day8.html#monitors-contd",
    "href": "day8.html#monitors-contd",
    "title": "CSC 453",
    "section": "Monitors (cont’d)",
    "text": "Monitors (cont’d)\n\n\n\nMain idea: only one processes can be active within a monitor at any instant\n\nUp to the compilers to ensure mutual exclusion on monitor procedures\n\nIt can use other sync primitives to achieve this: e.g. a semaphore or mutex\n\nWe’re offloading synchronization correctness to the compiler, (hopefully) lessening the chance for error by the user\n\nMonitor variables are private"
  },
  {
    "objectID": "day8.html#condition-variables",
    "href": "day8.html#condition-variables",
    "title": "CSC 453",
    "section": "Condition variables",
    "text": "Condition variables\n\nMonitors often have condition variables\nCondition variables have wait() and signal() operations\n\nx.wait(): a process that invokes the operation is suspended until x.signal()\nx.signal(): resumes one of processes (if any) that invoked x.wait()\n\nIf no x.wait() on the variable, then it has no effect on the variable\n\n\nBig benefit of condition variables: x.broadcast()"
  },
  {
    "objectID": "day8.html#mutexes-semaphores-monitors-condition-variables",
    "href": "day8.html#mutexes-semaphores-monitors-condition-variables",
    "title": "CSC 453",
    "section": "Mutexes, semaphores, Monitors, Condition variables",
    "text": "Mutexes, semaphores, Monitors, Condition variables\n\nMutexes and Semaphores are good for:\n\nSimple mutual exclusion\nSimple counting resources\n\nMonitors are good for:\n\nComplex synchronization between many threads\nThread-safe operations (only allow one thread into the monitor at a time)\n\nCondition variables are good for:\n\nProducer-consumer problems (consumer threads waiting on some condition, signaled when ready)\nWe want to make one or more threads sleep until a resource is ready"
  },
  {
    "objectID": "day8.html#section",
    "href": "day8.html#section",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day8.html#questions-to-consider-1",
    "href": "day8.html#questions-to-consider-1",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the four necessary conditions for deadlock, and why must all four be present simultaneously?\nHow can Resource Allocation Graphs help us visualize and understand when deadlock might occur?\nWhy is a cycle necessary but not sufficient for deadlock when there are multiple instances of a resource?"
  },
  {
    "objectID": "day8.html#deadlocks-1",
    "href": "day8.html#deadlocks-1",
    "title": "CSC 453",
    "section": "Deadlocks",
    "text": "Deadlocks\n\nIf we’re not careful about dependencies, we might create pathologies that lead to deadlock\n\nLike race conditions, may only happen sometimes, making them hard to identify and debug\n\nExample: Three processes, three resources of the same type, each process requires two resources to make progress\n\nThis can happen across a network as well, which is particularly hard to diagnose\n\nCan we detect and resolve these situations? Can we prevent them?"
  },
  {
    "objectID": "day8.html#deadlock-example",
    "href": "day8.html#deadlock-example",
    "title": "CSC 453",
    "section": "Deadlock example",
    "text": "Deadlock example\n\nClassic example: Thread1 holds lock L1 and is waiting for lock L2. Thread2 holds L2 and is waiting for L1\n  Thread 1:                       Thread 2:\n  pthread_mutex_lock(L1);         pthread_mutex_lock(L2);\n  pthread_mutex_lock(L2);         pthread_mutex_lock(L1);"
  },
  {
    "objectID": "day8.html#deadlock-characteristics",
    "href": "day8.html#deadlock-characteristics",
    "title": "CSC 453",
    "section": "Deadlock characteristics",
    "text": "Deadlock characteristics\n\nDefinition: A set of processes are deadlocked if each process in the set is waiting for an event that only another process in the set can cause.\n\nResource deadlock is the most common (and what we’ll focus on generally)\nCommunication deadlock: e.g., Process A sends a message to B, then sleeps until reply; Process B sleeps until it receives a message from A; message is lost"
  },
  {
    "objectID": "day8.html#conditions-for-deadlock",
    "href": "day8.html#conditions-for-deadlock",
    "title": "CSC 453",
    "section": "Conditions for deadlock",
    "text": "Conditions for deadlock\n\nFour necessary conditions (simultaneous):\n\nMutual exclusion: At least one resource can only be held by one process at a time; this can result in other processes waiting for that resources\nHold and wait: A process must be holding at least one resource while waiting for other resources (held by other processes)\nNo preemption: Resources can only be released voluntarily by a process; Resources cannot be revoked\nCircular wait: A set of \\(n\\) waiting process \\({P_0, ..., P_n}\\) such that \\(P_i\\) is waiting for resources held by \\(P_{i+1 \\bmod{n}}\\)\n\nAll must be met, and some imply others: e.g. Circular wait implies hold and wait."
  },
  {
    "objectID": "day8.html#deadlock-conditions",
    "href": "day8.html#deadlock-conditions",
    "title": "CSC 453",
    "section": "Deadlock conditions",
    "text": "Deadlock conditions\n\nEach condition relates to a policy that may or may not be implemented\n\nQ: Can a resource be assigned to more than one process?\nQ: Can a process request multiple resources? Over what period of time?\nQ: Can resources be preempted, and how?"
  },
  {
    "objectID": "day8.html#deadlock-modeling",
    "href": "day8.html#deadlock-modeling",
    "title": "CSC 453",
    "section": "Deadlock modeling",
    "text": "Deadlock modeling\n\n\n\nResource Allocation Graphs: A directed graph, where process and resources are nodes (sometimes circles and squares respectively), and edges are resource allocations & requests\nGraph for\nThread 1:                   Thread 2:\npthread_mutex_lock(L1);     pthread_mutex_lock(L2);\npthread_mutex_lock(L2);     pthread_mutex_lock(L1);\n\n\n\n\n\n\n\nCycles in a graph indicate deadlock\n\nWhen resources have only one instance: A cycle is both necessary and sufficient for deadlock\nIf there are multiple instances: A cycle is necessary but not sufficient for a deadlock"
  },
  {
    "objectID": "day8.html#is-this-deadlocked",
    "href": "day8.html#is-this-deadlocked",
    "title": "CSC 453",
    "section": "Is this deadlocked?",
    "text": "Is this deadlocked?\n\nThere is a cycle\nBut no hold and wait"
  },
  {
    "objectID": "day8.html#section-1",
    "href": "day8.html#section-1",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day8.html#questions-to-consider-2",
    "href": "day8.html#questions-to-consider-2",
    "title": "CSC 453",
    "section": "Questions to consider",
    "text": "Questions to consider\n\nWhat are the approaches to handling deadlock? How practical is each? How do they differ in approach?\nHow does deadlock avoidance differ from deadlock prevention? What techniques do we implement for deadlock avoidance?\nWhat are the trade-offs between detecting/recovering from deadlock versus preventing or avoiding it, and when is detection practical?"
  },
  {
    "objectID": "day8.html#how-should-the-os-handle-deadlocks",
    "href": "day8.html#how-should-the-os-handle-deadlocks",
    "title": "CSC 453",
    "section": "How should the OS handle deadlocks?",
    "text": "How should the OS handle deadlocks?\n\nOS can prevent deadlock: ensure deadlocks can never occur (by preventing one of the deadlock requirements from occurring)\nOS can avoid deadlock: like prevention, but given more information about a processes resource needs\nOS can detect deadlock: allow system to deadlock, detect and recover\nOS can do nothing, and let applications handle it\n\nOstrich Algorithm: head in sand; wait"
  },
  {
    "objectID": "day8.html#deadlock-prevention",
    "href": "day8.html#deadlock-prevention",
    "title": "CSC 453",
    "section": "Deadlock prevention",
    "text": "Deadlock prevention\n\nRemember, we just have to break one of these to prevent deadlock\n\nMutual exclusion\nHold and wait\nNo preemption\nCircular wait\n\n\n\nAny ideas?\n\n\nExample Strategies: - Dynamic Resource Allocation: Implement algorithms that dynamically adjust resource allocation based on current system state and process priorities. - Timeout Mechanism: Introduce timeouts for resource requests, forcing processes to release resources if they cannot acquire all necessary resources within a certain timeframe. - Resource Hierarchies: Establish a hierarchy for resource allocation, ensuring that processes request resources in a predefined order to avoid circular wait conditions. - Predictive Analysis: Use machine learning to predict potential deadlock scenarios based on historical data and proactively adjust resource allocation.\nFollow-Up Questions: - How does your strategy address mutual exclusion? - Can your strategy be implemented in real-world systems? If so, how? - What challenges might arise when implementing your strategy?"
  },
  {
    "objectID": "day8.html#attacking-mutual-exclusion",
    "href": "day8.html#attacking-mutual-exclusion",
    "title": "CSC 453",
    "section": "Attacking mutual exclusion",
    "text": "Attacking mutual exclusion\n\nNo one resource can only be held by one process at a time; while some resources are preemptable (like memory, through swapping) preventing mutual exclusion is fundamentally difficult as so many resource are non-sharable: printers, files, disks, etc.\n\nWe can create a monitor for non-preemptable resources (e.g., print spooler, disk drive buffer)"
  },
  {
    "objectID": "day8.html#attacking-hold-and-wait",
    "href": "day8.html#attacking-hold-and-wait",
    "title": "CSC 453",
    "section": "Attacking hold and wait",
    "text": "Attacking hold and wait\n\nWhen a process requests a resource, it cannot be holding any other resources\nA process must request all of its resources at one time\nExample, treat group of lock acquisitions like a critical section and surround with a mutex\npthread_mutex_lock(global_lock);\npthread_mutex_lock(L1);\npthread_mutex_lock(L2);\n...\npthread_mutex_unlock(global_lock);\nSee any downsides?\n\nMust know all needed locks a priori\nWill likely decrease concurrency"
  },
  {
    "objectID": "day8.html#attacking-no-preemption",
    "href": "day8.html#attacking-no-preemption",
    "title": "CSC 453",
    "section": "Attacking no preemption",
    "text": "Attacking no preemption\n\nIf a process is holding some resources and requests another that cannot be immediately allocated, then all resources held are released\nProcess is restarted only when it can regain its old resources plus the new\nOr, if a process requests a resource that cannot be immediately allocated, then all resources held are preempted and added to the list of available resources\nDownsides?\n\nNot all resources are preempt-able\nStarvation is possible"
  },
  {
    "objectID": "day8.html#attacking-circular-wait",
    "href": "day8.html#attacking-circular-wait",
    "title": "CSC 453",
    "section": "Attacking circular wait",
    "text": "Attacking circular wait\n\nHow could you prevent by focusing on the circular wait requirement?\nImpose a total ordering of all resource types\n\nFor example, resource types R1, R2, …, Rn have ordering R1 &lt; R2 &lt; … &lt; Rn\nA process that needs multiple resources must request them in increasing order of enumeration\n\nDownsides?\n\nMay be difficult to impose a meaningful ordering\nMay lead to reduced concurrency"
  },
  {
    "objectID": "day8.html#deadlock-prevention-summary",
    "href": "day8.html#deadlock-prevention-summary",
    "title": "CSC 453",
    "section": "Deadlock prevention summary",
    "text": "Deadlock prevention summary\n\nWhich approach is best?\n\nAttacking mutual exclusion is generally not feasible\nAttacking hold and wait is wasteful and requires prescience\nAttacking no preemption is difficult due to non-preemptable resources\nAttacking circular wait is practical but may reduce concurrency - often the best choice and most used"
  },
  {
    "objectID": "day8.html#section-2",
    "href": "day8.html#section-2",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  },
  {
    "objectID": "day8.html#deadlock-avoidance",
    "href": "day8.html#deadlock-avoidance",
    "title": "CSC 453",
    "section": "Deadlock avoidance",
    "text": "Deadlock avoidance\n\nAll of the prevention techniques can be heavy-handed, reducing concurrency and overall system throughput\nWhat if we had more information about process resource needs before allocation?\n\nCould we make smarter decisions about resource allocation?\n\nThis is the idea behind deadlock avoidance"
  },
  {
    "objectID": "day8.html#avoidance-via-resource-allocation-graph",
    "href": "day8.html#avoidance-via-resource-allocation-graph",
    "title": "CSC 453",
    "section": "Avoidance via resource-allocation graph",
    "text": "Avoidance via resource-allocation graph\n\n\n\nIntroduce the idea of a claim edge (dashed line) from a process to a resource\n\nIndicates that the process may request that resource in the future\n\nThe system can maintain this graph, and only grant resources that will not create a cycle\nAny downsides / limitations?\n\nOverhead of maintaining the graph and checking for cycles\nOnly applicable to single instance resources"
  },
  {
    "objectID": "day8.html#a-note-on-dijkstras-bankers-algorithm",
    "href": "day8.html#a-note-on-dijkstras-bankers-algorithm",
    "title": "CSC 453",
    "section": "A note on Dijkstra’s Banker’s algorithm",
    "text": "A note on Dijkstra’s Banker’s algorithm\n\nMost OS textbooks discuss Dijkstra’s Banker’s algorithm as a deadlock avoidance technique\nEach process must declare the maximum number of resources it may need\nWhen a process requests a resource, the system must determine if granting the request will leave the system in a safe state\n\nA safe state is one where there exists a sequence of all processes such that each can obtain its maximum resources with the currently available resources plus those held by all preceding processes in the sequence\n\nIf granting the request leads to an unsafe state, the process must wait\nNot often used in practice due to overhead and requirement for prescience"
  },
  {
    "objectID": "day8.html#deadlock-avoidance-summary",
    "href": "day8.html#deadlock-avoidance-summary",
    "title": "CSC 453",
    "section": "Deadlock avoidance summary",
    "text": "Deadlock avoidance summary\n\nDo you think any of the avoidance methods are used in general purpose OSes? Why? Why not?\nResource-allocation graph with claim edges is sometimes used for specific resource types\n\ne.g., embedded systems with limited resources where you can predict maximum needs and the graph overhead is manageable\n\nBanker’s algorithm is generally not used due to its overhead and requirements"
  },
  {
    "objectID": "day8.html#detecting-and-recovering-from-deadlock",
    "href": "day8.html#detecting-and-recovering-from-deadlock",
    "title": "CSC 453",
    "section": "Detecting and recovering from deadlock",
    "text": "Detecting and recovering from deadlock\n\nAllow deadlocks to occur, then detect and recover\nIn some cases, recovery is pretty simple. If your machine froze once per year (maybe it does?) what would you do?\n\nReboot\n\nWhat scenarios do you think complex detection and recovery would make sense?\n\nSystems with high availability requirements where manual intervention is costly or impractical\n\ntelecommunications systems, financial transaction systems, healthcare systems\ncritical infrastructure systems"
  },
  {
    "objectID": "day8.html#detection",
    "href": "day8.html#detection",
    "title": "CSC 453",
    "section": "Detection",
    "text": "Detection\n\nUse a wait-for graph: a simplified resource-allocation graph that removes resource nodes\n\nAn edge from process \\(P_i\\) to \\(P_j\\) indicates that \\(P_i\\) is waiting for a resource held by \\(P_j\\)\nA cycle in this graph indicates a deadlock\n\\(O(n^2)\\) algorithm to search for cycles (beyond the cost of maintaining the graph itself)\nOnly applies to single instance resources"
  },
  {
    "objectID": "day8.html#detection-contd",
    "href": "day8.html#detection-contd",
    "title": "CSC 453",
    "section": "Detection (cont’d)",
    "text": "Detection (cont’d)"
  },
  {
    "objectID": "day8.html#detection-contd-1",
    "href": "day8.html#detection-contd-1",
    "title": "CSC 453",
    "section": "Detection (cont’d)",
    "text": "Detection (cont’d)\n\nFor multiple instance resources, we can use an algorithm similar to the Banker’s algorithm to detect deadlock\nQuestion: How often should we run the detection algorithm?\n\nToo often: wasteful overhead\nNot often enough: long delays before recovery\nWhat if we run it when a process requests a resource?\n\nCould allow us to assign blame for deadlock to the requesting process\n\nHeuristically (CPU utilization, etc.)\n\nLess overhead, but harder to assign blame"
  },
  {
    "objectID": "day8.html#recovery-options",
    "href": "day8.html#recovery-options",
    "title": "CSC 453",
    "section": "Recovery options",
    "text": "Recovery options\n\nProcess termination\n\nAbort all deadlocked processes (brute force)\nAbort one process at a time until deadlock is resolved\n\nHow to choose which process to abort?\n\nPriority, time running, resources used, etc.\n\n\n\nResource preemption\n\nTemporarily take resources away from some processes and give to others until deadlock is resolved\nHighly dependent on the resource type\nRollback problem - processes may need to be rolled back to a safe state before resources can be reallocated\nStarvation problem - same victims may be chosen repeatedly"
  },
  {
    "objectID": "day8.html#handling-deadlocks-summary",
    "href": "day8.html#handling-deadlocks-summary",
    "title": "CSC 453",
    "section": "Handling deadlocks summary",
    "text": "Handling deadlocks summary\n\nWhen to use which technique?\n\nPrevention: when you can afford to limit concurrency and throughput for simplicity\nAvoidance: when you have good information about process resource needs and can afford the overhead\nDetection and recovery: when deadlocks are rare and the overhead of prevention/avoidance is unjustified\nDo nothing: when deadlocks are extremely rare or tolerable and can be handled at the application level"
  },
  {
    "objectID": "day8.html#section-3",
    "href": "day8.html#section-3",
    "title": "CSC 453",
    "section": "",
    "text": "What isn’t clear?\nComments? Thoughts?"
  }
]